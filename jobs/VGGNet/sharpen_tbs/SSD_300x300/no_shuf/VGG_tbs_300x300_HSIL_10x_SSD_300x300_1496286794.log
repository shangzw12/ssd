I0601 11:13:14.335947 28894 caffe.cpp:217] Using GPUs 0
I0601 11:13:14.365380 28894 caffe.cpp:222] GPU 0: TITAN X (Pascal)
I0601 11:13:14.594763 28894 solver.cpp:63] Initializing solver from parameters: 
train_net: "models/VGGNet/tbs/SSD_300x300/train.prototxt"
test_net: "models/VGGNet/tbs/SSD_300x300/test.prototxt"
test_iter: 25
test_interval: 100
base_lr: 2.5e-05
display: 10
max_iter: 200000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
snapshot: 2000
snapshot_prefix: "models/VGGNet/tbs/SSD_300x300/VGG_tbs_300x300_HSIL_10x_SSD_300x300"
solver_mode: GPU
device_id: 0
debug_info: false
train_state {
  level: 0
  stage: ""
}
snapshot_after_train: true
test_initialization: false
average_loss: 10
stepvalue: 80000
stepvalue: 100000
stepvalue: 120000
iter_size: 1
type: "SGD"
eval_type: "detection"
ap_version: "11point"
I0601 11:13:14.594918 28894 solver.cpp:96] Creating training net from train_net file: models/VGGNet/tbs/SSD_300x300/train.prototxt
I0601 11:13:14.596590 28894 net.cpp:58] Initializing net from parameters: 
name: "VGG_tbs_300x300_HSIL_10x_SSD_300x300_train"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "AnnotatedData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    mean_value: 104
    mean_value: 117
    mean_value: 123
    resize_param {
      prob: 1
      resize_mode: WARP
      height: 300
      width: 300
      interp_mode: LINEAR
      interp_mode: AREA
      interp_mode: NEAREST
      interp_mode: CUBIC
      interp_mode: LANCZOS4
    }
    emit_constraint {
      emit_type: CENTER
    }
    distort_param {
      brightness_prob: 0.5
      brightness_delta: 32
      contrast_prob: 0.5
      contrast_lower: 0.5
      contrast_upper: 1.5
      hue_prob: 0.5
      hue_delta: 18
      saturation_prob: 0.5
      saturation_lower: 0.5
      saturation_upper: 1.5
      random_order_prob: 0
    }
    expand_param {
      prob: 0.5
      max_expand_ratio: 4
    }
  }
  data_param {
    source: "examples/tbs_300x300_HSIL_10x/tbs_300x300_HSIL_10x_trainval_lmdb"
    batch_size: 32
    backend: LMDB
  }
  annotated_data_param {
    batch_sampler {
      max_sample: 1
      max_trials: 1
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.1
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.3
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.5
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.7
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.9
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        max_jaccard_overlap: 1
      }
      max_sample: 1
      max_trials: 50
    }
    label_map_file: "data/tbs_300x300_HSIL_10x/labelmap_tbs.prototxt"
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "fc6"
  type: "Convolution"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    pad: 6
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 6
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "fc7"
  type: "Convolution"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "conv6_1"
  type: "Convolution"
  bottom: "fc7"
  top: "conv6_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6_1_relu"
  type: "ReLU"
  bottom: "conv6_1"
  top: "conv6_1"
}
layer {
  name: "conv6_2"
  type: "Convolution"
  bottom: "conv6_1"
  top: "conv6_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6_2_relu"
  type: "ReLU"
  bottom: "conv6_2"
  top: "conv6_2"
}
layer {
  name: "conv7_1"
  type: "Convolution"
  bottom: "conv6_2"
  top: "conv7_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv7_1_relu"
  type: "ReLU"
  bottom: "conv7_1"
  top: "conv7_1"
}
layer {
  name: "conv7_2"
  type: "Convolution"
  bottom: "conv7_1"
  top: "conv7_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv7_2_relu"
  type: "ReLU"
  bottom: "conv7_2"
  top: "conv7_2"
}
layer {
  name: "conv8_1"
  type: "Convolution"
  bottom: "conv7_2"
  top: "conv8_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv8_1_relu"
  type: "ReLU"
  bottom: "conv8_1"
  top: "conv8_1"
}
layer {
  name: "conv8_2"
  type: "Convolution"
  bottom: "conv8_1"
  top: "conv8_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv8_2_relu"
  type: "ReLU"
  bottom: "conv8_2"
  top: "conv8_2"
}
layer {
  name: "conv9_1"
  type: "Convolution"
  bottom: "conv8_2"
  top: "conv9_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv9_1_relu"
  type: "ReLU"
  bottom: "conv9_1"
  top: "conv9_1"
}
layer {
  name: "conv9_2"
  type: "Convolution"
  bottom: "conv9_1"
  top: "conv9_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv9_2_relu"
  type: "ReLU"
  bottom: "conv9_2"
  top: "conv9_2"
}
layer {
  name: "conv4_3_norm"
  type: "Normalize"
  bottom: "conv4_3"
  top: "conv4_3_norm"
  norm_param {
    across_spatial: false
    scale_filler {
      type: "constant"
      value: 20
    }
    channel_shared: false
  }
}
layer {
  name: "conv4_3_norm_mbox_loc"
  type: "Convolution"
  bottom: "conv4_3_norm"
  top: "conv4_3_norm_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_3_norm_mbox_loc_perm"
  type: "Permute"
  bottom: "conv4_3_norm_mbox_loc"
  top: "conv4_3_norm_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv4_3_norm_mbox_loc_perm"
  top: "conv4_3_norm_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_conf"
  type: "Convolution"
  bottom: "conv4_3_norm"
  top: "conv4_3_norm_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_3_norm_mbox_conf_perm"
  type: "Permute"
  bottom: "conv4_3_norm_mbox_conf"
  top: "conv4_3_norm_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv4_3_norm_mbox_conf_perm"
  top: "conv4_3_norm_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv4_3_norm"
  bottom: "data"
  top: "conv4_3_norm_mbox_priorbox"
  prior_box_param {
    min_size: 30
    max_size: 60
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 8
    offset: 0.5
  }
}
layer {
  name: "fc7_mbox_loc"
  type: "Convolution"
  bottom: "fc7"
  top: "fc7_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc7_mbox_loc_perm"
  type: "Permute"
  bottom: "fc7_mbox_loc"
  top: "fc7_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "fc7_mbox_loc_flat"
  type: "Flatten"
  bottom: "fc7_mbox_loc_perm"
  top: "fc7_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "fc7_mbox_conf"
  type: "Convolution"
  bottom: "fc7"
  top: "fc7_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc7_mbox_conf_perm"
  type: "Permute"
  bottom: "fc7_mbox_conf"
  top: "fc7_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "fc7_mbox_conf_flat"
  type: "Flatten"
  bottom: "fc7_mbox_conf_perm"
  top: "fc7_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "fc7_mbox_priorbox"
  type: "PriorBox"
  bottom: "fc7"
  bottom: "data"
  top: "fc7_mbox_priorbox"
  prior_box_param {
    min_size: 60
    max_size: 111
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 16
    offset: 0.5
  }
}
layer {
  name: "conv6_2_mbox_loc"
  type: "Convolution"
  bottom: "conv6_2"
  top: "conv6_2_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6_2_mbox_loc_perm"
  type: "Permute"
  bottom: "conv6_2_mbox_loc"
  top: "conv6_2_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv6_2_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv6_2_mbox_loc_perm"
  top: "conv6_2_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv6_2_mbox_conf"
  type: "Convolution"
  bottom: "conv6_2"
  top: "conv6_2_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6_2_mbox_conf_perm"
  type: "Permute"
  bottom: "conv6_2_mbox_conf"
  top: "conv6_2_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv6_2_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv6_2_mbox_conf_perm"
  top: "conv6_2_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv6_2_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv6_2"
  bottom: "data"
  top: "conv6_2_mbox_priorbox"
  prior_box_param {
    min_size: 111
    max_size: 162
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 32
    offset: 0.5
  }
}
layer {
  name: "conv7_2_mbox_loc"
  type: "Convolution"
  bottom: "conv7_2"
  top: "conv7_2_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv7_2_mbox_loc_perm"
  type: "Permute"
  bottom: "conv7_2_mbox_loc"
  top: "conv7_2_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv7_2_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv7_2_mbox_loc_perm"
  top: "conv7_2_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv7_2_mbox_conf"
  type: "Convolution"
  bottom: "conv7_2"
  top: "conv7_2_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv7_2_mbox_conf_perm"
  type: "Permute"
  bottom: "conv7_2_mbox_conf"
  top: "conv7_2_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv7_2_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv7_2_mbox_conf_perm"
  top: "conv7_2_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv7_2_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv7_2"
  bottom: "data"
  top: "conv7_2_mbox_priorbox"
  prior_box_param {
    min_size: 162
    max_size: 213
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 64
    offset: 0.5
  }
}
layer {
  name: "conv8_2_mbox_loc"
  type: "Convolution"
  bottom: "conv8_2"
  top: "conv8_2_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv8_2_mbox_loc_perm"
  type: "Permute"
  bottom: "conv8_2_mbox_loc"
  top: "conv8_2_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv8_2_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv8_2_mbox_loc_perm"
  top: "conv8_2_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv8_2_mbox_conf"
  type: "Convolution"
  bottom: "conv8_2"
  top: "conv8_2_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv8_2_mbox_conf_perm"
  type: "Permute"
  bottom: "conv8_2_mbox_conf"
  top: "conv8_2_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv8_2_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv8_2_mbox_conf_perm"
  top: "conv8_2_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv8_2_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv8_2"
  bottom: "data"
  top: "conv8_2_mbox_priorbox"
  prior_box_param {
    min_size: 213
    max_size: 264
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 100
    offset: 0.5
  }
}
layer {
  name: "conv9_2_mbox_loc"
  type: "Convolution"
  bottom: "conv9_2"
  top: "conv9_2_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv9_2_mbox_loc_perm"
  type: "Permute"
  bottom: "conv9_2_mbox_loc"
  top: "conv9_2_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv9_2_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv9_2_mbox_loc_perm"
  top: "conv9_2_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv9_2_mbox_conf"
  type: "Convolution"
  bottom: "conv9_2"
  top: "conv9_2_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv9_2_mbox_conf_perm"
  type: "Permute"
  bottom: "conv9_2_mbox_conf"
  top: "conv9_2_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv9_2_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv9_2_mbox_conf_perm"
  top: "conv9_2_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv9_2_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv9_2"
  bottom: "data"
  top: "conv9_2_mbox_priorbox"
  prior_box_param {
    min_size: 264
    max_size: 315
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 300
    offset: 0.5
  }
}
layer {
  name: "mbox_loc"
  type: "Concat"
  bottom: "conv4_3_norm_mbox_loc_flat"
  bottom: "fc7_mbox_loc_flat"
  bottom: "conv6_2_mbox_loc_flat"
  bottom: "conv7_2_mbox_loc_flat"
  bottom: "conv8_2_mbox_loc_flat"
  bottom: "conv9_2_mbox_loc_flat"
  top: "mbox_loc"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mbox_conf"
  type: "Concat"
  bottom: "conv4_3_norm_mbox_conf_flat"
  bottom: "fc7_mbox_conf_flat"
  bottom: "conv6_2_mbox_conf_flat"
  bottom: "conv7_2_mbox_conf_flat"
  bottom: "conv8_2_mbox_conf_flat"
  bottom: "conv9_2_mbox_conf_flat"
  top: "mbox_conf"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mbox_priorbox"
  type: "Concat"
  bottom: "conv4_3_norm_mbox_priorbox"
  bottom: "fc7_mbox_priorbox"
  bottom: "conv6_2_mbox_priorbox"
  bottom: "conv7_2_mbox_priorbox"
  bottom: "conv8_2_mbox_priorbox"
  bottom: "conv9_2_mbox_priorbox"
  top: "mbox_priorbox"
  concat_param {
    axis: 2
  }
}
layer {
  name: "mbox_loss"
  type: "MultiBoxLoss"
  bottom: "mbox_loc"
  bottom: "mbox_conf"
  bottom: "mbox_priorbox"
  bottom: "label"
  top: "mbox_loss"
  include {
    phase: TRAIN
  }
  propagate_down: true
  propagate_down: true
  propagate_down: false
  propagate_down: false
  loss_param {
    normalization: VALID
  }
  multibox_loss_param {
    loc_loss_type: SMOOTH_L1
    conf_loss_type: SOFTMAX
    loc_weight: 1
    num_classes: 4
    share_location: true
    match_type: PER_PREDICTION
    overlap_threshold: 0.5
    use_prior_for_matching: true
    background_label_id: 0
    use_difficult_gt: true
    neg_pos_ratio: 3
    neg_overlap: 0.5
    code_type: CENTER_SIZE
    ignore_cross_boundary_bbox: false
    mining_type: MAX_NEGATIVE
  }
}
I0601 11:13:14.596928 28894 layer_factory.hpp:77] Creating layer data
I0601 11:13:14.597143 28894 net.cpp:100] Creating Layer data
I0601 11:13:14.597153 28894 net.cpp:408] data -> data
I0601 11:13:14.597180 28894 net.cpp:408] data -> label
I0601 11:13:14.597719 28910 db_lmdb.cpp:35] Opened lmdb examples/tbs_300x300_HSIL_10x/tbs_300x300_HSIL_10x_trainval_lmdb
I0601 11:13:14.606310 28894 annotated_data_layer.cpp:62] output data size: 32,3,300,300
I0601 11:13:14.665503 28894 net.cpp:150] Setting up data
I0601 11:13:14.665536 28894 net.cpp:157] Top shape: 32 3 300 300 (8640000)
I0601 11:13:14.665540 28894 net.cpp:157] Top shape: 1 1 1 8 (8)
I0601 11:13:14.665571 28894 net.cpp:165] Memory required for data: 34560032
I0601 11:13:14.665580 28894 layer_factory.hpp:77] Creating layer data_data_0_split
I0601 11:13:14.665602 28894 net.cpp:100] Creating Layer data_data_0_split
I0601 11:13:14.665607 28894 net.cpp:434] data_data_0_split <- data
I0601 11:13:14.665632 28894 net.cpp:408] data_data_0_split -> data_data_0_split_0
I0601 11:13:14.665657 28894 net.cpp:408] data_data_0_split -> data_data_0_split_1
I0601 11:13:14.665675 28894 net.cpp:408] data_data_0_split -> data_data_0_split_2
I0601 11:13:14.665683 28894 net.cpp:408] data_data_0_split -> data_data_0_split_3
I0601 11:13:14.665686 28894 net.cpp:408] data_data_0_split -> data_data_0_split_4
I0601 11:13:14.665691 28894 net.cpp:408] data_data_0_split -> data_data_0_split_5
I0601 11:13:14.665696 28894 net.cpp:408] data_data_0_split -> data_data_0_split_6
I0601 11:13:14.665777 28894 net.cpp:150] Setting up data_data_0_split
I0601 11:13:14.665782 28894 net.cpp:157] Top shape: 32 3 300 300 (8640000)
I0601 11:13:14.665786 28894 net.cpp:157] Top shape: 32 3 300 300 (8640000)
I0601 11:13:14.665788 28894 net.cpp:157] Top shape: 32 3 300 300 (8640000)
I0601 11:13:14.665791 28894 net.cpp:157] Top shape: 32 3 300 300 (8640000)
I0601 11:13:14.665793 28894 net.cpp:157] Top shape: 32 3 300 300 (8640000)
I0601 11:13:14.665812 28894 net.cpp:157] Top shape: 32 3 300 300 (8640000)
I0601 11:13:14.665814 28894 net.cpp:157] Top shape: 32 3 300 300 (8640000)
I0601 11:13:14.665818 28894 net.cpp:165] Memory required for data: 276480032
I0601 11:13:14.665822 28894 layer_factory.hpp:77] Creating layer conv1_1
I0601 11:13:14.665837 28894 net.cpp:100] Creating Layer conv1_1
I0601 11:13:14.665843 28894 net.cpp:434] conv1_1 <- data_data_0_split_0
I0601 11:13:14.665848 28894 net.cpp:408] conv1_1 -> conv1_1
I0601 11:13:14.667512 28894 net.cpp:150] Setting up conv1_1
I0601 11:13:14.667526 28894 net.cpp:157] Top shape: 32 64 300 300 (184320000)
I0601 11:13:14.667528 28894 net.cpp:165] Memory required for data: 1013760032
I0601 11:13:14.667541 28894 layer_factory.hpp:77] Creating layer relu1_1
I0601 11:13:14.667547 28894 net.cpp:100] Creating Layer relu1_1
I0601 11:13:14.667551 28894 net.cpp:434] relu1_1 <- conv1_1
I0601 11:13:14.667557 28894 net.cpp:395] relu1_1 -> conv1_1 (in-place)
I0601 11:13:14.667562 28894 net.cpp:150] Setting up relu1_1
I0601 11:13:14.667567 28894 net.cpp:157] Top shape: 32 64 300 300 (184320000)
I0601 11:13:14.667568 28894 net.cpp:165] Memory required for data: 1751040032
I0601 11:13:14.667572 28894 layer_factory.hpp:77] Creating layer conv1_2
I0601 11:13:14.667579 28894 net.cpp:100] Creating Layer conv1_2
I0601 11:13:14.667582 28894 net.cpp:434] conv1_2 <- conv1_1
I0601 11:13:14.667587 28894 net.cpp:408] conv1_2 -> conv1_2
I0601 11:13:14.679075 28894 net.cpp:150] Setting up conv1_2
I0601 11:13:14.679090 28894 net.cpp:157] Top shape: 32 64 300 300 (184320000)
I0601 11:13:14.679092 28894 net.cpp:165] Memory required for data: 2488320032
I0601 11:13:14.679116 28894 layer_factory.hpp:77] Creating layer relu1_2
I0601 11:13:14.679122 28894 net.cpp:100] Creating Layer relu1_2
I0601 11:13:14.679126 28894 net.cpp:434] relu1_2 <- conv1_2
I0601 11:13:14.679129 28894 net.cpp:395] relu1_2 -> conv1_2 (in-place)
I0601 11:13:14.679136 28894 net.cpp:150] Setting up relu1_2
I0601 11:13:14.679138 28894 net.cpp:157] Top shape: 32 64 300 300 (184320000)
I0601 11:13:14.679141 28894 net.cpp:165] Memory required for data: 3225600032
I0601 11:13:14.679142 28894 layer_factory.hpp:77] Creating layer pool1
I0601 11:13:14.679147 28894 net.cpp:100] Creating Layer pool1
I0601 11:13:14.679148 28894 net.cpp:434] pool1 <- conv1_2
I0601 11:13:14.679153 28894 net.cpp:408] pool1 -> pool1
I0601 11:13:14.679200 28894 net.cpp:150] Setting up pool1
I0601 11:13:14.679206 28894 net.cpp:157] Top shape: 32 64 150 150 (46080000)
I0601 11:13:14.679208 28894 net.cpp:165] Memory required for data: 3409920032
I0601 11:13:14.679211 28894 layer_factory.hpp:77] Creating layer conv2_1
I0601 11:13:14.679219 28894 net.cpp:100] Creating Layer conv2_1
I0601 11:13:14.679232 28894 net.cpp:434] conv2_1 <- pool1
I0601 11:13:14.679236 28894 net.cpp:408] conv2_1 -> conv2_1
I0601 11:13:14.679843 28894 net.cpp:150] Setting up conv2_1
I0601 11:13:14.679867 28894 net.cpp:157] Top shape: 32 128 150 150 (92160000)
I0601 11:13:14.679868 28894 net.cpp:165] Memory required for data: 3778560032
I0601 11:13:14.679874 28894 layer_factory.hpp:77] Creating layer relu2_1
I0601 11:13:14.679880 28894 net.cpp:100] Creating Layer relu2_1
I0601 11:13:14.679883 28894 net.cpp:434] relu2_1 <- conv2_1
I0601 11:13:14.679888 28894 net.cpp:395] relu2_1 -> conv2_1 (in-place)
I0601 11:13:14.679904 28894 net.cpp:150] Setting up relu2_1
I0601 11:13:14.679908 28894 net.cpp:157] Top shape: 32 128 150 150 (92160000)
I0601 11:13:14.679909 28894 net.cpp:165] Memory required for data: 4147200032
I0601 11:13:14.679911 28894 layer_factory.hpp:77] Creating layer conv2_2
I0601 11:13:14.679918 28894 net.cpp:100] Creating Layer conv2_2
I0601 11:13:14.679920 28894 net.cpp:434] conv2_2 <- conv2_1
I0601 11:13:14.679924 28894 net.cpp:408] conv2_2 -> conv2_2
I0601 11:13:14.680786 28894 net.cpp:150] Setting up conv2_2
I0601 11:13:14.680794 28894 net.cpp:157] Top shape: 32 128 150 150 (92160000)
I0601 11:13:14.680797 28894 net.cpp:165] Memory required for data: 4515840032
I0601 11:13:14.680801 28894 layer_factory.hpp:77] Creating layer relu2_2
I0601 11:13:14.680804 28894 net.cpp:100] Creating Layer relu2_2
I0601 11:13:14.680806 28894 net.cpp:434] relu2_2 <- conv2_2
I0601 11:13:14.680811 28894 net.cpp:395] relu2_2 -> conv2_2 (in-place)
I0601 11:13:14.680815 28894 net.cpp:150] Setting up relu2_2
I0601 11:13:14.680819 28894 net.cpp:157] Top shape: 32 128 150 150 (92160000)
I0601 11:13:14.680821 28894 net.cpp:165] Memory required for data: 4884480032
I0601 11:13:14.680824 28894 layer_factory.hpp:77] Creating layer pool2
I0601 11:13:14.680827 28894 net.cpp:100] Creating Layer pool2
I0601 11:13:14.680830 28894 net.cpp:434] pool2 <- conv2_2
I0601 11:13:14.680833 28894 net.cpp:408] pool2 -> pool2
I0601 11:13:14.680857 28894 net.cpp:150] Setting up pool2
I0601 11:13:14.680861 28894 net.cpp:157] Top shape: 32 128 75 75 (23040000)
I0601 11:13:14.680876 28894 net.cpp:165] Memory required for data: 4976640032
I0601 11:13:14.680879 28894 layer_factory.hpp:77] Creating layer conv3_1
I0601 11:13:14.680889 28894 net.cpp:100] Creating Layer conv3_1
I0601 11:13:14.680894 28894 net.cpp:434] conv3_1 <- pool2
I0601 11:13:14.680899 28894 net.cpp:408] conv3_1 -> conv3_1
I0601 11:13:14.683408 28894 net.cpp:150] Setting up conv3_1
I0601 11:13:14.683423 28894 net.cpp:157] Top shape: 32 256 75 75 (46080000)
I0601 11:13:14.683424 28894 net.cpp:165] Memory required for data: 5160960032
I0601 11:13:14.683434 28894 layer_factory.hpp:77] Creating layer relu3_1
I0601 11:13:14.683440 28894 net.cpp:100] Creating Layer relu3_1
I0601 11:13:14.683444 28894 net.cpp:434] relu3_1 <- conv3_1
I0601 11:13:14.683449 28894 net.cpp:395] relu3_1 -> conv3_1 (in-place)
I0601 11:13:14.683454 28894 net.cpp:150] Setting up relu3_1
I0601 11:13:14.683459 28894 net.cpp:157] Top shape: 32 256 75 75 (46080000)
I0601 11:13:14.683460 28894 net.cpp:165] Memory required for data: 5345280032
I0601 11:13:14.683464 28894 layer_factory.hpp:77] Creating layer conv3_2
I0601 11:13:14.683470 28894 net.cpp:100] Creating Layer conv3_2
I0601 11:13:14.683472 28894 net.cpp:434] conv3_2 <- conv3_1
I0601 11:13:14.683476 28894 net.cpp:408] conv3_2 -> conv3_2
I0601 11:13:14.686631 28894 net.cpp:150] Setting up conv3_2
I0601 11:13:14.686643 28894 net.cpp:157] Top shape: 32 256 75 75 (46080000)
I0601 11:13:14.686645 28894 net.cpp:165] Memory required for data: 5529600032
I0601 11:13:14.686650 28894 layer_factory.hpp:77] Creating layer relu3_2
I0601 11:13:14.686657 28894 net.cpp:100] Creating Layer relu3_2
I0601 11:13:14.686661 28894 net.cpp:434] relu3_2 <- conv3_2
I0601 11:13:14.686664 28894 net.cpp:395] relu3_2 -> conv3_2 (in-place)
I0601 11:13:14.686671 28894 net.cpp:150] Setting up relu3_2
I0601 11:13:14.686674 28894 net.cpp:157] Top shape: 32 256 75 75 (46080000)
I0601 11:13:14.686691 28894 net.cpp:165] Memory required for data: 5713920032
I0601 11:13:14.686702 28894 layer_factory.hpp:77] Creating layer conv3_3
I0601 11:13:14.686710 28894 net.cpp:100] Creating Layer conv3_3
I0601 11:13:14.686714 28894 net.cpp:434] conv3_3 <- conv3_2
I0601 11:13:14.686719 28894 net.cpp:408] conv3_3 -> conv3_3
I0601 11:13:14.689906 28894 net.cpp:150] Setting up conv3_3
I0601 11:13:14.689918 28894 net.cpp:157] Top shape: 32 256 75 75 (46080000)
I0601 11:13:14.689921 28894 net.cpp:165] Memory required for data: 5898240032
I0601 11:13:14.689926 28894 layer_factory.hpp:77] Creating layer relu3_3
I0601 11:13:14.689931 28894 net.cpp:100] Creating Layer relu3_3
I0601 11:13:14.689934 28894 net.cpp:434] relu3_3 <- conv3_3
I0601 11:13:14.689940 28894 net.cpp:395] relu3_3 -> conv3_3 (in-place)
I0601 11:13:14.689945 28894 net.cpp:150] Setting up relu3_3
I0601 11:13:14.689949 28894 net.cpp:157] Top shape: 32 256 75 75 (46080000)
I0601 11:13:14.689951 28894 net.cpp:165] Memory required for data: 6082560032
I0601 11:13:14.689954 28894 layer_factory.hpp:77] Creating layer pool3
I0601 11:13:14.689959 28894 net.cpp:100] Creating Layer pool3
I0601 11:13:14.689960 28894 net.cpp:434] pool3 <- conv3_3
I0601 11:13:14.689965 28894 net.cpp:408] pool3 -> pool3
I0601 11:13:14.689991 28894 net.cpp:150] Setting up pool3
I0601 11:13:14.689996 28894 net.cpp:157] Top shape: 32 256 38 38 (11829248)
I0601 11:13:14.689997 28894 net.cpp:165] Memory required for data: 6129877024
I0601 11:13:14.689999 28894 layer_factory.hpp:77] Creating layer conv4_1
I0601 11:13:14.690007 28894 net.cpp:100] Creating Layer conv4_1
I0601 11:13:14.690011 28894 net.cpp:434] conv4_1 <- pool3
I0601 11:13:14.690013 28894 net.cpp:408] conv4_1 -> conv4_1
I0601 11:13:14.697123 28894 net.cpp:150] Setting up conv4_1
I0601 11:13:14.697140 28894 net.cpp:157] Top shape: 32 512 38 38 (23658496)
I0601 11:13:14.697142 28894 net.cpp:165] Memory required for data: 6224511008
I0601 11:13:14.697163 28894 layer_factory.hpp:77] Creating layer relu4_1
I0601 11:13:14.697171 28894 net.cpp:100] Creating Layer relu4_1
I0601 11:13:14.697175 28894 net.cpp:434] relu4_1 <- conv4_1
I0601 11:13:14.697180 28894 net.cpp:395] relu4_1 -> conv4_1 (in-place)
I0601 11:13:14.697185 28894 net.cpp:150] Setting up relu4_1
I0601 11:13:14.697188 28894 net.cpp:157] Top shape: 32 512 38 38 (23658496)
I0601 11:13:14.697190 28894 net.cpp:165] Memory required for data: 6319144992
I0601 11:13:14.697192 28894 layer_factory.hpp:77] Creating layer conv4_2
I0601 11:13:14.697214 28894 net.cpp:100] Creating Layer conv4_2
I0601 11:13:14.697233 28894 net.cpp:434] conv4_2 <- conv4_1
I0601 11:13:14.697238 28894 net.cpp:408] conv4_2 -> conv4_2
I0601 11:13:14.708745 28894 net.cpp:150] Setting up conv4_2
I0601 11:13:14.708765 28894 net.cpp:157] Top shape: 32 512 38 38 (23658496)
I0601 11:13:14.708768 28894 net.cpp:165] Memory required for data: 6413778976
I0601 11:13:14.708793 28894 layer_factory.hpp:77] Creating layer relu4_2
I0601 11:13:14.708799 28894 net.cpp:100] Creating Layer relu4_2
I0601 11:13:14.708803 28894 net.cpp:434] relu4_2 <- conv4_2
I0601 11:13:14.708808 28894 net.cpp:395] relu4_2 -> conv4_2 (in-place)
I0601 11:13:14.708814 28894 net.cpp:150] Setting up relu4_2
I0601 11:13:14.708817 28894 net.cpp:157] Top shape: 32 512 38 38 (23658496)
I0601 11:13:14.708834 28894 net.cpp:165] Memory required for data: 6508412960
I0601 11:13:14.708837 28894 layer_factory.hpp:77] Creating layer conv4_3
I0601 11:13:14.708856 28894 net.cpp:100] Creating Layer conv4_3
I0601 11:13:14.708860 28894 net.cpp:434] conv4_3 <- conv4_2
I0601 11:13:14.708868 28894 net.cpp:408] conv4_3 -> conv4_3
I0601 11:13:14.720937 28894 net.cpp:150] Setting up conv4_3
I0601 11:13:14.720966 28894 net.cpp:157] Top shape: 32 512 38 38 (23658496)
I0601 11:13:14.720968 28894 net.cpp:165] Memory required for data: 6603046944
I0601 11:13:14.720989 28894 layer_factory.hpp:77] Creating layer relu4_3
I0601 11:13:14.720995 28894 net.cpp:100] Creating Layer relu4_3
I0601 11:13:14.720999 28894 net.cpp:434] relu4_3 <- conv4_3
I0601 11:13:14.721004 28894 net.cpp:395] relu4_3 -> conv4_3 (in-place)
I0601 11:13:14.721037 28894 net.cpp:150] Setting up relu4_3
I0601 11:13:14.721041 28894 net.cpp:157] Top shape: 32 512 38 38 (23658496)
I0601 11:13:14.721043 28894 net.cpp:165] Memory required for data: 6697680928
I0601 11:13:14.721060 28894 layer_factory.hpp:77] Creating layer conv4_3_relu4_3_0_split
I0601 11:13:14.721065 28894 net.cpp:100] Creating Layer conv4_3_relu4_3_0_split
I0601 11:13:14.721067 28894 net.cpp:434] conv4_3_relu4_3_0_split <- conv4_3
I0601 11:13:14.721072 28894 net.cpp:408] conv4_3_relu4_3_0_split -> conv4_3_relu4_3_0_split_0
I0601 11:13:14.721079 28894 net.cpp:408] conv4_3_relu4_3_0_split -> conv4_3_relu4_3_0_split_1
I0601 11:13:14.721107 28894 net.cpp:150] Setting up conv4_3_relu4_3_0_split
I0601 11:13:14.721112 28894 net.cpp:157] Top shape: 32 512 38 38 (23658496)
I0601 11:13:14.721115 28894 net.cpp:157] Top shape: 32 512 38 38 (23658496)
I0601 11:13:14.721117 28894 net.cpp:165] Memory required for data: 6886948896
I0601 11:13:14.721119 28894 layer_factory.hpp:77] Creating layer pool4
I0601 11:13:14.721138 28894 net.cpp:100] Creating Layer pool4
I0601 11:13:14.721140 28894 net.cpp:434] pool4 <- conv4_3_relu4_3_0_split_0
I0601 11:13:14.721163 28894 net.cpp:408] pool4 -> pool4
I0601 11:13:14.721223 28894 net.cpp:150] Setting up pool4
I0601 11:13:14.721230 28894 net.cpp:157] Top shape: 32 512 19 19 (5914624)
I0601 11:13:14.721231 28894 net.cpp:165] Memory required for data: 6910607392
I0601 11:13:14.721233 28894 layer_factory.hpp:77] Creating layer conv5_1
I0601 11:13:14.721245 28894 net.cpp:100] Creating Layer conv5_1
I0601 11:13:14.721247 28894 net.cpp:434] conv5_1 <- pool4
I0601 11:13:14.721254 28894 net.cpp:408] conv5_1 -> conv5_1
I0601 11:13:14.733162 28894 net.cpp:150] Setting up conv5_1
I0601 11:13:14.733180 28894 net.cpp:157] Top shape: 32 512 19 19 (5914624)
I0601 11:13:14.733182 28894 net.cpp:165] Memory required for data: 6934265888
I0601 11:13:14.733187 28894 layer_factory.hpp:77] Creating layer relu5_1
I0601 11:13:14.733209 28894 net.cpp:100] Creating Layer relu5_1
I0601 11:13:14.733213 28894 net.cpp:434] relu5_1 <- conv5_1
I0601 11:13:14.733217 28894 net.cpp:395] relu5_1 -> conv5_1 (in-place)
I0601 11:13:14.733223 28894 net.cpp:150] Setting up relu5_1
I0601 11:13:14.733227 28894 net.cpp:157] Top shape: 32 512 19 19 (5914624)
I0601 11:13:14.733229 28894 net.cpp:165] Memory required for data: 6957924384
I0601 11:13:14.733232 28894 layer_factory.hpp:77] Creating layer conv5_2
I0601 11:13:14.733253 28894 net.cpp:100] Creating Layer conv5_2
I0601 11:13:14.733256 28894 net.cpp:434] conv5_2 <- conv5_1
I0601 11:13:14.733261 28894 net.cpp:408] conv5_2 -> conv5_2
I0601 11:13:14.745086 28894 net.cpp:150] Setting up conv5_2
I0601 11:13:14.745105 28894 net.cpp:157] Top shape: 32 512 19 19 (5914624)
I0601 11:13:14.745106 28894 net.cpp:165] Memory required for data: 6981582880
I0601 11:13:14.745113 28894 layer_factory.hpp:77] Creating layer relu5_2
I0601 11:13:14.745121 28894 net.cpp:100] Creating Layer relu5_2
I0601 11:13:14.745123 28894 net.cpp:434] relu5_2 <- conv5_2
I0601 11:13:14.745143 28894 net.cpp:395] relu5_2 -> conv5_2 (in-place)
I0601 11:13:14.745149 28894 net.cpp:150] Setting up relu5_2
I0601 11:13:14.745153 28894 net.cpp:157] Top shape: 32 512 19 19 (5914624)
I0601 11:13:14.745156 28894 net.cpp:165] Memory required for data: 7005241376
I0601 11:13:14.745157 28894 layer_factory.hpp:77] Creating layer conv5_3
I0601 11:13:14.745164 28894 net.cpp:100] Creating Layer conv5_3
I0601 11:13:14.745167 28894 net.cpp:434] conv5_3 <- conv5_2
I0601 11:13:14.745187 28894 net.cpp:408] conv5_3 -> conv5_3
I0601 11:13:14.757086 28894 net.cpp:150] Setting up conv5_3
I0601 11:13:14.757103 28894 net.cpp:157] Top shape: 32 512 19 19 (5914624)
I0601 11:13:14.757105 28894 net.cpp:165] Memory required for data: 7028899872
I0601 11:13:14.757112 28894 layer_factory.hpp:77] Creating layer relu5_3
I0601 11:13:14.757122 28894 net.cpp:100] Creating Layer relu5_3
I0601 11:13:14.757140 28894 net.cpp:434] relu5_3 <- conv5_3
I0601 11:13:14.757145 28894 net.cpp:395] relu5_3 -> conv5_3 (in-place)
I0601 11:13:14.757151 28894 net.cpp:150] Setting up relu5_3
I0601 11:13:14.757180 28894 net.cpp:157] Top shape: 32 512 19 19 (5914624)
I0601 11:13:14.757184 28894 net.cpp:165] Memory required for data: 7052558368
I0601 11:13:14.757185 28894 layer_factory.hpp:77] Creating layer pool5
I0601 11:13:14.757192 28894 net.cpp:100] Creating Layer pool5
I0601 11:13:14.757196 28894 net.cpp:434] pool5 <- conv5_3
I0601 11:13:14.757200 28894 net.cpp:408] pool5 -> pool5
I0601 11:13:14.757230 28894 net.cpp:150] Setting up pool5
I0601 11:13:14.757235 28894 net.cpp:157] Top shape: 32 512 19 19 (5914624)
I0601 11:13:14.757237 28894 net.cpp:165] Memory required for data: 7076216864
I0601 11:13:14.757239 28894 layer_factory.hpp:77] Creating layer fc6
I0601 11:13:14.757246 28894 net.cpp:100] Creating Layer fc6
I0601 11:13:14.757251 28894 net.cpp:434] fc6 <- pool5
I0601 11:13:14.757254 28894 net.cpp:408] fc6 -> fc6
I0601 11:13:14.779821 28894 net.cpp:150] Setting up fc6
I0601 11:13:14.779839 28894 net.cpp:157] Top shape: 32 1024 19 19 (11829248)
I0601 11:13:14.779841 28894 net.cpp:165] Memory required for data: 7123533856
I0601 11:13:14.779861 28894 layer_factory.hpp:77] Creating layer relu6
I0601 11:13:14.779868 28894 net.cpp:100] Creating Layer relu6
I0601 11:13:14.779871 28894 net.cpp:434] relu6 <- fc6
I0601 11:13:14.779876 28894 net.cpp:395] relu6 -> fc6 (in-place)
I0601 11:13:14.779883 28894 net.cpp:150] Setting up relu6
I0601 11:13:14.779886 28894 net.cpp:157] Top shape: 32 1024 19 19 (11829248)
I0601 11:13:14.779887 28894 net.cpp:165] Memory required for data: 7170850848
I0601 11:13:14.779891 28894 layer_factory.hpp:77] Creating layer fc7
I0601 11:13:14.779912 28894 net.cpp:100] Creating Layer fc7
I0601 11:13:14.779928 28894 net.cpp:434] fc7 <- fc6
I0601 11:13:14.779932 28894 net.cpp:408] fc7 -> fc7
I0601 11:13:14.785809 28894 net.cpp:150] Setting up fc7
I0601 11:13:14.785825 28894 net.cpp:157] Top shape: 32 1024 19 19 (11829248)
I0601 11:13:14.785827 28894 net.cpp:165] Memory required for data: 7218167840
I0601 11:13:14.785833 28894 layer_factory.hpp:77] Creating layer relu7
I0601 11:13:14.785841 28894 net.cpp:100] Creating Layer relu7
I0601 11:13:14.785845 28894 net.cpp:434] relu7 <- fc7
I0601 11:13:14.785850 28894 net.cpp:395] relu7 -> fc7 (in-place)
I0601 11:13:14.785856 28894 net.cpp:150] Setting up relu7
I0601 11:13:14.785861 28894 net.cpp:157] Top shape: 32 1024 19 19 (11829248)
I0601 11:13:14.785862 28894 net.cpp:165] Memory required for data: 7265484832
I0601 11:13:14.785864 28894 layer_factory.hpp:77] Creating layer fc7_relu7_0_split
I0601 11:13:14.785869 28894 net.cpp:100] Creating Layer fc7_relu7_0_split
I0601 11:13:14.785871 28894 net.cpp:434] fc7_relu7_0_split <- fc7
I0601 11:13:14.785874 28894 net.cpp:408] fc7_relu7_0_split -> fc7_relu7_0_split_0
I0601 11:13:14.785881 28894 net.cpp:408] fc7_relu7_0_split -> fc7_relu7_0_split_1
I0601 11:13:14.785897 28894 net.cpp:408] fc7_relu7_0_split -> fc7_relu7_0_split_2
I0601 11:13:14.785902 28894 net.cpp:408] fc7_relu7_0_split -> fc7_relu7_0_split_3
I0601 11:13:14.785945 28894 net.cpp:150] Setting up fc7_relu7_0_split
I0601 11:13:14.785949 28894 net.cpp:157] Top shape: 32 1024 19 19 (11829248)
I0601 11:13:14.785954 28894 net.cpp:157] Top shape: 32 1024 19 19 (11829248)
I0601 11:13:14.785956 28894 net.cpp:157] Top shape: 32 1024 19 19 (11829248)
I0601 11:13:14.785959 28894 net.cpp:157] Top shape: 32 1024 19 19 (11829248)
I0601 11:13:14.785961 28894 net.cpp:165] Memory required for data: 7454752800
I0601 11:13:14.785964 28894 layer_factory.hpp:77] Creating layer conv6_1
I0601 11:13:14.785969 28894 net.cpp:100] Creating Layer conv6_1
I0601 11:13:14.785974 28894 net.cpp:434] conv6_1 <- fc7_relu7_0_split_0
I0601 11:13:14.785979 28894 net.cpp:408] conv6_1 -> conv6_1
I0601 11:13:14.787865 28894 net.cpp:150] Setting up conv6_1
I0601 11:13:14.787875 28894 net.cpp:157] Top shape: 32 256 19 19 (2957312)
I0601 11:13:14.787878 28894 net.cpp:165] Memory required for data: 7466582048
I0601 11:13:14.787883 28894 layer_factory.hpp:77] Creating layer conv6_1_relu
I0601 11:13:14.787889 28894 net.cpp:100] Creating Layer conv6_1_relu
I0601 11:13:14.787904 28894 net.cpp:434] conv6_1_relu <- conv6_1
I0601 11:13:14.787907 28894 net.cpp:395] conv6_1_relu -> conv6_1 (in-place)
I0601 11:13:14.787912 28894 net.cpp:150] Setting up conv6_1_relu
I0601 11:13:14.787916 28894 net.cpp:157] Top shape: 32 256 19 19 (2957312)
I0601 11:13:14.787919 28894 net.cpp:165] Memory required for data: 7478411296
I0601 11:13:14.787920 28894 layer_factory.hpp:77] Creating layer conv6_2
I0601 11:13:14.787927 28894 net.cpp:100] Creating Layer conv6_2
I0601 11:13:14.787931 28894 net.cpp:434] conv6_2 <- conv6_1
I0601 11:13:14.787936 28894 net.cpp:408] conv6_2 -> conv6_2
I0601 11:13:14.794455 28894 net.cpp:150] Setting up conv6_2
I0601 11:13:14.794471 28894 net.cpp:157] Top shape: 32 512 10 10 (1638400)
I0601 11:13:14.794473 28894 net.cpp:165] Memory required for data: 7484964896
I0601 11:13:14.794498 28894 layer_factory.hpp:77] Creating layer conv6_2_relu
I0601 11:13:14.794518 28894 net.cpp:100] Creating Layer conv6_2_relu
I0601 11:13:14.794523 28894 net.cpp:434] conv6_2_relu <- conv6_2
I0601 11:13:14.794526 28894 net.cpp:395] conv6_2_relu -> conv6_2 (in-place)
I0601 11:13:14.794533 28894 net.cpp:150] Setting up conv6_2_relu
I0601 11:13:14.794550 28894 net.cpp:157] Top shape: 32 512 10 10 (1638400)
I0601 11:13:14.794553 28894 net.cpp:165] Memory required for data: 7491518496
I0601 11:13:14.794554 28894 layer_factory.hpp:77] Creating layer conv6_2_conv6_2_relu_0_split
I0601 11:13:14.794559 28894 net.cpp:100] Creating Layer conv6_2_conv6_2_relu_0_split
I0601 11:13:14.794560 28894 net.cpp:434] conv6_2_conv6_2_relu_0_split <- conv6_2
I0601 11:13:14.794565 28894 net.cpp:408] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_0
I0601 11:13:14.794584 28894 net.cpp:408] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_1
I0601 11:13:14.794595 28894 net.cpp:408] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_2
I0601 11:13:14.794600 28894 net.cpp:408] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_3
I0601 11:13:14.794646 28894 net.cpp:150] Setting up conv6_2_conv6_2_relu_0_split
I0601 11:13:14.794652 28894 net.cpp:157] Top shape: 32 512 10 10 (1638400)
I0601 11:13:14.794654 28894 net.cpp:157] Top shape: 32 512 10 10 (1638400)
I0601 11:13:14.794657 28894 net.cpp:157] Top shape: 32 512 10 10 (1638400)
I0601 11:13:14.794659 28894 net.cpp:157] Top shape: 32 512 10 10 (1638400)
I0601 11:13:14.794662 28894 net.cpp:165] Memory required for data: 7517732896
I0601 11:13:14.794664 28894 layer_factory.hpp:77] Creating layer conv7_1
I0601 11:13:14.794672 28894 net.cpp:100] Creating Layer conv7_1
I0601 11:13:14.794675 28894 net.cpp:434] conv7_1 <- conv6_2_conv6_2_relu_0_split_0
I0601 11:13:14.794682 28894 net.cpp:408] conv7_1 -> conv7_1
I0601 11:13:14.795110 28894 net.cpp:150] Setting up conv7_1
I0601 11:13:14.795120 28894 net.cpp:157] Top shape: 32 128 10 10 (409600)
I0601 11:13:14.795122 28894 net.cpp:165] Memory required for data: 7519371296
I0601 11:13:14.795128 28894 layer_factory.hpp:77] Creating layer conv7_1_relu
I0601 11:13:14.795136 28894 net.cpp:100] Creating Layer conv7_1_relu
I0601 11:13:14.795138 28894 net.cpp:434] conv7_1_relu <- conv7_1
I0601 11:13:14.795142 28894 net.cpp:395] conv7_1_relu -> conv7_1 (in-place)
I0601 11:13:14.795146 28894 net.cpp:150] Setting up conv7_1_relu
I0601 11:13:14.795150 28894 net.cpp:157] Top shape: 32 128 10 10 (409600)
I0601 11:13:14.795151 28894 net.cpp:165] Memory required for data: 7521009696
I0601 11:13:14.795153 28894 layer_factory.hpp:77] Creating layer conv7_2
I0601 11:13:14.795159 28894 net.cpp:100] Creating Layer conv7_2
I0601 11:13:14.795161 28894 net.cpp:434] conv7_2 <- conv7_1
I0601 11:13:14.795166 28894 net.cpp:408] conv7_2 -> conv7_2
I0601 11:13:14.797154 28894 net.cpp:150] Setting up conv7_2
I0601 11:13:14.797165 28894 net.cpp:157] Top shape: 32 256 5 5 (204800)
I0601 11:13:14.797168 28894 net.cpp:165] Memory required for data: 7521828896
I0601 11:13:14.797173 28894 layer_factory.hpp:77] Creating layer conv7_2_relu
I0601 11:13:14.797178 28894 net.cpp:100] Creating Layer conv7_2_relu
I0601 11:13:14.797181 28894 net.cpp:434] conv7_2_relu <- conv7_2
I0601 11:13:14.797195 28894 net.cpp:395] conv7_2_relu -> conv7_2 (in-place)
I0601 11:13:14.797201 28894 net.cpp:150] Setting up conv7_2_relu
I0601 11:13:14.797205 28894 net.cpp:157] Top shape: 32 256 5 5 (204800)
I0601 11:13:14.797207 28894 net.cpp:165] Memory required for data: 7522648096
I0601 11:13:14.797210 28894 layer_factory.hpp:77] Creating layer conv7_2_conv7_2_relu_0_split
I0601 11:13:14.797214 28894 net.cpp:100] Creating Layer conv7_2_conv7_2_relu_0_split
I0601 11:13:14.797216 28894 net.cpp:434] conv7_2_conv7_2_relu_0_split <- conv7_2
I0601 11:13:14.797219 28894 net.cpp:408] conv7_2_conv7_2_relu_0_split -> conv7_2_conv7_2_relu_0_split_0
I0601 11:13:14.797226 28894 net.cpp:408] conv7_2_conv7_2_relu_0_split -> conv7_2_conv7_2_relu_0_split_1
I0601 11:13:14.797231 28894 net.cpp:408] conv7_2_conv7_2_relu_0_split -> conv7_2_conv7_2_relu_0_split_2
I0601 11:13:14.797235 28894 net.cpp:408] conv7_2_conv7_2_relu_0_split -> conv7_2_conv7_2_relu_0_split_3
I0601 11:13:14.797276 28894 net.cpp:150] Setting up conv7_2_conv7_2_relu_0_split
I0601 11:13:14.797279 28894 net.cpp:157] Top shape: 32 256 5 5 (204800)
I0601 11:13:14.797283 28894 net.cpp:157] Top shape: 32 256 5 5 (204800)
I0601 11:13:14.797286 28894 net.cpp:157] Top shape: 32 256 5 5 (204800)
I0601 11:13:14.797288 28894 net.cpp:157] Top shape: 32 256 5 5 (204800)
I0601 11:13:14.797289 28894 net.cpp:165] Memory required for data: 7525924896
I0601 11:13:14.797292 28894 layer_factory.hpp:77] Creating layer conv8_1
I0601 11:13:14.797298 28894 net.cpp:100] Creating Layer conv8_1
I0601 11:13:14.797302 28894 net.cpp:434] conv8_1 <- conv7_2_conv7_2_relu_0_split_0
I0601 11:13:14.797307 28894 net.cpp:408] conv8_1 -> conv8_1
I0601 11:13:14.797586 28894 net.cpp:150] Setting up conv8_1
I0601 11:13:14.797592 28894 net.cpp:157] Top shape: 32 128 5 5 (102400)
I0601 11:13:14.797595 28894 net.cpp:165] Memory required for data: 7526334496
I0601 11:13:14.797597 28894 layer_factory.hpp:77] Creating layer conv8_1_relu
I0601 11:13:14.797602 28894 net.cpp:100] Creating Layer conv8_1_relu
I0601 11:13:14.797605 28894 net.cpp:434] conv8_1_relu <- conv8_1
I0601 11:13:14.797608 28894 net.cpp:395] conv8_1_relu -> conv8_1 (in-place)
I0601 11:13:14.797612 28894 net.cpp:150] Setting up conv8_1_relu
I0601 11:13:14.797616 28894 net.cpp:157] Top shape: 32 128 5 5 (102400)
I0601 11:13:14.797617 28894 net.cpp:165] Memory required for data: 7526744096
I0601 11:13:14.797619 28894 layer_factory.hpp:77] Creating layer conv8_2
I0601 11:13:14.797623 28894 net.cpp:100] Creating Layer conv8_2
I0601 11:13:14.797626 28894 net.cpp:434] conv8_2 <- conv8_1
I0601 11:13:14.797631 28894 net.cpp:408] conv8_2 -> conv8_2
I0601 11:13:14.799688 28894 net.cpp:150] Setting up conv8_2
I0601 11:13:14.799701 28894 net.cpp:157] Top shape: 32 256 3 3 (73728)
I0601 11:13:14.799705 28894 net.cpp:165] Memory required for data: 7527039008
I0601 11:13:14.799710 28894 layer_factory.hpp:77] Creating layer conv8_2_relu
I0601 11:13:14.799715 28894 net.cpp:100] Creating Layer conv8_2_relu
I0601 11:13:14.799717 28894 net.cpp:434] conv8_2_relu <- conv8_2
I0601 11:13:14.799722 28894 net.cpp:395] conv8_2_relu -> conv8_2 (in-place)
I0601 11:13:14.799729 28894 net.cpp:150] Setting up conv8_2_relu
I0601 11:13:14.799732 28894 net.cpp:157] Top shape: 32 256 3 3 (73728)
I0601 11:13:14.799734 28894 net.cpp:165] Memory required for data: 7527333920
I0601 11:13:14.799737 28894 layer_factory.hpp:77] Creating layer conv8_2_conv8_2_relu_0_split
I0601 11:13:14.799741 28894 net.cpp:100] Creating Layer conv8_2_conv8_2_relu_0_split
I0601 11:13:14.799743 28894 net.cpp:434] conv8_2_conv8_2_relu_0_split <- conv8_2
I0601 11:13:14.799747 28894 net.cpp:408] conv8_2_conv8_2_relu_0_split -> conv8_2_conv8_2_relu_0_split_0
I0601 11:13:14.799752 28894 net.cpp:408] conv8_2_conv8_2_relu_0_split -> conv8_2_conv8_2_relu_0_split_1
I0601 11:13:14.799757 28894 net.cpp:408] conv8_2_conv8_2_relu_0_split -> conv8_2_conv8_2_relu_0_split_2
I0601 11:13:14.799762 28894 net.cpp:408] conv8_2_conv8_2_relu_0_split -> conv8_2_conv8_2_relu_0_split_3
I0601 11:13:14.799816 28894 net.cpp:150] Setting up conv8_2_conv8_2_relu_0_split
I0601 11:13:14.799824 28894 net.cpp:157] Top shape: 32 256 3 3 (73728)
I0601 11:13:14.799827 28894 net.cpp:157] Top shape: 32 256 3 3 (73728)
I0601 11:13:14.799829 28894 net.cpp:157] Top shape: 32 256 3 3 (73728)
I0601 11:13:14.799832 28894 net.cpp:157] Top shape: 32 256 3 3 (73728)
I0601 11:13:14.799834 28894 net.cpp:165] Memory required for data: 7528513568
I0601 11:13:14.799836 28894 layer_factory.hpp:77] Creating layer conv9_1
I0601 11:13:14.799844 28894 net.cpp:100] Creating Layer conv9_1
I0601 11:13:14.799847 28894 net.cpp:434] conv9_1 <- conv8_2_conv8_2_relu_0_split_0
I0601 11:13:14.799854 28894 net.cpp:408] conv9_1 -> conv9_1
I0601 11:13:14.800130 28894 net.cpp:150] Setting up conv9_1
I0601 11:13:14.800137 28894 net.cpp:157] Top shape: 32 128 3 3 (36864)
I0601 11:13:14.800139 28894 net.cpp:165] Memory required for data: 7528661024
I0601 11:13:14.800145 28894 layer_factory.hpp:77] Creating layer conv9_1_relu
I0601 11:13:14.800150 28894 net.cpp:100] Creating Layer conv9_1_relu
I0601 11:13:14.800153 28894 net.cpp:434] conv9_1_relu <- conv9_1
I0601 11:13:14.800155 28894 net.cpp:395] conv9_1_relu -> conv9_1 (in-place)
I0601 11:13:14.800159 28894 net.cpp:150] Setting up conv9_1_relu
I0601 11:13:14.800163 28894 net.cpp:157] Top shape: 32 128 3 3 (36864)
I0601 11:13:14.800164 28894 net.cpp:165] Memory required for data: 7528808480
I0601 11:13:14.800166 28894 layer_factory.hpp:77] Creating layer conv9_2
I0601 11:13:14.800173 28894 net.cpp:100] Creating Layer conv9_2
I0601 11:13:14.800174 28894 net.cpp:434] conv9_2 <- conv9_1
I0601 11:13:14.800179 28894 net.cpp:408] conv9_2 -> conv9_2
I0601 11:13:14.802400 28894 net.cpp:150] Setting up conv9_2
I0601 11:13:14.802410 28894 net.cpp:157] Top shape: 32 256 1 1 (8192)
I0601 11:13:14.802412 28894 net.cpp:165] Memory required for data: 7528841248
I0601 11:13:14.802417 28894 layer_factory.hpp:77] Creating layer conv9_2_relu
I0601 11:13:14.802423 28894 net.cpp:100] Creating Layer conv9_2_relu
I0601 11:13:14.802426 28894 net.cpp:434] conv9_2_relu <- conv9_2
I0601 11:13:14.802430 28894 net.cpp:395] conv9_2_relu -> conv9_2 (in-place)
I0601 11:13:14.802434 28894 net.cpp:150] Setting up conv9_2_relu
I0601 11:13:14.802438 28894 net.cpp:157] Top shape: 32 256 1 1 (8192)
I0601 11:13:14.802439 28894 net.cpp:165] Memory required for data: 7528874016
I0601 11:13:14.802443 28894 layer_factory.hpp:77] Creating layer conv9_2_conv9_2_relu_0_split
I0601 11:13:14.802445 28894 net.cpp:100] Creating Layer conv9_2_conv9_2_relu_0_split
I0601 11:13:14.802448 28894 net.cpp:434] conv9_2_conv9_2_relu_0_split <- conv9_2
I0601 11:13:14.802453 28894 net.cpp:408] conv9_2_conv9_2_relu_0_split -> conv9_2_conv9_2_relu_0_split_0
I0601 11:13:14.802458 28894 net.cpp:408] conv9_2_conv9_2_relu_0_split -> conv9_2_conv9_2_relu_0_split_1
I0601 11:13:14.802461 28894 net.cpp:408] conv9_2_conv9_2_relu_0_split -> conv9_2_conv9_2_relu_0_split_2
I0601 11:13:14.802495 28894 net.cpp:150] Setting up conv9_2_conv9_2_relu_0_split
I0601 11:13:14.802500 28894 net.cpp:157] Top shape: 32 256 1 1 (8192)
I0601 11:13:14.802502 28894 net.cpp:157] Top shape: 32 256 1 1 (8192)
I0601 11:13:14.802505 28894 net.cpp:157] Top shape: 32 256 1 1 (8192)
I0601 11:13:14.802506 28894 net.cpp:165] Memory required for data: 7528972320
I0601 11:13:14.802508 28894 layer_factory.hpp:77] Creating layer conv4_3_norm
I0601 11:13:14.802513 28894 net.cpp:100] Creating Layer conv4_3_norm
I0601 11:13:14.802515 28894 net.cpp:434] conv4_3_norm <- conv4_3_relu4_3_0_split_1
I0601 11:13:14.802520 28894 net.cpp:408] conv4_3_norm -> conv4_3_norm
I0601 11:13:14.802620 28894 net.cpp:150] Setting up conv4_3_norm
I0601 11:13:14.802626 28894 net.cpp:157] Top shape: 32 512 38 38 (23658496)
I0601 11:13:14.802628 28894 net.cpp:165] Memory required for data: 7623606304
I0601 11:13:14.802631 28894 layer_factory.hpp:77] Creating layer conv4_3_norm_conv4_3_norm_0_split
I0601 11:13:14.802634 28894 net.cpp:100] Creating Layer conv4_3_norm_conv4_3_norm_0_split
I0601 11:13:14.802637 28894 net.cpp:434] conv4_3_norm_conv4_3_norm_0_split <- conv4_3_norm
I0601 11:13:14.802650 28894 net.cpp:408] conv4_3_norm_conv4_3_norm_0_split -> conv4_3_norm_conv4_3_norm_0_split_0
I0601 11:13:14.802656 28894 net.cpp:408] conv4_3_norm_conv4_3_norm_0_split -> conv4_3_norm_conv4_3_norm_0_split_1
I0601 11:13:14.802660 28894 net.cpp:408] conv4_3_norm_conv4_3_norm_0_split -> conv4_3_norm_conv4_3_norm_0_split_2
I0601 11:13:14.802690 28894 net.cpp:150] Setting up conv4_3_norm_conv4_3_norm_0_split
I0601 11:13:14.802695 28894 net.cpp:157] Top shape: 32 512 38 38 (23658496)
I0601 11:13:14.802697 28894 net.cpp:157] Top shape: 32 512 38 38 (23658496)
I0601 11:13:14.802700 28894 net.cpp:157] Top shape: 32 512 38 38 (23658496)
I0601 11:13:14.802702 28894 net.cpp:165] Memory required for data: 7907508256
I0601 11:13:14.802705 28894 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_loc
I0601 11:13:14.802711 28894 net.cpp:100] Creating Layer conv4_3_norm_mbox_loc
I0601 11:13:14.802713 28894 net.cpp:434] conv4_3_norm_mbox_loc <- conv4_3_norm_conv4_3_norm_0_split_0
I0601 11:13:14.802717 28894 net.cpp:408] conv4_3_norm_mbox_loc -> conv4_3_norm_mbox_loc
I0601 11:13:14.803165 28894 net.cpp:150] Setting up conv4_3_norm_mbox_loc
I0601 11:13:14.803171 28894 net.cpp:157] Top shape: 32 16 38 38 (739328)
I0601 11:13:14.803174 28894 net.cpp:165] Memory required for data: 7910465568
I0601 11:13:14.803177 28894 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_loc_perm
I0601 11:13:14.803182 28894 net.cpp:100] Creating Layer conv4_3_norm_mbox_loc_perm
I0601 11:13:14.803185 28894 net.cpp:434] conv4_3_norm_mbox_loc_perm <- conv4_3_norm_mbox_loc
I0601 11:13:14.803189 28894 net.cpp:408] conv4_3_norm_mbox_loc_perm -> conv4_3_norm_mbox_loc_perm
I0601 11:13:14.803254 28894 net.cpp:150] Setting up conv4_3_norm_mbox_loc_perm
I0601 11:13:14.803259 28894 net.cpp:157] Top shape: 32 38 38 16 (739328)
I0601 11:13:14.803261 28894 net.cpp:165] Memory required for data: 7913422880
I0601 11:13:14.803263 28894 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_loc_flat
I0601 11:13:14.803267 28894 net.cpp:100] Creating Layer conv4_3_norm_mbox_loc_flat
I0601 11:13:14.803269 28894 net.cpp:434] conv4_3_norm_mbox_loc_flat <- conv4_3_norm_mbox_loc_perm
I0601 11:13:14.803273 28894 net.cpp:408] conv4_3_norm_mbox_loc_flat -> conv4_3_norm_mbox_loc_flat
I0601 11:13:14.803297 28894 net.cpp:150] Setting up conv4_3_norm_mbox_loc_flat
I0601 11:13:14.803303 28894 net.cpp:157] Top shape: 32 23104 (739328)
I0601 11:13:14.803305 28894 net.cpp:165] Memory required for data: 7916380192
I0601 11:13:14.803308 28894 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_conf
I0601 11:13:14.803318 28894 net.cpp:100] Creating Layer conv4_3_norm_mbox_conf
I0601 11:13:14.803321 28894 net.cpp:434] conv4_3_norm_mbox_conf <- conv4_3_norm_conv4_3_norm_0_split_1
I0601 11:13:14.803325 28894 net.cpp:408] conv4_3_norm_mbox_conf -> conv4_3_norm_mbox_conf
I0601 11:13:14.803799 28894 net.cpp:150] Setting up conv4_3_norm_mbox_conf
I0601 11:13:14.803807 28894 net.cpp:157] Top shape: 32 16 38 38 (739328)
I0601 11:13:14.803809 28894 net.cpp:165] Memory required for data: 7919337504
I0601 11:13:14.803813 28894 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_conf_perm
I0601 11:13:14.803817 28894 net.cpp:100] Creating Layer conv4_3_norm_mbox_conf_perm
I0601 11:13:14.803820 28894 net.cpp:434] conv4_3_norm_mbox_conf_perm <- conv4_3_norm_mbox_conf
I0601 11:13:14.803824 28894 net.cpp:408] conv4_3_norm_mbox_conf_perm -> conv4_3_norm_mbox_conf_perm
I0601 11:13:14.803885 28894 net.cpp:150] Setting up conv4_3_norm_mbox_conf_perm
I0601 11:13:14.803890 28894 net.cpp:157] Top shape: 32 38 38 16 (739328)
I0601 11:13:14.803892 28894 net.cpp:165] Memory required for data: 7922294816
I0601 11:13:14.803894 28894 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_conf_flat
I0601 11:13:14.803899 28894 net.cpp:100] Creating Layer conv4_3_norm_mbox_conf_flat
I0601 11:13:14.803901 28894 net.cpp:434] conv4_3_norm_mbox_conf_flat <- conv4_3_norm_mbox_conf_perm
I0601 11:13:14.803905 28894 net.cpp:408] conv4_3_norm_mbox_conf_flat -> conv4_3_norm_mbox_conf_flat
I0601 11:13:14.803927 28894 net.cpp:150] Setting up conv4_3_norm_mbox_conf_flat
I0601 11:13:14.803932 28894 net.cpp:157] Top shape: 32 23104 (739328)
I0601 11:13:14.803935 28894 net.cpp:165] Memory required for data: 7925252128
I0601 11:13:14.803936 28894 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_priorbox
I0601 11:13:14.803942 28894 net.cpp:100] Creating Layer conv4_3_norm_mbox_priorbox
I0601 11:13:14.803946 28894 net.cpp:434] conv4_3_norm_mbox_priorbox <- conv4_3_norm_conv4_3_norm_0_split_2
I0601 11:13:14.803951 28894 net.cpp:434] conv4_3_norm_mbox_priorbox <- data_data_0_split_1
I0601 11:13:14.803953 28894 net.cpp:408] conv4_3_norm_mbox_priorbox -> conv4_3_norm_mbox_priorbox
I0601 11:13:14.803972 28894 net.cpp:150] Setting up conv4_3_norm_mbox_priorbox
I0601 11:13:14.803977 28894 net.cpp:157] Top shape: 1 2 23104 (46208)
I0601 11:13:14.803979 28894 net.cpp:165] Memory required for data: 7925436960
I0601 11:13:14.803982 28894 layer_factory.hpp:77] Creating layer fc7_mbox_loc
I0601 11:13:14.803988 28894 net.cpp:100] Creating Layer fc7_mbox_loc
I0601 11:13:14.803992 28894 net.cpp:434] fc7_mbox_loc <- fc7_relu7_0_split_1
I0601 11:13:14.803997 28894 net.cpp:408] fc7_mbox_loc -> fc7_mbox_loc
I0601 11:13:14.805063 28894 net.cpp:150] Setting up fc7_mbox_loc
I0601 11:13:14.805069 28894 net.cpp:157] Top shape: 32 24 19 19 (277248)
I0601 11:13:14.805073 28894 net.cpp:165] Memory required for data: 7926545952
I0601 11:13:14.805076 28894 layer_factory.hpp:77] Creating layer fc7_mbox_loc_perm
I0601 11:13:14.805081 28894 net.cpp:100] Creating Layer fc7_mbox_loc_perm
I0601 11:13:14.805084 28894 net.cpp:434] fc7_mbox_loc_perm <- fc7_mbox_loc
I0601 11:13:14.805088 28894 net.cpp:408] fc7_mbox_loc_perm -> fc7_mbox_loc_perm
I0601 11:13:14.805150 28894 net.cpp:150] Setting up fc7_mbox_loc_perm
I0601 11:13:14.805155 28894 net.cpp:157] Top shape: 32 19 19 24 (277248)
I0601 11:13:14.805156 28894 net.cpp:165] Memory required for data: 7927654944
I0601 11:13:14.805160 28894 layer_factory.hpp:77] Creating layer fc7_mbox_loc_flat
I0601 11:13:14.805163 28894 net.cpp:100] Creating Layer fc7_mbox_loc_flat
I0601 11:13:14.805166 28894 net.cpp:434] fc7_mbox_loc_flat <- fc7_mbox_loc_perm
I0601 11:13:14.805169 28894 net.cpp:408] fc7_mbox_loc_flat -> fc7_mbox_loc_flat
I0601 11:13:14.805187 28894 net.cpp:150] Setting up fc7_mbox_loc_flat
I0601 11:13:14.805191 28894 net.cpp:157] Top shape: 32 8664 (277248)
I0601 11:13:14.805193 28894 net.cpp:165] Memory required for data: 7928763936
I0601 11:13:14.805196 28894 layer_factory.hpp:77] Creating layer fc7_mbox_conf
I0601 11:13:14.805202 28894 net.cpp:100] Creating Layer fc7_mbox_conf
I0601 11:13:14.805207 28894 net.cpp:434] fc7_mbox_conf <- fc7_relu7_0_split_2
I0601 11:13:14.805212 28894 net.cpp:408] fc7_mbox_conf -> fc7_mbox_conf
I0601 11:13:14.806259 28894 net.cpp:150] Setting up fc7_mbox_conf
I0601 11:13:14.806267 28894 net.cpp:157] Top shape: 32 24 19 19 (277248)
I0601 11:13:14.806268 28894 net.cpp:165] Memory required for data: 7929872928
I0601 11:13:14.806272 28894 layer_factory.hpp:77] Creating layer fc7_mbox_conf_perm
I0601 11:13:14.806277 28894 net.cpp:100] Creating Layer fc7_mbox_conf_perm
I0601 11:13:14.806279 28894 net.cpp:434] fc7_mbox_conf_perm <- fc7_mbox_conf
I0601 11:13:14.806283 28894 net.cpp:408] fc7_mbox_conf_perm -> fc7_mbox_conf_perm
I0601 11:13:14.806345 28894 net.cpp:150] Setting up fc7_mbox_conf_perm
I0601 11:13:14.806350 28894 net.cpp:157] Top shape: 32 19 19 24 (277248)
I0601 11:13:14.806352 28894 net.cpp:165] Memory required for data: 7930981920
I0601 11:13:14.806354 28894 layer_factory.hpp:77] Creating layer fc7_mbox_conf_flat
I0601 11:13:14.806358 28894 net.cpp:100] Creating Layer fc7_mbox_conf_flat
I0601 11:13:14.806361 28894 net.cpp:434] fc7_mbox_conf_flat <- fc7_mbox_conf_perm
I0601 11:13:14.806366 28894 net.cpp:408] fc7_mbox_conf_flat -> fc7_mbox_conf_flat
I0601 11:13:14.806380 28894 net.cpp:150] Setting up fc7_mbox_conf_flat
I0601 11:13:14.806385 28894 net.cpp:157] Top shape: 32 8664 (277248)
I0601 11:13:14.806386 28894 net.cpp:165] Memory required for data: 7932090912
I0601 11:13:14.806396 28894 layer_factory.hpp:77] Creating layer fc7_mbox_priorbox
I0601 11:13:14.806401 28894 net.cpp:100] Creating Layer fc7_mbox_priorbox
I0601 11:13:14.806404 28894 net.cpp:434] fc7_mbox_priorbox <- fc7_relu7_0_split_3
I0601 11:13:14.806407 28894 net.cpp:434] fc7_mbox_priorbox <- data_data_0_split_2
I0601 11:13:14.806412 28894 net.cpp:408] fc7_mbox_priorbox -> fc7_mbox_priorbox
I0601 11:13:14.806428 28894 net.cpp:150] Setting up fc7_mbox_priorbox
I0601 11:13:14.806433 28894 net.cpp:157] Top shape: 1 2 8664 (17328)
I0601 11:13:14.806435 28894 net.cpp:165] Memory required for data: 7932160224
I0601 11:13:14.806437 28894 layer_factory.hpp:77] Creating layer conv6_2_mbox_loc
I0601 11:13:14.806445 28894 net.cpp:100] Creating Layer conv6_2_mbox_loc
I0601 11:13:14.806449 28894 net.cpp:434] conv6_2_mbox_loc <- conv6_2_conv6_2_relu_0_split_1
I0601 11:13:14.806453 28894 net.cpp:408] conv6_2_mbox_loc -> conv6_2_mbox_loc
I0601 11:13:14.807047 28894 net.cpp:150] Setting up conv6_2_mbox_loc
I0601 11:13:14.807055 28894 net.cpp:157] Top shape: 32 24 10 10 (76800)
I0601 11:13:14.807059 28894 net.cpp:165] Memory required for data: 7932467424
I0601 11:13:14.807065 28894 layer_factory.hpp:77] Creating layer conv6_2_mbox_loc_perm
I0601 11:13:14.807073 28894 net.cpp:100] Creating Layer conv6_2_mbox_loc_perm
I0601 11:13:14.807077 28894 net.cpp:434] conv6_2_mbox_loc_perm <- conv6_2_mbox_loc
I0601 11:13:14.807081 28894 net.cpp:408] conv6_2_mbox_loc_perm -> conv6_2_mbox_loc_perm
I0601 11:13:14.807145 28894 net.cpp:150] Setting up conv6_2_mbox_loc_perm
I0601 11:13:14.807150 28894 net.cpp:157] Top shape: 32 10 10 24 (76800)
I0601 11:13:14.807152 28894 net.cpp:165] Memory required for data: 7932774624
I0601 11:13:14.807154 28894 layer_factory.hpp:77] Creating layer conv6_2_mbox_loc_flat
I0601 11:13:14.807157 28894 net.cpp:100] Creating Layer conv6_2_mbox_loc_flat
I0601 11:13:14.807160 28894 net.cpp:434] conv6_2_mbox_loc_flat <- conv6_2_mbox_loc_perm
I0601 11:13:14.807164 28894 net.cpp:408] conv6_2_mbox_loc_flat -> conv6_2_mbox_loc_flat
I0601 11:13:14.807178 28894 net.cpp:150] Setting up conv6_2_mbox_loc_flat
I0601 11:13:14.807183 28894 net.cpp:157] Top shape: 32 2400 (76800)
I0601 11:13:14.807185 28894 net.cpp:165] Memory required for data: 7933081824
I0601 11:13:14.807188 28894 layer_factory.hpp:77] Creating layer conv6_2_mbox_conf
I0601 11:13:14.807193 28894 net.cpp:100] Creating Layer conv6_2_mbox_conf
I0601 11:13:14.807195 28894 net.cpp:434] conv6_2_mbox_conf <- conv6_2_conv6_2_relu_0_split_2
I0601 11:13:14.807200 28894 net.cpp:408] conv6_2_mbox_conf -> conv6_2_mbox_conf
I0601 11:13:14.807802 28894 net.cpp:150] Setting up conv6_2_mbox_conf
I0601 11:13:14.807808 28894 net.cpp:157] Top shape: 32 24 10 10 (76800)
I0601 11:13:14.807811 28894 net.cpp:165] Memory required for data: 7933389024
I0601 11:13:14.807814 28894 layer_factory.hpp:77] Creating layer conv6_2_mbox_conf_perm
I0601 11:13:14.807819 28894 net.cpp:100] Creating Layer conv6_2_mbox_conf_perm
I0601 11:13:14.807822 28894 net.cpp:434] conv6_2_mbox_conf_perm <- conv6_2_mbox_conf
I0601 11:13:14.807826 28894 net.cpp:408] conv6_2_mbox_conf_perm -> conv6_2_mbox_conf_perm
I0601 11:13:14.807891 28894 net.cpp:150] Setting up conv6_2_mbox_conf_perm
I0601 11:13:14.807896 28894 net.cpp:157] Top shape: 32 10 10 24 (76800)
I0601 11:13:14.807898 28894 net.cpp:165] Memory required for data: 7933696224
I0601 11:13:14.807900 28894 layer_factory.hpp:77] Creating layer conv6_2_mbox_conf_flat
I0601 11:13:14.807905 28894 net.cpp:100] Creating Layer conv6_2_mbox_conf_flat
I0601 11:13:14.807907 28894 net.cpp:434] conv6_2_mbox_conf_flat <- conv6_2_mbox_conf_perm
I0601 11:13:14.807911 28894 net.cpp:408] conv6_2_mbox_conf_flat -> conv6_2_mbox_conf_flat
I0601 11:13:14.807925 28894 net.cpp:150] Setting up conv6_2_mbox_conf_flat
I0601 11:13:14.807930 28894 net.cpp:157] Top shape: 32 2400 (76800)
I0601 11:13:14.807932 28894 net.cpp:165] Memory required for data: 7934003424
I0601 11:13:14.807934 28894 layer_factory.hpp:77] Creating layer conv6_2_mbox_priorbox
I0601 11:13:14.807945 28894 net.cpp:100] Creating Layer conv6_2_mbox_priorbox
I0601 11:13:14.807950 28894 net.cpp:434] conv6_2_mbox_priorbox <- conv6_2_conv6_2_relu_0_split_3
I0601 11:13:14.807952 28894 net.cpp:434] conv6_2_mbox_priorbox <- data_data_0_split_3
I0601 11:13:14.807956 28894 net.cpp:408] conv6_2_mbox_priorbox -> conv6_2_mbox_priorbox
I0601 11:13:14.807972 28894 net.cpp:150] Setting up conv6_2_mbox_priorbox
I0601 11:13:14.807977 28894 net.cpp:157] Top shape: 1 2 2400 (4800)
I0601 11:13:14.807979 28894 net.cpp:165] Memory required for data: 7934022624
I0601 11:13:14.807981 28894 layer_factory.hpp:77] Creating layer conv7_2_mbox_loc
I0601 11:13:14.807987 28894 net.cpp:100] Creating Layer conv7_2_mbox_loc
I0601 11:13:14.807991 28894 net.cpp:434] conv7_2_mbox_loc <- conv7_2_conv7_2_relu_0_split_1
I0601 11:13:14.807996 28894 net.cpp:408] conv7_2_mbox_loc -> conv7_2_mbox_loc
I0601 11:13:14.808377 28894 net.cpp:150] Setting up conv7_2_mbox_loc
I0601 11:13:14.808382 28894 net.cpp:157] Top shape: 32 24 5 5 (19200)
I0601 11:13:14.808385 28894 net.cpp:165] Memory required for data: 7934099424
I0601 11:13:14.808404 28894 layer_factory.hpp:77] Creating layer conv7_2_mbox_loc_perm
I0601 11:13:14.808410 28894 net.cpp:100] Creating Layer conv7_2_mbox_loc_perm
I0601 11:13:14.808413 28894 net.cpp:434] conv7_2_mbox_loc_perm <- conv7_2_mbox_loc
I0601 11:13:14.808418 28894 net.cpp:408] conv7_2_mbox_loc_perm -> conv7_2_mbox_loc_perm
I0601 11:13:14.808498 28894 net.cpp:150] Setting up conv7_2_mbox_loc_perm
I0601 11:13:14.808503 28894 net.cpp:157] Top shape: 32 5 5 24 (19200)
I0601 11:13:14.808506 28894 net.cpp:165] Memory required for data: 7934176224
I0601 11:13:14.808508 28894 layer_factory.hpp:77] Creating layer conv7_2_mbox_loc_flat
I0601 11:13:14.808512 28894 net.cpp:100] Creating Layer conv7_2_mbox_loc_flat
I0601 11:13:14.808514 28894 net.cpp:434] conv7_2_mbox_loc_flat <- conv7_2_mbox_loc_perm
I0601 11:13:14.808518 28894 net.cpp:408] conv7_2_mbox_loc_flat -> conv7_2_mbox_loc_flat
I0601 11:13:14.808532 28894 net.cpp:150] Setting up conv7_2_mbox_loc_flat
I0601 11:13:14.808537 28894 net.cpp:157] Top shape: 32 600 (19200)
I0601 11:13:14.808538 28894 net.cpp:165] Memory required for data: 7934253024
I0601 11:13:14.808540 28894 layer_factory.hpp:77] Creating layer conv7_2_mbox_conf
I0601 11:13:14.808547 28894 net.cpp:100] Creating Layer conv7_2_mbox_conf
I0601 11:13:14.808552 28894 net.cpp:434] conv7_2_mbox_conf <- conv7_2_conv7_2_relu_0_split_2
I0601 11:13:14.808555 28894 net.cpp:408] conv7_2_mbox_conf -> conv7_2_mbox_conf
I0601 11:13:14.808928 28894 net.cpp:150] Setting up conv7_2_mbox_conf
I0601 11:13:14.808934 28894 net.cpp:157] Top shape: 32 24 5 5 (19200)
I0601 11:13:14.808938 28894 net.cpp:165] Memory required for data: 7934329824
I0601 11:13:14.808940 28894 layer_factory.hpp:77] Creating layer conv7_2_mbox_conf_perm
I0601 11:13:14.808945 28894 net.cpp:100] Creating Layer conv7_2_mbox_conf_perm
I0601 11:13:14.808949 28894 net.cpp:434] conv7_2_mbox_conf_perm <- conv7_2_mbox_conf
I0601 11:13:14.808953 28894 net.cpp:408] conv7_2_mbox_conf_perm -> conv7_2_mbox_conf_perm
I0601 11:13:14.809015 28894 net.cpp:150] Setting up conv7_2_mbox_conf_perm
I0601 11:13:14.809020 28894 net.cpp:157] Top shape: 32 5 5 24 (19200)
I0601 11:13:14.809021 28894 net.cpp:165] Memory required for data: 7934406624
I0601 11:13:14.809023 28894 layer_factory.hpp:77] Creating layer conv7_2_mbox_conf_flat
I0601 11:13:14.809026 28894 net.cpp:100] Creating Layer conv7_2_mbox_conf_flat
I0601 11:13:14.809029 28894 net.cpp:434] conv7_2_mbox_conf_flat <- conv7_2_mbox_conf_perm
I0601 11:13:14.809033 28894 net.cpp:408] conv7_2_mbox_conf_flat -> conv7_2_mbox_conf_flat
I0601 11:13:14.809048 28894 net.cpp:150] Setting up conv7_2_mbox_conf_flat
I0601 11:13:14.809052 28894 net.cpp:157] Top shape: 32 600 (19200)
I0601 11:13:14.809054 28894 net.cpp:165] Memory required for data: 7934483424
I0601 11:13:14.809056 28894 layer_factory.hpp:77] Creating layer conv7_2_mbox_priorbox
I0601 11:13:14.809061 28894 net.cpp:100] Creating Layer conv7_2_mbox_priorbox
I0601 11:13:14.809062 28894 net.cpp:434] conv7_2_mbox_priorbox <- conv7_2_conv7_2_relu_0_split_3
I0601 11:13:14.809072 28894 net.cpp:434] conv7_2_mbox_priorbox <- data_data_0_split_4
I0601 11:13:14.809077 28894 net.cpp:408] conv7_2_mbox_priorbox -> conv7_2_mbox_priorbox
I0601 11:13:14.809095 28894 net.cpp:150] Setting up conv7_2_mbox_priorbox
I0601 11:13:14.809100 28894 net.cpp:157] Top shape: 1 2 600 (1200)
I0601 11:13:14.809103 28894 net.cpp:165] Memory required for data: 7934488224
I0601 11:13:14.809104 28894 layer_factory.hpp:77] Creating layer conv8_2_mbox_loc
I0601 11:13:14.809111 28894 net.cpp:100] Creating Layer conv8_2_mbox_loc
I0601 11:13:14.809115 28894 net.cpp:434] conv8_2_mbox_loc <- conv8_2_conv8_2_relu_0_split_1
I0601 11:13:14.809120 28894 net.cpp:408] conv8_2_mbox_loc -> conv8_2_mbox_loc
I0601 11:13:14.809414 28894 net.cpp:150] Setting up conv8_2_mbox_loc
I0601 11:13:14.809420 28894 net.cpp:157] Top shape: 32 16 3 3 (4608)
I0601 11:13:14.809422 28894 net.cpp:165] Memory required for data: 7934506656
I0601 11:13:14.809432 28894 layer_factory.hpp:77] Creating layer conv8_2_mbox_loc_perm
I0601 11:13:14.809437 28894 net.cpp:100] Creating Layer conv8_2_mbox_loc_perm
I0601 11:13:14.809442 28894 net.cpp:434] conv8_2_mbox_loc_perm <- conv8_2_mbox_loc
I0601 11:13:14.809445 28894 net.cpp:408] conv8_2_mbox_loc_perm -> conv8_2_mbox_loc_perm
I0601 11:13:14.809509 28894 net.cpp:150] Setting up conv8_2_mbox_loc_perm
I0601 11:13:14.809514 28894 net.cpp:157] Top shape: 32 3 3 16 (4608)
I0601 11:13:14.809516 28894 net.cpp:165] Memory required for data: 7934525088
I0601 11:13:14.809518 28894 layer_factory.hpp:77] Creating layer conv8_2_mbox_loc_flat
I0601 11:13:14.809521 28894 net.cpp:100] Creating Layer conv8_2_mbox_loc_flat
I0601 11:13:14.809525 28894 net.cpp:434] conv8_2_mbox_loc_flat <- conv8_2_mbox_loc_perm
I0601 11:13:14.809530 28894 net.cpp:408] conv8_2_mbox_loc_flat -> conv8_2_mbox_loc_flat
I0601 11:13:14.809542 28894 net.cpp:150] Setting up conv8_2_mbox_loc_flat
I0601 11:13:14.809548 28894 net.cpp:157] Top shape: 32 144 (4608)
I0601 11:13:14.809551 28894 net.cpp:165] Memory required for data: 7934543520
I0601 11:13:14.809552 28894 layer_factory.hpp:77] Creating layer conv8_2_mbox_conf
I0601 11:13:14.809557 28894 net.cpp:100] Creating Layer conv8_2_mbox_conf
I0601 11:13:14.809561 28894 net.cpp:434] conv8_2_mbox_conf <- conv8_2_conv8_2_relu_0_split_2
I0601 11:13:14.809566 28894 net.cpp:408] conv8_2_mbox_conf -> conv8_2_mbox_conf
I0601 11:13:14.809864 28894 net.cpp:150] Setting up conv8_2_mbox_conf
I0601 11:13:14.809870 28894 net.cpp:157] Top shape: 32 16 3 3 (4608)
I0601 11:13:14.809872 28894 net.cpp:165] Memory required for data: 7934561952
I0601 11:13:14.809875 28894 layer_factory.hpp:77] Creating layer conv8_2_mbox_conf_perm
I0601 11:13:14.809880 28894 net.cpp:100] Creating Layer conv8_2_mbox_conf_perm
I0601 11:13:14.809881 28894 net.cpp:434] conv8_2_mbox_conf_perm <- conv8_2_mbox_conf
I0601 11:13:14.809886 28894 net.cpp:408] conv8_2_mbox_conf_perm -> conv8_2_mbox_conf_perm
I0601 11:13:14.809949 28894 net.cpp:150] Setting up conv8_2_mbox_conf_perm
I0601 11:13:14.809954 28894 net.cpp:157] Top shape: 32 3 3 16 (4608)
I0601 11:13:14.809957 28894 net.cpp:165] Memory required for data: 7934580384
I0601 11:13:14.809958 28894 layer_factory.hpp:77] Creating layer conv8_2_mbox_conf_flat
I0601 11:13:14.809962 28894 net.cpp:100] Creating Layer conv8_2_mbox_conf_flat
I0601 11:13:14.809964 28894 net.cpp:434] conv8_2_mbox_conf_flat <- conv8_2_mbox_conf_perm
I0601 11:13:14.809968 28894 net.cpp:408] conv8_2_mbox_conf_flat -> conv8_2_mbox_conf_flat
I0601 11:13:14.809983 28894 net.cpp:150] Setting up conv8_2_mbox_conf_flat
I0601 11:13:14.809988 28894 net.cpp:157] Top shape: 32 144 (4608)
I0601 11:13:14.809989 28894 net.cpp:165] Memory required for data: 7934598816
I0601 11:13:14.809990 28894 layer_factory.hpp:77] Creating layer conv8_2_mbox_priorbox
I0601 11:13:14.809995 28894 net.cpp:100] Creating Layer conv8_2_mbox_priorbox
I0601 11:13:14.809998 28894 net.cpp:434] conv8_2_mbox_priorbox <- conv8_2_conv8_2_relu_0_split_3
I0601 11:13:14.810000 28894 net.cpp:434] conv8_2_mbox_priorbox <- data_data_0_split_5
I0601 11:13:14.810012 28894 net.cpp:408] conv8_2_mbox_priorbox -> conv8_2_mbox_priorbox
I0601 11:13:14.810029 28894 net.cpp:150] Setting up conv8_2_mbox_priorbox
I0601 11:13:14.810034 28894 net.cpp:157] Top shape: 1 2 144 (288)
I0601 11:13:14.810036 28894 net.cpp:165] Memory required for data: 7934599968
I0601 11:13:14.810039 28894 layer_factory.hpp:77] Creating layer conv9_2_mbox_loc
I0601 11:13:14.810045 28894 net.cpp:100] Creating Layer conv9_2_mbox_loc
I0601 11:13:14.810050 28894 net.cpp:434] conv9_2_mbox_loc <- conv9_2_conv9_2_relu_0_split_0
I0601 11:13:14.810053 28894 net.cpp:408] conv9_2_mbox_loc -> conv9_2_mbox_loc
I0601 11:13:14.810362 28894 net.cpp:150] Setting up conv9_2_mbox_loc
I0601 11:13:14.810369 28894 net.cpp:157] Top shape: 32 16 1 1 (512)
I0601 11:13:14.810371 28894 net.cpp:165] Memory required for data: 7934602016
I0601 11:13:14.810375 28894 layer_factory.hpp:77] Creating layer conv9_2_mbox_loc_perm
I0601 11:13:14.810379 28894 net.cpp:100] Creating Layer conv9_2_mbox_loc_perm
I0601 11:13:14.810381 28894 net.cpp:434] conv9_2_mbox_loc_perm <- conv9_2_mbox_loc
I0601 11:13:14.810385 28894 net.cpp:408] conv9_2_mbox_loc_perm -> conv9_2_mbox_loc_perm
I0601 11:13:14.810446 28894 net.cpp:150] Setting up conv9_2_mbox_loc_perm
I0601 11:13:14.810449 28894 net.cpp:157] Top shape: 32 1 1 16 (512)
I0601 11:13:14.810451 28894 net.cpp:165] Memory required for data: 7934604064
I0601 11:13:14.810454 28894 layer_factory.hpp:77] Creating layer conv9_2_mbox_loc_flat
I0601 11:13:14.810457 28894 net.cpp:100] Creating Layer conv9_2_mbox_loc_flat
I0601 11:13:14.810461 28894 net.cpp:434] conv9_2_mbox_loc_flat <- conv9_2_mbox_loc_perm
I0601 11:13:14.810463 28894 net.cpp:408] conv9_2_mbox_loc_flat -> conv9_2_mbox_loc_flat
I0601 11:13:14.810478 28894 net.cpp:150] Setting up conv9_2_mbox_loc_flat
I0601 11:13:14.810482 28894 net.cpp:157] Top shape: 32 16 (512)
I0601 11:13:14.810484 28894 net.cpp:165] Memory required for data: 7934606112
I0601 11:13:14.810487 28894 layer_factory.hpp:77] Creating layer conv9_2_mbox_conf
I0601 11:13:14.810492 28894 net.cpp:100] Creating Layer conv9_2_mbox_conf
I0601 11:13:14.810495 28894 net.cpp:434] conv9_2_mbox_conf <- conv9_2_conv9_2_relu_0_split_1
I0601 11:13:14.810499 28894 net.cpp:408] conv9_2_mbox_conf -> conv9_2_mbox_conf
I0601 11:13:14.810809 28894 net.cpp:150] Setting up conv9_2_mbox_conf
I0601 11:13:14.810817 28894 net.cpp:157] Top shape: 32 16 1 1 (512)
I0601 11:13:14.810818 28894 net.cpp:165] Memory required for data: 7934608160
I0601 11:13:14.810822 28894 layer_factory.hpp:77] Creating layer conv9_2_mbox_conf_perm
I0601 11:13:14.810827 28894 net.cpp:100] Creating Layer conv9_2_mbox_conf_perm
I0601 11:13:14.810829 28894 net.cpp:434] conv9_2_mbox_conf_perm <- conv9_2_mbox_conf
I0601 11:13:14.810837 28894 net.cpp:408] conv9_2_mbox_conf_perm -> conv9_2_mbox_conf_perm
I0601 11:13:14.810897 28894 net.cpp:150] Setting up conv9_2_mbox_conf_perm
I0601 11:13:14.810902 28894 net.cpp:157] Top shape: 32 1 1 16 (512)
I0601 11:13:14.810904 28894 net.cpp:165] Memory required for data: 7934610208
I0601 11:13:14.810907 28894 layer_factory.hpp:77] Creating layer conv9_2_mbox_conf_flat
I0601 11:13:14.810910 28894 net.cpp:100] Creating Layer conv9_2_mbox_conf_flat
I0601 11:13:14.810912 28894 net.cpp:434] conv9_2_mbox_conf_flat <- conv9_2_mbox_conf_perm
I0601 11:13:14.810916 28894 net.cpp:408] conv9_2_mbox_conf_flat -> conv9_2_mbox_conf_flat
I0601 11:13:14.810930 28894 net.cpp:150] Setting up conv9_2_mbox_conf_flat
I0601 11:13:14.810935 28894 net.cpp:157] Top shape: 32 16 (512)
I0601 11:13:14.810936 28894 net.cpp:165] Memory required for data: 7934612256
I0601 11:13:14.810938 28894 layer_factory.hpp:77] Creating layer conv9_2_mbox_priorbox
I0601 11:13:14.810943 28894 net.cpp:100] Creating Layer conv9_2_mbox_priorbox
I0601 11:13:14.810945 28894 net.cpp:434] conv9_2_mbox_priorbox <- conv9_2_conv9_2_relu_0_split_2
I0601 11:13:14.810948 28894 net.cpp:434] conv9_2_mbox_priorbox <- data_data_0_split_6
I0601 11:13:14.810953 28894 net.cpp:408] conv9_2_mbox_priorbox -> conv9_2_mbox_priorbox
I0601 11:13:14.810976 28894 net.cpp:150] Setting up conv9_2_mbox_priorbox
I0601 11:13:14.810981 28894 net.cpp:157] Top shape: 1 2 16 (32)
I0601 11:13:14.810982 28894 net.cpp:165] Memory required for data: 7934612384
I0601 11:13:14.810984 28894 layer_factory.hpp:77] Creating layer mbox_loc
I0601 11:13:14.810989 28894 net.cpp:100] Creating Layer mbox_loc
I0601 11:13:14.810992 28894 net.cpp:434] mbox_loc <- conv4_3_norm_mbox_loc_flat
I0601 11:13:14.810995 28894 net.cpp:434] mbox_loc <- fc7_mbox_loc_flat
I0601 11:13:14.810998 28894 net.cpp:434] mbox_loc <- conv6_2_mbox_loc_flat
I0601 11:13:14.811002 28894 net.cpp:434] mbox_loc <- conv7_2_mbox_loc_flat
I0601 11:13:14.811004 28894 net.cpp:434] mbox_loc <- conv8_2_mbox_loc_flat
I0601 11:13:14.811007 28894 net.cpp:434] mbox_loc <- conv9_2_mbox_loc_flat
I0601 11:13:14.811010 28894 net.cpp:408] mbox_loc -> mbox_loc
I0601 11:13:14.811029 28894 net.cpp:150] Setting up mbox_loc
I0601 11:13:14.811033 28894 net.cpp:157] Top shape: 32 34928 (1117696)
I0601 11:13:14.811036 28894 net.cpp:165] Memory required for data: 7939083168
I0601 11:13:14.811038 28894 layer_factory.hpp:77] Creating layer mbox_conf
I0601 11:13:14.811043 28894 net.cpp:100] Creating Layer mbox_conf
I0601 11:13:14.811044 28894 net.cpp:434] mbox_conf <- conv4_3_norm_mbox_conf_flat
I0601 11:13:14.811048 28894 net.cpp:434] mbox_conf <- fc7_mbox_conf_flat
I0601 11:13:14.811050 28894 net.cpp:434] mbox_conf <- conv6_2_mbox_conf_flat
I0601 11:13:14.811053 28894 net.cpp:434] mbox_conf <- conv7_2_mbox_conf_flat
I0601 11:13:14.811055 28894 net.cpp:434] mbox_conf <- conv8_2_mbox_conf_flat
I0601 11:13:14.811058 28894 net.cpp:434] mbox_conf <- conv9_2_mbox_conf_flat
I0601 11:13:14.811061 28894 net.cpp:408] mbox_conf -> mbox_conf
I0601 11:13:14.811077 28894 net.cpp:150] Setting up mbox_conf
I0601 11:13:14.811081 28894 net.cpp:157] Top shape: 32 34928 (1117696)
I0601 11:13:14.811084 28894 net.cpp:165] Memory required for data: 7943553952
I0601 11:13:14.811085 28894 layer_factory.hpp:77] Creating layer mbox_priorbox
I0601 11:13:14.811089 28894 net.cpp:100] Creating Layer mbox_priorbox
I0601 11:13:14.811091 28894 net.cpp:434] mbox_priorbox <- conv4_3_norm_mbox_priorbox
I0601 11:13:14.811094 28894 net.cpp:434] mbox_priorbox <- fc7_mbox_priorbox
I0601 11:13:14.811096 28894 net.cpp:434] mbox_priorbox <- conv6_2_mbox_priorbox
I0601 11:13:14.811100 28894 net.cpp:434] mbox_priorbox <- conv7_2_mbox_priorbox
I0601 11:13:14.811102 28894 net.cpp:434] mbox_priorbox <- conv8_2_mbox_priorbox
I0601 11:13:14.811105 28894 net.cpp:434] mbox_priorbox <- conv9_2_mbox_priorbox
I0601 11:13:14.811107 28894 net.cpp:408] mbox_priorbox -> mbox_priorbox
I0601 11:13:14.811123 28894 net.cpp:150] Setting up mbox_priorbox
I0601 11:13:14.811127 28894 net.cpp:157] Top shape: 1 2 34928 (69856)
I0601 11:13:14.811130 28894 net.cpp:165] Memory required for data: 7943833376
I0601 11:13:14.811131 28894 layer_factory.hpp:77] Creating layer mbox_loss
I0601 11:13:14.811141 28894 net.cpp:100] Creating Layer mbox_loss
I0601 11:13:14.811143 28894 net.cpp:434] mbox_loss <- mbox_loc
I0601 11:13:14.811146 28894 net.cpp:434] mbox_loss <- mbox_conf
I0601 11:13:14.811148 28894 net.cpp:434] mbox_loss <- mbox_priorbox
I0601 11:13:14.811151 28894 net.cpp:434] mbox_loss <- label
I0601 11:13:14.811156 28894 net.cpp:408] mbox_loss -> mbox_loss
I0601 11:13:14.811193 28894 layer_factory.hpp:77] Creating layer mbox_loss_smooth_L1_loc
I0601 11:13:14.811251 28894 layer_factory.hpp:77] Creating layer mbox_loss_softmax_conf
I0601 11:13:14.811260 28894 layer_factory.hpp:77] Creating layer mbox_loss_softmax_conf
I0601 11:13:14.811323 28894 net.cpp:150] Setting up mbox_loss
I0601 11:13:14.811327 28894 net.cpp:157] Top shape: (1)
I0601 11:13:14.811329 28894 net.cpp:160]     with loss weight 1
I0601 11:13:14.811347 28894 net.cpp:165] Memory required for data: 7943833380
I0601 11:13:14.811348 28894 net.cpp:226] mbox_loss needs backward computation.
I0601 11:13:14.811354 28894 net.cpp:228] mbox_priorbox does not need backward computation.
I0601 11:13:14.811358 28894 net.cpp:226] mbox_conf needs backward computation.
I0601 11:13:14.811370 28894 net.cpp:226] mbox_loc needs backward computation.
I0601 11:13:14.811374 28894 net.cpp:228] conv9_2_mbox_priorbox does not need backward computation.
I0601 11:13:14.811378 28894 net.cpp:226] conv9_2_mbox_conf_flat needs backward computation.
I0601 11:13:14.811380 28894 net.cpp:226] conv9_2_mbox_conf_perm needs backward computation.
I0601 11:13:14.811384 28894 net.cpp:226] conv9_2_mbox_conf needs backward computation.
I0601 11:13:14.811386 28894 net.cpp:226] conv9_2_mbox_loc_flat needs backward computation.
I0601 11:13:14.811389 28894 net.cpp:226] conv9_2_mbox_loc_perm needs backward computation.
I0601 11:13:14.811391 28894 net.cpp:226] conv9_2_mbox_loc needs backward computation.
I0601 11:13:14.811394 28894 net.cpp:228] conv8_2_mbox_priorbox does not need backward computation.
I0601 11:13:14.811398 28894 net.cpp:226] conv8_2_mbox_conf_flat needs backward computation.
I0601 11:13:14.811399 28894 net.cpp:226] conv8_2_mbox_conf_perm needs backward computation.
I0601 11:13:14.811403 28894 net.cpp:226] conv8_2_mbox_conf needs backward computation.
I0601 11:13:14.811404 28894 net.cpp:226] conv8_2_mbox_loc_flat needs backward computation.
I0601 11:13:14.811406 28894 net.cpp:226] conv8_2_mbox_loc_perm needs backward computation.
I0601 11:13:14.811409 28894 net.cpp:226] conv8_2_mbox_loc needs backward computation.
I0601 11:13:14.811411 28894 net.cpp:228] conv7_2_mbox_priorbox does not need backward computation.
I0601 11:13:14.811414 28894 net.cpp:226] conv7_2_mbox_conf_flat needs backward computation.
I0601 11:13:14.811417 28894 net.cpp:226] conv7_2_mbox_conf_perm needs backward computation.
I0601 11:13:14.811420 28894 net.cpp:226] conv7_2_mbox_conf needs backward computation.
I0601 11:13:14.811422 28894 net.cpp:226] conv7_2_mbox_loc_flat needs backward computation.
I0601 11:13:14.811425 28894 net.cpp:226] conv7_2_mbox_loc_perm needs backward computation.
I0601 11:13:14.811427 28894 net.cpp:226] conv7_2_mbox_loc needs backward computation.
I0601 11:13:14.811430 28894 net.cpp:228] conv6_2_mbox_priorbox does not need backward computation.
I0601 11:13:14.811434 28894 net.cpp:226] conv6_2_mbox_conf_flat needs backward computation.
I0601 11:13:14.811435 28894 net.cpp:226] conv6_2_mbox_conf_perm needs backward computation.
I0601 11:13:14.811437 28894 net.cpp:226] conv6_2_mbox_conf needs backward computation.
I0601 11:13:14.811439 28894 net.cpp:226] conv6_2_mbox_loc_flat needs backward computation.
I0601 11:13:14.811442 28894 net.cpp:226] conv6_2_mbox_loc_perm needs backward computation.
I0601 11:13:14.811444 28894 net.cpp:226] conv6_2_mbox_loc needs backward computation.
I0601 11:13:14.811447 28894 net.cpp:228] fc7_mbox_priorbox does not need backward computation.
I0601 11:13:14.811450 28894 net.cpp:226] fc7_mbox_conf_flat needs backward computation.
I0601 11:13:14.811453 28894 net.cpp:226] fc7_mbox_conf_perm needs backward computation.
I0601 11:13:14.811456 28894 net.cpp:226] fc7_mbox_conf needs backward computation.
I0601 11:13:14.811460 28894 net.cpp:226] fc7_mbox_loc_flat needs backward computation.
I0601 11:13:14.811461 28894 net.cpp:226] fc7_mbox_loc_perm needs backward computation.
I0601 11:13:14.811463 28894 net.cpp:226] fc7_mbox_loc needs backward computation.
I0601 11:13:14.811466 28894 net.cpp:228] conv4_3_norm_mbox_priorbox does not need backward computation.
I0601 11:13:14.811470 28894 net.cpp:226] conv4_3_norm_mbox_conf_flat needs backward computation.
I0601 11:13:14.811472 28894 net.cpp:226] conv4_3_norm_mbox_conf_perm needs backward computation.
I0601 11:13:14.811475 28894 net.cpp:226] conv4_3_norm_mbox_conf needs backward computation.
I0601 11:13:14.811477 28894 net.cpp:226] conv4_3_norm_mbox_loc_flat needs backward computation.
I0601 11:13:14.811480 28894 net.cpp:226] conv4_3_norm_mbox_loc_perm needs backward computation.
I0601 11:13:14.811483 28894 net.cpp:226] conv4_3_norm_mbox_loc needs backward computation.
I0601 11:13:14.811486 28894 net.cpp:226] conv4_3_norm_conv4_3_norm_0_split needs backward computation.
I0601 11:13:14.811488 28894 net.cpp:226] conv4_3_norm needs backward computation.
I0601 11:13:14.811496 28894 net.cpp:226] conv9_2_conv9_2_relu_0_split needs backward computation.
I0601 11:13:14.811497 28894 net.cpp:226] conv9_2_relu needs backward computation.
I0601 11:13:14.811501 28894 net.cpp:226] conv9_2 needs backward computation.
I0601 11:13:14.811503 28894 net.cpp:226] conv9_1_relu needs backward computation.
I0601 11:13:14.811506 28894 net.cpp:226] conv9_1 needs backward computation.
I0601 11:13:14.811507 28894 net.cpp:226] conv8_2_conv8_2_relu_0_split needs backward computation.
I0601 11:13:14.811509 28894 net.cpp:226] conv8_2_relu needs backward computation.
I0601 11:13:14.811512 28894 net.cpp:226] conv8_2 needs backward computation.
I0601 11:13:14.811516 28894 net.cpp:226] conv8_1_relu needs backward computation.
I0601 11:13:14.811517 28894 net.cpp:226] conv8_1 needs backward computation.
I0601 11:13:14.811519 28894 net.cpp:226] conv7_2_conv7_2_relu_0_split needs backward computation.
I0601 11:13:14.811522 28894 net.cpp:226] conv7_2_relu needs backward computation.
I0601 11:13:14.811524 28894 net.cpp:226] conv7_2 needs backward computation.
I0601 11:13:14.811527 28894 net.cpp:226] conv7_1_relu needs backward computation.
I0601 11:13:14.811528 28894 net.cpp:226] conv7_1 needs backward computation.
I0601 11:13:14.811532 28894 net.cpp:226] conv6_2_conv6_2_relu_0_split needs backward computation.
I0601 11:13:14.811533 28894 net.cpp:226] conv6_2_relu needs backward computation.
I0601 11:13:14.811535 28894 net.cpp:226] conv6_2 needs backward computation.
I0601 11:13:14.811538 28894 net.cpp:226] conv6_1_relu needs backward computation.
I0601 11:13:14.811540 28894 net.cpp:226] conv6_1 needs backward computation.
I0601 11:13:14.811544 28894 net.cpp:228] fc7_relu7_0_split does not need backward computation.
I0601 11:13:14.811547 28894 net.cpp:228] relu7 does not need backward computation.
I0601 11:13:14.811549 28894 net.cpp:228] fc7 does not need backward computation.
I0601 11:13:14.811553 28894 net.cpp:228] relu6 does not need backward computation.
I0601 11:13:14.811554 28894 net.cpp:228] fc6 does not need backward computation.
I0601 11:13:14.811558 28894 net.cpp:228] pool5 does not need backward computation.
I0601 11:13:14.811559 28894 net.cpp:228] relu5_3 does not need backward computation.
I0601 11:13:14.811563 28894 net.cpp:228] conv5_3 does not need backward computation.
I0601 11:13:14.811564 28894 net.cpp:228] relu5_2 does not need backward computation.
I0601 11:13:14.811566 28894 net.cpp:228] conv5_2 does not need backward computation.
I0601 11:13:14.811569 28894 net.cpp:228] relu5_1 does not need backward computation.
I0601 11:13:14.811571 28894 net.cpp:228] conv5_1 does not need backward computation.
I0601 11:13:14.811574 28894 net.cpp:228] pool4 does not need backward computation.
I0601 11:13:14.811578 28894 net.cpp:228] conv4_3_relu4_3_0_split does not need backward computation.
I0601 11:13:14.811579 28894 net.cpp:228] relu4_3 does not need backward computation.
I0601 11:13:14.811583 28894 net.cpp:228] conv4_3 does not need backward computation.
I0601 11:13:14.811584 28894 net.cpp:228] relu4_2 does not need backward computation.
I0601 11:13:14.811586 28894 net.cpp:228] conv4_2 does not need backward computation.
I0601 11:13:14.811589 28894 net.cpp:228] relu4_1 does not need backward computation.
I0601 11:13:14.811592 28894 net.cpp:228] conv4_1 does not need backward computation.
I0601 11:13:14.811594 28894 net.cpp:228] pool3 does not need backward computation.
I0601 11:13:14.811596 28894 net.cpp:228] relu3_3 does not need backward computation.
I0601 11:13:14.811599 28894 net.cpp:228] conv3_3 does not need backward computation.
I0601 11:13:14.811601 28894 net.cpp:228] relu3_2 does not need backward computation.
I0601 11:13:14.811604 28894 net.cpp:228] conv3_2 does not need backward computation.
I0601 11:13:14.811609 28894 net.cpp:228] relu3_1 does not need backward computation.
I0601 11:13:14.811614 28894 net.cpp:228] conv3_1 does not need backward computation.
I0601 11:13:14.811616 28894 net.cpp:228] pool2 does not need backward computation.
I0601 11:13:14.811619 28894 net.cpp:228] relu2_2 does not need backward computation.
I0601 11:13:14.811625 28894 net.cpp:228] conv2_2 does not need backward computation.
I0601 11:13:14.811628 28894 net.cpp:228] relu2_1 does not need backward computation.
I0601 11:13:14.811631 28894 net.cpp:228] conv2_1 does not need backward computation.
I0601 11:13:14.811633 28894 net.cpp:228] pool1 does not need backward computation.
I0601 11:13:14.811635 28894 net.cpp:228] relu1_2 does not need backward computation.
I0601 11:13:14.811637 28894 net.cpp:228] conv1_2 does not need backward computation.
I0601 11:13:14.811640 28894 net.cpp:228] relu1_1 does not need backward computation.
I0601 11:13:14.811642 28894 net.cpp:228] conv1_1 does not need backward computation.
I0601 11:13:14.811645 28894 net.cpp:228] data_data_0_split does not need backward computation.
I0601 11:13:14.811648 28894 net.cpp:228] data does not need backward computation.
I0601 11:13:14.811650 28894 net.cpp:270] This network produces output mbox_loss
I0601 11:13:14.811709 28894 net.cpp:283] Network initialization done.
I0601 11:13:14.812402 28894 solver.cpp:196] Creating test net (#0) specified by test_net file: models/VGGNet/tbs/SSD_300x300/test.prototxt
I0601 11:13:14.812969 28894 net.cpp:58] Initializing net from parameters: 
name: "VGG_tbs_300x300_HSIL_10x_SSD_300x300_test"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "AnnotatedData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mean_value: 104
    mean_value: 117
    mean_value: 123
    resize_param {
      prob: 1
      resize_mode: WARP
      height: 300
      width: 300
      interp_mode: LINEAR
    }
  }
  data_param {
    source: "examples/tbs_300x300_HSIL_10x/tbs_300x300_HSIL_10x_test_lmdb"
    batch_size: 4
    backend: LMDB
  }
  annotated_data_param {
    batch_sampler {
    }
    label_map_file: "data/tbs_300x300_HSIL_10x/labelmap_tbs.prototxt"
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "fc6"
  type: "Convolution"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    pad: 6
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 6
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "fc7"
  type: "Convolution"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "conv6_1"
  type: "Convolution"
  bottom: "fc7"
  top: "conv6_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6_1_relu"
  type: "ReLU"
  bottom: "conv6_1"
  top: "conv6_1"
}
layer {
  name: "conv6_2"
  type: "Convolution"
  bottom: "conv6_1"
  top: "conv6_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6_2_relu"
  type: "ReLU"
  bottom: "conv6_2"
  top: "conv6_2"
}
layer {
  name: "conv7_1"
  type: "Convolution"
  bottom: "conv6_2"
  top: "conv7_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv7_1_relu"
  type: "ReLU"
  bottom: "conv7_1"
  top: "conv7_1"
}
layer {
  name: "conv7_2"
  type: "Convolution"
  bottom: "conv7_1"
  top: "conv7_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv7_2_relu"
  type: "ReLU"
  bottom: "conv7_2"
  top: "conv7_2"
}
layer {
  name: "conv8_1"
  type: "Convolution"
  bottom: "conv7_2"
  top: "conv8_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv8_1_relu"
  type: "ReLU"
  bottom: "conv8_1"
  top: "conv8_1"
}
layer {
  name: "conv8_2"
  type: "Convolution"
  bottom: "conv8_1"
  top: "conv8_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv8_2_relu"
  type: "ReLU"
  bottom: "conv8_2"
  top: "conv8_2"
}
layer {
  name: "conv9_1"
  type: "Convolution"
  bottom: "conv8_2"
  top: "conv9_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv9_1_relu"
  type: "ReLU"
  bottom: "conv9_1"
  top: "conv9_1"
}
layer {
  name: "conv9_2"
  type: "Convolution"
  bottom: "conv9_1"
  top: "conv9_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv9_2_relu"
  type: "ReLU"
  bottom: "conv9_2"
  top: "conv9_2"
}
layer {
  name: "conv4_3_norm"
  type: "Normalize"
  bottom: "conv4_3"
  top: "conv4_3_norm"
  norm_param {
    across_spatial: false
    scale_filler {
      type: "constant"
      value: 20
    }
    channel_shared: false
  }
}
layer {
  name: "conv4_3_norm_mbox_loc"
  type: "Convolution"
  bottom: "conv4_3_norm"
  top: "conv4_3_norm_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_3_norm_mbox_loc_perm"
  type: "Permute"
  bottom: "conv4_3_norm_mbox_loc"
  top: "conv4_3_norm_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv4_3_norm_mbox_loc_perm"
  top: "conv4_3_norm_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_conf"
  type: "Convolution"
  bottom: "conv4_3_norm"
  top: "conv4_3_norm_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_3_norm_mbox_conf_perm"
  type: "Permute"
  bottom: "conv4_3_norm_mbox_conf"
  top: "conv4_3_norm_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv4_3_norm_mbox_conf_perm"
  top: "conv4_3_norm_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv4_3_norm"
  bottom: "data"
  top: "conv4_3_norm_mbox_priorbox"
  prior_box_param {
    min_size: 30
    max_size: 60
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 8
    offset: 0.5
  }
}
layer {
  name: "fc7_mbox_loc"
  type: "Convolution"
  bottom: "fc7"
  top: "fc7_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc7_mbox_loc_perm"
  type: "Permute"
  bottom: "fc7_mbox_loc"
  top: "fc7_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "fc7_mbox_loc_flat"
  type: "Flatten"
  bottom: "fc7_mbox_loc_perm"
  top: "fc7_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "fc7_mbox_conf"
  type: "Convolution"
  bottom: "fc7"
  top: "fc7_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc7_mbox_conf_perm"
  type: "Permute"
  bottom: "fc7_mbox_conf"
  top: "fc7_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "fc7_mbox_conf_flat"
  type: "Flatten"
  bottom: "fc7_mbox_conf_perm"
  top: "fc7_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "fc7_mbox_priorbox"
  type: "PriorBox"
  bottom: "fc7"
  bottom: "data"
  top: "fc7_mbox_priorbox"
  prior_box_param {
    min_size: 60
    max_size: 111
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 16
    offset: 0.5
  }
}
layer {
  name: "conv6_2_mbox_loc"
  type: "Convolution"
  bottom: "conv6_2"
  top: "conv6_2_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6_2_mbox_loc_perm"
  type: "Permute"
  bottom: "conv6_2_mbox_loc"
  top: "conv6_2_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv6_2_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv6_2_mbox_loc_perm"
  top: "conv6_2_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv6_2_mbox_conf"
  type: "Convolution"
  bottom: "conv6_2"
  top: "conv6_2_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6_2_mbox_conf_perm"
  type: "Permute"
  bottom: "conv6_2_mbox_conf"
  top: "conv6_2_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv6_2_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv6_2_mbox_conf_perm"
  top: "conv6_2_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv6_2_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv6_2"
  bottom: "data"
  top: "conv6_2_mbox_priorbox"
  prior_box_param {
    min_size: 111
    max_size: 162
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 32
    offset: 0.5
  }
}
layer {
  name: "conv7_2_mbox_loc"
  type: "Convolution"
  bottom: "conv7_2"
  top: "conv7_2_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv7_2_mbox_loc_perm"
  type: "Permute"
  bottom: "conv7_2_mbox_loc"
  top: "conv7_2_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv7_2_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv7_2_mbox_loc_perm"
  top: "conv7_2_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv7_2_mbox_conf"
  type: "Convolution"
  bottom: "conv7_2"
  top: "conv7_2_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv7_2_mbox_conf_perm"
  type: "Permute"
  bottom: "conv7_2_mbox_conf"
  top: "conv7_2_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv7_2_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv7_2_mbox_conf_perm"
  top: "conv7_2_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv7_2_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv7_2"
  bottom: "data"
  top: "conv7_2_mbox_priorbox"
  prior_box_param {
    min_size: 162
    max_size: 213
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 64
    offset: 0.5
  }
}
layer {
  name: "conv8_2_mbox_loc"
  type: "Convolution"
  bottom: "conv8_2"
  top: "conv8_2_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv8_2_mbox_loc_perm"
  type: "Permute"
  bottom: "conv8_2_mbox_loc"
  top: "conv8_2_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv8_2_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv8_2_mbox_loc_perm"
  top: "conv8_2_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv8_2_mbox_conf"
  type: "Convolution"
  bottom: "conv8_2"
  top: "conv8_2_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv8_2_mbox_conf_perm"
  type: "Permute"
  bottom: "conv8_2_mbox_conf"
  top: "conv8_2_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv8_2_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv8_2_mbox_conf_perm"
  top: "conv8_2_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv8_2_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv8_2"
  bottom: "data"
  top: "conv8_2_mbox_priorbox"
  prior_box_param {
    min_size: 213
    max_size: 264
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 100
    offset: 0.5
  }
}
layer {
  name: "conv9_2_mbox_loc"
  type: "Convolution"
  bottom: "conv9_2"
  top: "conv9_2_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv9_2_mbox_loc_perm"
  type: "Permute"
  bottom: "conv9_2_mbox_loc"
  top: "conv9_2_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv9_2_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv9_2_mbox_loc_perm"
  top: "conv9_2_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv9_2_mbox_conf"
  type: "Convolution"
  bottom: "conv9_2"
  top: "conv9_2_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv9_2_mbox_conf_perm"
  type: "Permute"
  bottom: "conv9_2_mbox_conf"
  top: "conv9_2_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv9_2_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv9_2_mbox_conf_perm"
  top: "conv9_2_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv9_2_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv9_2"
  bottom: "data"
  top: "conv9_2_mbox_priorbox"
  prior_box_param {
    min_size: 264
    max_size: 315
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 300
    offset: 0.5
  }
}
layer {
  name: "mbox_loc"
  type: "Concat"
  bottom: "conv4_3_norm_mbox_loc_flat"
  bottom: "fc7_mbox_loc_flat"
  bottom: "conv6_2_mbox_loc_flat"
  bottom: "conv7_2_mbox_loc_flat"
  bottom: "conv8_2_mbox_loc_flat"
  bottom: "conv9_2_mbox_loc_flat"
  top: "mbox_loc"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mbox_conf"
  type: "Concat"
  bottom: "conv4_3_norm_mbox_conf_flat"
  bottom: "fc7_mbox_conf_flat"
  bottom: "conv6_2_mbox_conf_flat"
  bottom: "conv7_2_mbox_conf_flat"
  bottom: "conv8_2_mbox_conf_flat"
  bottom: "conv9_2_mbox_conf_flat"
  top: "mbox_conf"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mbox_priorbox"
  type: "Concat"
  bottom: "conv4_3_norm_mbox_priorbox"
  bottom: "fc7_mbox_priorbox"
  bottom: "conv6_2_mbox_priorbox"
  bottom: "conv7_2_mbox_priorbox"
  bottom: "conv8_2_mbox_priorbox"
  bottom: "conv9_2_mbox_priorbox"
  top: "mbox_priorbox"
  concat_param {
    axis: 2
  }
}
layer {
  name: "mbox_conf_reshape"
  type: "Reshape"
  bottom: "mbox_conf"
  top: "mbox_conf_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: -1
      dim: 4
    }
  }
}
layer {
  name: "mbox_conf_softmax"
  type: "Softmax"
  bottom: "mbox_conf_reshape"
  top: "mbox_conf_softmax"
  softmax_param {
    axis: 2
  }
}
layer {
  name: "mbox_conf_flatten"
  type: "Flatten"
  bottom: "mbox_conf_softmax"
  top: "mbox_conf_flatten"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "detection_out"
  type: "DetectionOutput"
  bottom: "mbox_loc"
  bottom: "mbox_conf_flatten"
  bottom: "mbox_priorbox"
  top: "detection_out"
  include {
    phase: TEST
  }
  detection_output_param {
    num_classes: 4
    share_location: true
    background_label_id: 0
    nms_param {
      nms_threshold: 0.45
      top_k: 400
    }
    save_output_param {
      output_directory: "/home/shangzw/data/tbs/results/tbs/SSD_300x300/Main"
      output_name_prefix: "comp4_det_test_"
      output_format: "VOC"
      label_map_file: "data/tbs_300x300_HSIL_10x/labelmap_tbs.prototxt"
      name_size_file: "data/VOC0712/test_name_size.txt"
      num_test_image: 100
    }
    code_type: CENTER_SIZE
    keep_top_k: 200
    confidence_threshold: 0.01
  }
}
layer {
  name: "detection_eval"
  type: "DetectionEvaluate"
  bottom: "detection_out"
  bottom: "label"
  top: "detection_eval"
  include {
    phase: TEST
  }
  detection_evaluate_param {
    num_classes: 4
    background_label_id: 0
    overlap_threshold: 0.5
    evaluate_difficult_gt: false
    name_size_file: "data/VOC0712/test_name_size.txt"
  }
}
I0601 11:13:14.813284 28894 layer_factory.hpp:77] Creating layer data
I0601 11:13:14.813330 28894 net.cpp:100] Creating Layer data
I0601 11:13:14.813338 28894 net.cpp:408] data -> data
I0601 11:13:14.813344 28894 net.cpp:408] data -> label
I0601 11:13:14.813832 28912 db_lmdb.cpp:35] Opened lmdb examples/tbs_300x300_HSIL_10x/tbs_300x300_HSIL_10x_test_lmdb
I0601 11:13:14.814517 28894 annotated_data_layer.cpp:62] output data size: 4,3,300,300
I0601 11:13:14.823653 28894 net.cpp:150] Setting up data
I0601 11:13:14.823688 28894 net.cpp:157] Top shape: 4 3 300 300 (1080000)
I0601 11:13:14.823693 28894 net.cpp:157] Top shape: 1 1 1 8 (8)
I0601 11:13:14.823709 28894 net.cpp:165] Memory required for data: 4320032
I0601 11:13:14.823712 28894 layer_factory.hpp:77] Creating layer data_data_0_split
I0601 11:13:14.823724 28894 net.cpp:100] Creating Layer data_data_0_split
I0601 11:13:14.823729 28894 net.cpp:434] data_data_0_split <- data
I0601 11:13:14.823735 28894 net.cpp:408] data_data_0_split -> data_data_0_split_0
I0601 11:13:14.823746 28894 net.cpp:408] data_data_0_split -> data_data_0_split_1
I0601 11:13:14.823752 28894 net.cpp:408] data_data_0_split -> data_data_0_split_2
I0601 11:13:14.823760 28894 net.cpp:408] data_data_0_split -> data_data_0_split_3
I0601 11:13:14.823765 28894 net.cpp:408] data_data_0_split -> data_data_0_split_4
I0601 11:13:14.823771 28894 net.cpp:408] data_data_0_split -> data_data_0_split_5
I0601 11:13:14.823776 28894 net.cpp:408] data_data_0_split -> data_data_0_split_6
I0601 11:13:14.823854 28894 net.cpp:150] Setting up data_data_0_split
I0601 11:13:14.823861 28894 net.cpp:157] Top shape: 4 3 300 300 (1080000)
I0601 11:13:14.823876 28894 net.cpp:157] Top shape: 4 3 300 300 (1080000)
I0601 11:13:14.823881 28894 net.cpp:157] Top shape: 4 3 300 300 (1080000)
I0601 11:13:14.823885 28894 net.cpp:157] Top shape: 4 3 300 300 (1080000)
I0601 11:13:14.823891 28894 net.cpp:157] Top shape: 4 3 300 300 (1080000)
I0601 11:13:14.823895 28894 net.cpp:157] Top shape: 4 3 300 300 (1080000)
I0601 11:13:14.823899 28894 net.cpp:157] Top shape: 4 3 300 300 (1080000)
I0601 11:13:14.823901 28894 net.cpp:165] Memory required for data: 34560032
I0601 11:13:14.823905 28894 layer_factory.hpp:77] Creating layer conv1_1
I0601 11:13:14.823916 28894 net.cpp:100] Creating Layer conv1_1
I0601 11:13:14.823920 28894 net.cpp:434] conv1_1 <- data_data_0_split_0
I0601 11:13:14.823925 28894 net.cpp:408] conv1_1 -> conv1_1
I0601 11:13:14.824146 28894 net.cpp:150] Setting up conv1_1
I0601 11:13:14.824152 28894 net.cpp:157] Top shape: 4 64 300 300 (23040000)
I0601 11:13:14.824156 28894 net.cpp:165] Memory required for data: 126720032
I0601 11:13:14.824164 28894 layer_factory.hpp:77] Creating layer relu1_1
I0601 11:13:14.824170 28894 net.cpp:100] Creating Layer relu1_1
I0601 11:13:14.824174 28894 net.cpp:434] relu1_1 <- conv1_1
I0601 11:13:14.824178 28894 net.cpp:395] relu1_1 -> conv1_1 (in-place)
I0601 11:13:14.824184 28894 net.cpp:150] Setting up relu1_1
I0601 11:13:14.824189 28894 net.cpp:157] Top shape: 4 64 300 300 (23040000)
I0601 11:13:14.824193 28894 net.cpp:165] Memory required for data: 218880032
I0601 11:13:14.824195 28894 layer_factory.hpp:77] Creating layer conv1_2
I0601 11:13:14.824203 28894 net.cpp:100] Creating Layer conv1_2
I0601 11:13:14.824206 28894 net.cpp:434] conv1_2 <- conv1_1
I0601 11:13:14.824211 28894 net.cpp:408] conv1_2 -> conv1_2
I0601 11:13:14.824553 28894 net.cpp:150] Setting up conv1_2
I0601 11:13:14.824558 28894 net.cpp:157] Top shape: 4 64 300 300 (23040000)
I0601 11:13:14.824561 28894 net.cpp:165] Memory required for data: 311040032
I0601 11:13:14.824568 28894 layer_factory.hpp:77] Creating layer relu1_2
I0601 11:13:14.824573 28894 net.cpp:100] Creating Layer relu1_2
I0601 11:13:14.824575 28894 net.cpp:434] relu1_2 <- conv1_2
I0601 11:13:14.824580 28894 net.cpp:395] relu1_2 -> conv1_2 (in-place)
I0601 11:13:14.824586 28894 net.cpp:150] Setting up relu1_2
I0601 11:13:14.824591 28894 net.cpp:157] Top shape: 4 64 300 300 (23040000)
I0601 11:13:14.824594 28894 net.cpp:165] Memory required for data: 403200032
I0601 11:13:14.824597 28894 layer_factory.hpp:77] Creating layer pool1
I0601 11:13:14.824602 28894 net.cpp:100] Creating Layer pool1
I0601 11:13:14.824606 28894 net.cpp:434] pool1 <- conv1_2
I0601 11:13:14.824610 28894 net.cpp:408] pool1 -> pool1
I0601 11:13:14.824638 28894 net.cpp:150] Setting up pool1
I0601 11:13:14.824642 28894 net.cpp:157] Top shape: 4 64 150 150 (5760000)
I0601 11:13:14.824645 28894 net.cpp:165] Memory required for data: 426240032
I0601 11:13:14.824648 28894 layer_factory.hpp:77] Creating layer conv2_1
I0601 11:13:14.824656 28894 net.cpp:100] Creating Layer conv2_1
I0601 11:13:14.824659 28894 net.cpp:434] conv2_1 <- pool1
I0601 11:13:14.824664 28894 net.cpp:408] conv2_1 -> conv2_1
I0601 11:13:14.827050 28894 net.cpp:150] Setting up conv2_1
I0601 11:13:14.827060 28894 net.cpp:157] Top shape: 4 128 150 150 (11520000)
I0601 11:13:14.827064 28894 net.cpp:165] Memory required for data: 472320032
I0601 11:13:14.827074 28894 layer_factory.hpp:77] Creating layer relu2_1
I0601 11:13:14.827080 28894 net.cpp:100] Creating Layer relu2_1
I0601 11:13:14.827083 28894 net.cpp:434] relu2_1 <- conv2_1
I0601 11:13:14.827088 28894 net.cpp:395] relu2_1 -> conv2_1 (in-place)
I0601 11:13:14.827095 28894 net.cpp:150] Setting up relu2_1
I0601 11:13:14.827100 28894 net.cpp:157] Top shape: 4 128 150 150 (11520000)
I0601 11:13:14.827103 28894 net.cpp:165] Memory required for data: 518400032
I0601 11:13:14.827106 28894 layer_factory.hpp:77] Creating layer conv2_2
I0601 11:13:14.827114 28894 net.cpp:100] Creating Layer conv2_2
I0601 11:13:14.827117 28894 net.cpp:434] conv2_2 <- conv2_1
I0601 11:13:14.827122 28894 net.cpp:408] conv2_2 -> conv2_2
I0601 11:13:14.828510 28894 net.cpp:150] Setting up conv2_2
I0601 11:13:14.828521 28894 net.cpp:157] Top shape: 4 128 150 150 (11520000)
I0601 11:13:14.828522 28894 net.cpp:165] Memory required for data: 564480032
I0601 11:13:14.828531 28894 layer_factory.hpp:77] Creating layer relu2_2
I0601 11:13:14.828536 28894 net.cpp:100] Creating Layer relu2_2
I0601 11:13:14.828541 28894 net.cpp:434] relu2_2 <- conv2_2
I0601 11:13:14.828547 28894 net.cpp:395] relu2_2 -> conv2_2 (in-place)
I0601 11:13:14.828553 28894 net.cpp:150] Setting up relu2_2
I0601 11:13:14.828558 28894 net.cpp:157] Top shape: 4 128 150 150 (11520000)
I0601 11:13:14.828562 28894 net.cpp:165] Memory required for data: 610560032
I0601 11:13:14.828565 28894 layer_factory.hpp:77] Creating layer pool2
I0601 11:13:14.828572 28894 net.cpp:100] Creating Layer pool2
I0601 11:13:14.828575 28894 net.cpp:434] pool2 <- conv2_2
I0601 11:13:14.828580 28894 net.cpp:408] pool2 -> pool2
I0601 11:13:14.828611 28894 net.cpp:150] Setting up pool2
I0601 11:13:14.828616 28894 net.cpp:157] Top shape: 4 128 75 75 (2880000)
I0601 11:13:14.828619 28894 net.cpp:165] Memory required for data: 622080032
I0601 11:13:14.828622 28894 layer_factory.hpp:77] Creating layer conv3_1
I0601 11:13:14.828629 28894 net.cpp:100] Creating Layer conv3_1
I0601 11:13:14.828634 28894 net.cpp:434] conv3_1 <- pool2
I0601 11:13:14.828639 28894 net.cpp:408] conv3_1 -> conv3_1
I0601 11:13:14.829973 28894 net.cpp:150] Setting up conv3_1
I0601 11:13:14.829980 28894 net.cpp:157] Top shape: 4 256 75 75 (5760000)
I0601 11:13:14.829983 28894 net.cpp:165] Memory required for data: 645120032
I0601 11:13:14.829993 28894 layer_factory.hpp:77] Creating layer relu3_1
I0601 11:13:14.829998 28894 net.cpp:100] Creating Layer relu3_1
I0601 11:13:14.830000 28894 net.cpp:434] relu3_1 <- conv3_1
I0601 11:13:14.830005 28894 net.cpp:395] relu3_1 -> conv3_1 (in-place)
I0601 11:13:14.830011 28894 net.cpp:150] Setting up relu3_1
I0601 11:13:14.830016 28894 net.cpp:157] Top shape: 4 256 75 75 (5760000)
I0601 11:13:14.830019 28894 net.cpp:165] Memory required for data: 668160032
I0601 11:13:14.830023 28894 layer_factory.hpp:77] Creating layer conv3_2
I0601 11:13:14.830030 28894 net.cpp:100] Creating Layer conv3_2
I0601 11:13:14.830034 28894 net.cpp:434] conv3_2 <- conv3_1
I0601 11:13:14.830039 28894 net.cpp:408] conv3_2 -> conv3_2
I0601 11:13:14.833317 28894 net.cpp:150] Setting up conv3_2
I0601 11:13:14.833333 28894 net.cpp:157] Top shape: 4 256 75 75 (5760000)
I0601 11:13:14.833335 28894 net.cpp:165] Memory required for data: 691200032
I0601 11:13:14.833343 28894 layer_factory.hpp:77] Creating layer relu3_2
I0601 11:13:14.833349 28894 net.cpp:100] Creating Layer relu3_2
I0601 11:13:14.833353 28894 net.cpp:434] relu3_2 <- conv3_2
I0601 11:13:14.833360 28894 net.cpp:395] relu3_2 -> conv3_2 (in-place)
I0601 11:13:14.833371 28894 net.cpp:150] Setting up relu3_2
I0601 11:13:14.833379 28894 net.cpp:157] Top shape: 4 256 75 75 (5760000)
I0601 11:13:14.833384 28894 net.cpp:165] Memory required for data: 714240032
I0601 11:13:14.833387 28894 layer_factory.hpp:77] Creating layer conv3_3
I0601 11:13:14.833400 28894 net.cpp:100] Creating Layer conv3_3
I0601 11:13:14.833405 28894 net.cpp:434] conv3_3 <- conv3_2
I0601 11:13:14.833412 28894 net.cpp:408] conv3_3 -> conv3_3
I0601 11:13:14.836661 28894 net.cpp:150] Setting up conv3_3
I0601 11:13:14.836674 28894 net.cpp:157] Top shape: 4 256 75 75 (5760000)
I0601 11:13:14.836676 28894 net.cpp:165] Memory required for data: 737280032
I0601 11:13:14.836683 28894 layer_factory.hpp:77] Creating layer relu3_3
I0601 11:13:14.836691 28894 net.cpp:100] Creating Layer relu3_3
I0601 11:13:14.836695 28894 net.cpp:434] relu3_3 <- conv3_3
I0601 11:13:14.836700 28894 net.cpp:395] relu3_3 -> conv3_3 (in-place)
I0601 11:13:14.836710 28894 net.cpp:150] Setting up relu3_3
I0601 11:13:14.836715 28894 net.cpp:157] Top shape: 4 256 75 75 (5760000)
I0601 11:13:14.836719 28894 net.cpp:165] Memory required for data: 760320032
I0601 11:13:14.836721 28894 layer_factory.hpp:77] Creating layer pool3
I0601 11:13:14.836729 28894 net.cpp:100] Creating Layer pool3
I0601 11:13:14.836748 28894 net.cpp:434] pool3 <- conv3_3
I0601 11:13:14.836756 28894 net.cpp:408] pool3 -> pool3
I0601 11:13:14.836796 28894 net.cpp:150] Setting up pool3
I0601 11:13:14.836802 28894 net.cpp:157] Top shape: 4 256 38 38 (1478656)
I0601 11:13:14.836805 28894 net.cpp:165] Memory required for data: 766234656
I0601 11:13:14.836807 28894 layer_factory.hpp:77] Creating layer conv4_1
I0601 11:13:14.836817 28894 net.cpp:100] Creating Layer conv4_1
I0601 11:13:14.836822 28894 net.cpp:434] conv4_1 <- pool3
I0601 11:13:14.836829 28894 net.cpp:408] conv4_1 -> conv4_1
I0601 11:13:14.844050 28894 net.cpp:150] Setting up conv4_1
I0601 11:13:14.844069 28894 net.cpp:157] Top shape: 4 512 38 38 (2957312)
I0601 11:13:14.844071 28894 net.cpp:165] Memory required for data: 778063904
I0601 11:13:14.844076 28894 layer_factory.hpp:77] Creating layer relu4_1
I0601 11:13:14.844085 28894 net.cpp:100] Creating Layer relu4_1
I0601 11:13:14.844089 28894 net.cpp:434] relu4_1 <- conv4_1
I0601 11:13:14.844096 28894 net.cpp:395] relu4_1 -> conv4_1 (in-place)
I0601 11:13:14.844103 28894 net.cpp:150] Setting up relu4_1
I0601 11:13:14.844113 28894 net.cpp:157] Top shape: 4 512 38 38 (2957312)
I0601 11:13:14.844120 28894 net.cpp:165] Memory required for data: 789893152
I0601 11:13:14.844125 28894 layer_factory.hpp:77] Creating layer conv4_2
I0601 11:13:14.844137 28894 net.cpp:100] Creating Layer conv4_2
I0601 11:13:14.844143 28894 net.cpp:434] conv4_2 <- conv4_1
I0601 11:13:14.844151 28894 net.cpp:408] conv4_2 -> conv4_2
I0601 11:13:14.855783 28894 net.cpp:150] Setting up conv4_2
I0601 11:13:14.855799 28894 net.cpp:157] Top shape: 4 512 38 38 (2957312)
I0601 11:13:14.855801 28894 net.cpp:165] Memory required for data: 801722400
I0601 11:13:14.855828 28894 layer_factory.hpp:77] Creating layer relu4_2
I0601 11:13:14.855849 28894 net.cpp:100] Creating Layer relu4_2
I0601 11:13:14.855852 28894 net.cpp:434] relu4_2 <- conv4_2
I0601 11:13:14.855856 28894 net.cpp:395] relu4_2 -> conv4_2 (in-place)
I0601 11:13:14.855862 28894 net.cpp:150] Setting up relu4_2
I0601 11:13:14.855867 28894 net.cpp:157] Top shape: 4 512 38 38 (2957312)
I0601 11:13:14.855870 28894 net.cpp:165] Memory required for data: 813551648
I0601 11:13:14.855872 28894 layer_factory.hpp:77] Creating layer conv4_3
I0601 11:13:14.855881 28894 net.cpp:100] Creating Layer conv4_3
I0601 11:13:14.855886 28894 net.cpp:434] conv4_3 <- conv4_2
I0601 11:13:14.855895 28894 net.cpp:408] conv4_3 -> conv4_3
I0601 11:13:14.868749 28894 net.cpp:150] Setting up conv4_3
I0601 11:13:14.868767 28894 net.cpp:157] Top shape: 4 512 38 38 (2957312)
I0601 11:13:14.868770 28894 net.cpp:165] Memory required for data: 825380896
I0601 11:13:14.868790 28894 layer_factory.hpp:77] Creating layer relu4_3
I0601 11:13:14.868796 28894 net.cpp:100] Creating Layer relu4_3
I0601 11:13:14.868813 28894 net.cpp:434] relu4_3 <- conv4_3
I0601 11:13:14.868819 28894 net.cpp:395] relu4_3 -> conv4_3 (in-place)
I0601 11:13:14.868827 28894 net.cpp:150] Setting up relu4_3
I0601 11:13:14.868831 28894 net.cpp:157] Top shape: 4 512 38 38 (2957312)
I0601 11:13:14.868834 28894 net.cpp:165] Memory required for data: 837210144
I0601 11:13:14.868837 28894 layer_factory.hpp:77] Creating layer conv4_3_relu4_3_0_split
I0601 11:13:14.868844 28894 net.cpp:100] Creating Layer conv4_3_relu4_3_0_split
I0601 11:13:14.868847 28894 net.cpp:434] conv4_3_relu4_3_0_split <- conv4_3
I0601 11:13:14.868854 28894 net.cpp:408] conv4_3_relu4_3_0_split -> conv4_3_relu4_3_0_split_0
I0601 11:13:14.868863 28894 net.cpp:408] conv4_3_relu4_3_0_split -> conv4_3_relu4_3_0_split_1
I0601 11:13:14.868934 28894 net.cpp:150] Setting up conv4_3_relu4_3_0_split
I0601 11:13:14.868943 28894 net.cpp:157] Top shape: 4 512 38 38 (2957312)
I0601 11:13:14.868948 28894 net.cpp:157] Top shape: 4 512 38 38 (2957312)
I0601 11:13:14.868952 28894 net.cpp:165] Memory required for data: 860868640
I0601 11:13:14.868955 28894 layer_factory.hpp:77] Creating layer pool4
I0601 11:13:14.868963 28894 net.cpp:100] Creating Layer pool4
I0601 11:13:14.868968 28894 net.cpp:434] pool4 <- conv4_3_relu4_3_0_split_0
I0601 11:13:14.868986 28894 net.cpp:408] pool4 -> pool4
I0601 11:13:14.869020 28894 net.cpp:150] Setting up pool4
I0601 11:13:14.869027 28894 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0601 11:13:14.869030 28894 net.cpp:165] Memory required for data: 863825952
I0601 11:13:14.869033 28894 layer_factory.hpp:77] Creating layer conv5_1
I0601 11:13:14.869045 28894 net.cpp:100] Creating Layer conv5_1
I0601 11:13:14.869050 28894 net.cpp:434] conv5_1 <- pool4
I0601 11:13:14.869057 28894 net.cpp:408] conv5_1 -> conv5_1
I0601 11:13:14.880645 28894 net.cpp:150] Setting up conv5_1
I0601 11:13:14.880666 28894 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0601 11:13:14.880669 28894 net.cpp:165] Memory required for data: 866783264
I0601 11:13:14.880677 28894 layer_factory.hpp:77] Creating layer relu5_1
I0601 11:13:14.880684 28894 net.cpp:100] Creating Layer relu5_1
I0601 11:13:14.880689 28894 net.cpp:434] relu5_1 <- conv5_1
I0601 11:13:14.880713 28894 net.cpp:395] relu5_1 -> conv5_1 (in-place)
I0601 11:13:14.880723 28894 net.cpp:150] Setting up relu5_1
I0601 11:13:14.880730 28894 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0601 11:13:14.880734 28894 net.cpp:165] Memory required for data: 869740576
I0601 11:13:14.880738 28894 layer_factory.hpp:77] Creating layer conv5_2
I0601 11:13:14.880749 28894 net.cpp:100] Creating Layer conv5_2
I0601 11:13:14.880753 28894 net.cpp:434] conv5_2 <- conv5_1
I0601 11:13:14.880774 28894 net.cpp:408] conv5_2 -> conv5_2
I0601 11:13:14.892428 28894 net.cpp:150] Setting up conv5_2
I0601 11:13:14.892452 28894 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0601 11:13:14.892455 28894 net.cpp:165] Memory required for data: 872697888
I0601 11:13:14.892464 28894 layer_factory.hpp:77] Creating layer relu5_2
I0601 11:13:14.892473 28894 net.cpp:100] Creating Layer relu5_2
I0601 11:13:14.892478 28894 net.cpp:434] relu5_2 <- conv5_2
I0601 11:13:14.892485 28894 net.cpp:395] relu5_2 -> conv5_2 (in-place)
I0601 11:13:14.892494 28894 net.cpp:150] Setting up relu5_2
I0601 11:13:14.892499 28894 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0601 11:13:14.892503 28894 net.cpp:165] Memory required for data: 875655200
I0601 11:13:14.892506 28894 layer_factory.hpp:77] Creating layer conv5_3
I0601 11:13:14.892518 28894 net.cpp:100] Creating Layer conv5_3
I0601 11:13:14.892525 28894 net.cpp:434] conv5_3 <- conv5_2
I0601 11:13:14.892534 28894 net.cpp:408] conv5_3 -> conv5_3
I0601 11:13:14.904177 28894 net.cpp:150] Setting up conv5_3
I0601 11:13:14.904194 28894 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0601 11:13:14.904197 28894 net.cpp:165] Memory required for data: 878612512
I0601 11:13:14.904204 28894 layer_factory.hpp:77] Creating layer relu5_3
I0601 11:13:14.904233 28894 net.cpp:100] Creating Layer relu5_3
I0601 11:13:14.904255 28894 net.cpp:434] relu5_3 <- conv5_3
I0601 11:13:14.904263 28894 net.cpp:395] relu5_3 -> conv5_3 (in-place)
I0601 11:13:14.904273 28894 net.cpp:150] Setting up relu5_3
I0601 11:13:14.904278 28894 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0601 11:13:14.904284 28894 net.cpp:165] Memory required for data: 881569824
I0601 11:13:14.904300 28894 layer_factory.hpp:77] Creating layer pool5
I0601 11:13:14.904307 28894 net.cpp:100] Creating Layer pool5
I0601 11:13:14.904312 28894 net.cpp:434] pool5 <- conv5_3
I0601 11:13:14.904320 28894 net.cpp:408] pool5 -> pool5
I0601 11:13:14.904361 28894 net.cpp:150] Setting up pool5
I0601 11:13:14.904366 28894 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0601 11:13:14.904371 28894 net.cpp:165] Memory required for data: 884527136
I0601 11:13:14.904374 28894 layer_factory.hpp:77] Creating layer fc6
I0601 11:13:14.904412 28894 net.cpp:100] Creating Layer fc6
I0601 11:13:14.904417 28894 net.cpp:434] fc6 <- pool5
I0601 11:13:14.904422 28894 net.cpp:408] fc6 -> fc6
I0601 11:13:14.927152 28894 net.cpp:150] Setting up fc6
I0601 11:13:14.927175 28894 net.cpp:157] Top shape: 4 1024 19 19 (1478656)
I0601 11:13:14.927177 28894 net.cpp:165] Memory required for data: 890441760
I0601 11:13:14.927186 28894 layer_factory.hpp:77] Creating layer relu6
I0601 11:13:14.927222 28894 net.cpp:100] Creating Layer relu6
I0601 11:13:14.927242 28894 net.cpp:434] relu6 <- fc6
I0601 11:13:14.927253 28894 net.cpp:395] relu6 -> fc6 (in-place)
I0601 11:13:14.927263 28894 net.cpp:150] Setting up relu6
I0601 11:13:14.927269 28894 net.cpp:157] Top shape: 4 1024 19 19 (1478656)
I0601 11:13:14.927274 28894 net.cpp:165] Memory required for data: 896356384
I0601 11:13:14.927278 28894 layer_factory.hpp:77] Creating layer fc7
I0601 11:13:14.927301 28894 net.cpp:100] Creating Layer fc7
I0601 11:13:14.927306 28894 net.cpp:434] fc7 <- fc6
I0601 11:13:14.927312 28894 net.cpp:408] fc7 -> fc7
I0601 11:13:14.933234 28894 net.cpp:150] Setting up fc7
I0601 11:13:14.933282 28894 net.cpp:157] Top shape: 4 1024 19 19 (1478656)
I0601 11:13:14.933300 28894 net.cpp:165] Memory required for data: 902271008
I0601 11:13:14.933310 28894 layer_factory.hpp:77] Creating layer relu7
I0601 11:13:14.933317 28894 net.cpp:100] Creating Layer relu7
I0601 11:13:14.933322 28894 net.cpp:434] relu7 <- fc7
I0601 11:13:14.933329 28894 net.cpp:395] relu7 -> fc7 (in-place)
I0601 11:13:14.933353 28894 net.cpp:150] Setting up relu7
I0601 11:13:14.933368 28894 net.cpp:157] Top shape: 4 1024 19 19 (1478656)
I0601 11:13:14.933374 28894 net.cpp:165] Memory required for data: 908185632
I0601 11:13:14.933378 28894 layer_factory.hpp:77] Creating layer fc7_relu7_0_split
I0601 11:13:14.933387 28894 net.cpp:100] Creating Layer fc7_relu7_0_split
I0601 11:13:14.933390 28894 net.cpp:434] fc7_relu7_0_split <- fc7
I0601 11:13:14.933396 28894 net.cpp:408] fc7_relu7_0_split -> fc7_relu7_0_split_0
I0601 11:13:14.933406 28894 net.cpp:408] fc7_relu7_0_split -> fc7_relu7_0_split_1
I0601 11:13:14.933419 28894 net.cpp:408] fc7_relu7_0_split -> fc7_relu7_0_split_2
I0601 11:13:14.933428 28894 net.cpp:408] fc7_relu7_0_split -> fc7_relu7_0_split_3
I0601 11:13:14.933534 28894 net.cpp:150] Setting up fc7_relu7_0_split
I0601 11:13:14.933545 28894 net.cpp:157] Top shape: 4 1024 19 19 (1478656)
I0601 11:13:14.933564 28894 net.cpp:157] Top shape: 4 1024 19 19 (1478656)
I0601 11:13:14.933569 28894 net.cpp:157] Top shape: 4 1024 19 19 (1478656)
I0601 11:13:14.933575 28894 net.cpp:157] Top shape: 4 1024 19 19 (1478656)
I0601 11:13:14.933579 28894 net.cpp:165] Memory required for data: 931844128
I0601 11:13:14.933583 28894 layer_factory.hpp:77] Creating layer conv6_1
I0601 11:13:14.933594 28894 net.cpp:100] Creating Layer conv6_1
I0601 11:13:14.933601 28894 net.cpp:434] conv6_1 <- fc7_relu7_0_split_0
I0601 11:13:14.933610 28894 net.cpp:408] conv6_1 -> conv6_1
I0601 11:13:14.936223 28894 net.cpp:150] Setting up conv6_1
I0601 11:13:14.936235 28894 net.cpp:157] Top shape: 4 256 19 19 (369664)
I0601 11:13:14.936238 28894 net.cpp:165] Memory required for data: 933322784
I0601 11:13:14.936244 28894 layer_factory.hpp:77] Creating layer conv6_1_relu
I0601 11:13:14.936266 28894 net.cpp:100] Creating Layer conv6_1_relu
I0601 11:13:14.936271 28894 net.cpp:434] conv6_1_relu <- conv6_1
I0601 11:13:14.936277 28894 net.cpp:395] conv6_1_relu -> conv6_1 (in-place)
I0601 11:13:14.936286 28894 net.cpp:150] Setting up conv6_1_relu
I0601 11:13:14.936306 28894 net.cpp:157] Top shape: 4 256 19 19 (369664)
I0601 11:13:14.936311 28894 net.cpp:165] Memory required for data: 934801440
I0601 11:13:14.936328 28894 layer_factory.hpp:77] Creating layer conv6_2
I0601 11:13:14.936343 28894 net.cpp:100] Creating Layer conv6_2
I0601 11:13:14.936362 28894 net.cpp:434] conv6_2 <- conv6_1
I0601 11:13:14.936372 28894 net.cpp:408] conv6_2 -> conv6_2
I0601 11:13:14.942797 28894 net.cpp:150] Setting up conv6_2
I0601 11:13:14.942816 28894 net.cpp:157] Top shape: 4 512 10 10 (204800)
I0601 11:13:14.942818 28894 net.cpp:165] Memory required for data: 935620640
I0601 11:13:14.942831 28894 layer_factory.hpp:77] Creating layer conv6_2_relu
I0601 11:13:14.942855 28894 net.cpp:100] Creating Layer conv6_2_relu
I0601 11:13:14.942862 28894 net.cpp:434] conv6_2_relu <- conv6_2
I0601 11:13:14.942869 28894 net.cpp:395] conv6_2_relu -> conv6_2 (in-place)
I0601 11:13:14.942878 28894 net.cpp:150] Setting up conv6_2_relu
I0601 11:13:14.942895 28894 net.cpp:157] Top shape: 4 512 10 10 (204800)
I0601 11:13:14.942901 28894 net.cpp:165] Memory required for data: 936439840
I0601 11:13:14.942904 28894 layer_factory.hpp:77] Creating layer conv6_2_conv6_2_relu_0_split
I0601 11:13:14.942911 28894 net.cpp:100] Creating Layer conv6_2_conv6_2_relu_0_split
I0601 11:13:14.942915 28894 net.cpp:434] conv6_2_conv6_2_relu_0_split <- conv6_2
I0601 11:13:14.942924 28894 net.cpp:408] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_0
I0601 11:13:14.942932 28894 net.cpp:408] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_1
I0601 11:13:14.942940 28894 net.cpp:408] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_2
I0601 11:13:14.942948 28894 net.cpp:408] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_3
I0601 11:13:14.943027 28894 net.cpp:150] Setting up conv6_2_conv6_2_relu_0_split
I0601 11:13:14.943035 28894 net.cpp:157] Top shape: 4 512 10 10 (204800)
I0601 11:13:14.943042 28894 net.cpp:157] Top shape: 4 512 10 10 (204800)
I0601 11:13:14.943047 28894 net.cpp:157] Top shape: 4 512 10 10 (204800)
I0601 11:13:14.943053 28894 net.cpp:157] Top shape: 4 512 10 10 (204800)
I0601 11:13:14.943058 28894 net.cpp:165] Memory required for data: 939716640
I0601 11:13:14.943060 28894 layer_factory.hpp:77] Creating layer conv7_1
I0601 11:13:14.943073 28894 net.cpp:100] Creating Layer conv7_1
I0601 11:13:14.943078 28894 net.cpp:434] conv7_1 <- conv6_2_conv6_2_relu_0_split_0
I0601 11:13:14.943089 28894 net.cpp:408] conv7_1 -> conv7_1
I0601 11:13:14.943840 28894 net.cpp:150] Setting up conv7_1
I0601 11:13:14.943850 28894 net.cpp:157] Top shape: 4 128 10 10 (51200)
I0601 11:13:14.943856 28894 net.cpp:165] Memory required for data: 939921440
I0601 11:13:14.943863 28894 layer_factory.hpp:77] Creating layer conv7_1_relu
I0601 11:13:14.943869 28894 net.cpp:100] Creating Layer conv7_1_relu
I0601 11:13:14.943874 28894 net.cpp:434] conv7_1_relu <- conv7_1
I0601 11:13:14.943881 28894 net.cpp:395] conv7_1_relu -> conv7_1 (in-place)
I0601 11:13:14.943889 28894 net.cpp:150] Setting up conv7_1_relu
I0601 11:13:14.943897 28894 net.cpp:157] Top shape: 4 128 10 10 (51200)
I0601 11:13:14.943900 28894 net.cpp:165] Memory required for data: 940126240
I0601 11:13:14.943904 28894 layer_factory.hpp:77] Creating layer conv7_2
I0601 11:13:14.943915 28894 net.cpp:100] Creating Layer conv7_2
I0601 11:13:14.943920 28894 net.cpp:434] conv7_2 <- conv7_1
I0601 11:13:14.943929 28894 net.cpp:408] conv7_2 -> conv7_2
I0601 11:13:14.946267 28894 net.cpp:150] Setting up conv7_2
I0601 11:13:14.946281 28894 net.cpp:157] Top shape: 4 256 5 5 (25600)
I0601 11:13:14.946285 28894 net.cpp:165] Memory required for data: 940228640
I0601 11:13:14.946290 28894 layer_factory.hpp:77] Creating layer conv7_2_relu
I0601 11:13:14.946296 28894 net.cpp:100] Creating Layer conv7_2_relu
I0601 11:13:14.946301 28894 net.cpp:434] conv7_2_relu <- conv7_2
I0601 11:13:14.946307 28894 net.cpp:395] conv7_2_relu -> conv7_2 (in-place)
I0601 11:13:14.946316 28894 net.cpp:150] Setting up conv7_2_relu
I0601 11:13:14.946321 28894 net.cpp:157] Top shape: 4 256 5 5 (25600)
I0601 11:13:14.946326 28894 net.cpp:165] Memory required for data: 940331040
I0601 11:13:14.946329 28894 layer_factory.hpp:77] Creating layer conv7_2_conv7_2_relu_0_split
I0601 11:13:14.946337 28894 net.cpp:100] Creating Layer conv7_2_conv7_2_relu_0_split
I0601 11:13:14.946342 28894 net.cpp:434] conv7_2_conv7_2_relu_0_split <- conv7_2
I0601 11:13:14.946351 28894 net.cpp:408] conv7_2_conv7_2_relu_0_split -> conv7_2_conv7_2_relu_0_split_0
I0601 11:13:14.946359 28894 net.cpp:408] conv7_2_conv7_2_relu_0_split -> conv7_2_conv7_2_relu_0_split_1
I0601 11:13:14.946367 28894 net.cpp:408] conv7_2_conv7_2_relu_0_split -> conv7_2_conv7_2_relu_0_split_2
I0601 11:13:14.946374 28894 net.cpp:408] conv7_2_conv7_2_relu_0_split -> conv7_2_conv7_2_relu_0_split_3
I0601 11:13:14.946449 28894 net.cpp:150] Setting up conv7_2_conv7_2_relu_0_split
I0601 11:13:14.946458 28894 net.cpp:157] Top shape: 4 256 5 5 (25600)
I0601 11:13:14.946465 28894 net.cpp:157] Top shape: 4 256 5 5 (25600)
I0601 11:13:14.946481 28894 net.cpp:157] Top shape: 4 256 5 5 (25600)
I0601 11:13:14.946488 28894 net.cpp:157] Top shape: 4 256 5 5 (25600)
I0601 11:13:14.946492 28894 net.cpp:165] Memory required for data: 940740640
I0601 11:13:14.946497 28894 layer_factory.hpp:77] Creating layer conv8_1
I0601 11:13:14.946512 28894 net.cpp:100] Creating Layer conv8_1
I0601 11:13:14.946518 28894 net.cpp:434] conv8_1 <- conv7_2_conv7_2_relu_0_split_0
I0601 11:13:14.946527 28894 net.cpp:408] conv8_1 -> conv8_1
I0601 11:13:14.946990 28894 net.cpp:150] Setting up conv8_1
I0601 11:13:14.947000 28894 net.cpp:157] Top shape: 4 128 5 5 (12800)
I0601 11:13:14.947003 28894 net.cpp:165] Memory required for data: 940791840
I0601 11:13:14.947010 28894 layer_factory.hpp:77] Creating layer conv8_1_relu
I0601 11:13:14.947016 28894 net.cpp:100] Creating Layer conv8_1_relu
I0601 11:13:14.947019 28894 net.cpp:434] conv8_1_relu <- conv8_1
I0601 11:13:14.947024 28894 net.cpp:395] conv8_1_relu -> conv8_1 (in-place)
I0601 11:13:14.947031 28894 net.cpp:150] Setting up conv8_1_relu
I0601 11:13:14.947036 28894 net.cpp:157] Top shape: 4 128 5 5 (12800)
I0601 11:13:14.947039 28894 net.cpp:165] Memory required for data: 940843040
I0601 11:13:14.947043 28894 layer_factory.hpp:77] Creating layer conv8_2
I0601 11:13:14.947053 28894 net.cpp:100] Creating Layer conv8_2
I0601 11:13:14.947057 28894 net.cpp:434] conv8_2 <- conv8_1
I0601 11:13:14.947065 28894 net.cpp:408] conv8_2 -> conv8_2
I0601 11:13:14.949394 28894 net.cpp:150] Setting up conv8_2
I0601 11:13:14.949404 28894 net.cpp:157] Top shape: 4 256 3 3 (9216)
I0601 11:13:14.949406 28894 net.cpp:165] Memory required for data: 940879904
I0601 11:13:14.949412 28894 layer_factory.hpp:77] Creating layer conv8_2_relu
I0601 11:13:14.949419 28894 net.cpp:100] Creating Layer conv8_2_relu
I0601 11:13:14.949424 28894 net.cpp:434] conv8_2_relu <- conv8_2
I0601 11:13:14.949432 28894 net.cpp:395] conv8_2_relu -> conv8_2 (in-place)
I0601 11:13:14.949440 28894 net.cpp:150] Setting up conv8_2_relu
I0601 11:13:14.949446 28894 net.cpp:157] Top shape: 4 256 3 3 (9216)
I0601 11:13:14.949450 28894 net.cpp:165] Memory required for data: 940916768
I0601 11:13:14.949455 28894 layer_factory.hpp:77] Creating layer conv8_2_conv8_2_relu_0_split
I0601 11:13:14.949460 28894 net.cpp:100] Creating Layer conv8_2_conv8_2_relu_0_split
I0601 11:13:14.949466 28894 net.cpp:434] conv8_2_conv8_2_relu_0_split <- conv8_2
I0601 11:13:14.949475 28894 net.cpp:408] conv8_2_conv8_2_relu_0_split -> conv8_2_conv8_2_relu_0_split_0
I0601 11:13:14.949483 28894 net.cpp:408] conv8_2_conv8_2_relu_0_split -> conv8_2_conv8_2_relu_0_split_1
I0601 11:13:14.949491 28894 net.cpp:408] conv8_2_conv8_2_relu_0_split -> conv8_2_conv8_2_relu_0_split_2
I0601 11:13:14.949498 28894 net.cpp:408] conv8_2_conv8_2_relu_0_split -> conv8_2_conv8_2_relu_0_split_3
I0601 11:13:14.949573 28894 net.cpp:150] Setting up conv8_2_conv8_2_relu_0_split
I0601 11:13:14.949581 28894 net.cpp:157] Top shape: 4 256 3 3 (9216)
I0601 11:13:14.949587 28894 net.cpp:157] Top shape: 4 256 3 3 (9216)
I0601 11:13:14.949594 28894 net.cpp:157] Top shape: 4 256 3 3 (9216)
I0601 11:13:14.949599 28894 net.cpp:157] Top shape: 4 256 3 3 (9216)
I0601 11:13:14.949602 28894 net.cpp:165] Memory required for data: 941064224
I0601 11:13:14.949606 28894 layer_factory.hpp:77] Creating layer conv9_1
I0601 11:13:14.949617 28894 net.cpp:100] Creating Layer conv9_1
I0601 11:13:14.949622 28894 net.cpp:434] conv9_1 <- conv8_2_conv8_2_relu_0_split_0
I0601 11:13:14.949632 28894 net.cpp:408] conv9_1 -> conv9_1
I0601 11:13:14.950129 28894 net.cpp:150] Setting up conv9_1
I0601 11:13:14.950141 28894 net.cpp:157] Top shape: 4 128 3 3 (4608)
I0601 11:13:14.950146 28894 net.cpp:165] Memory required for data: 941082656
I0601 11:13:14.950153 28894 layer_factory.hpp:77] Creating layer conv9_1_relu
I0601 11:13:14.950160 28894 net.cpp:100] Creating Layer conv9_1_relu
I0601 11:13:14.950165 28894 net.cpp:434] conv9_1_relu <- conv9_1
I0601 11:13:14.950173 28894 net.cpp:395] conv9_1_relu -> conv9_1 (in-place)
I0601 11:13:14.950192 28894 net.cpp:150] Setting up conv9_1_relu
I0601 11:13:14.950199 28894 net.cpp:157] Top shape: 4 128 3 3 (4608)
I0601 11:13:14.950204 28894 net.cpp:165] Memory required for data: 941101088
I0601 11:13:14.950208 28894 layer_factory.hpp:77] Creating layer conv9_2
I0601 11:13:14.950218 28894 net.cpp:100] Creating Layer conv9_2
I0601 11:13:14.950223 28894 net.cpp:434] conv9_2 <- conv9_1
I0601 11:13:14.950232 28894 net.cpp:408] conv9_2 -> conv9_2
I0601 11:13:14.952399 28894 net.cpp:150] Setting up conv9_2
I0601 11:13:14.952409 28894 net.cpp:157] Top shape: 4 256 1 1 (1024)
I0601 11:13:14.952412 28894 net.cpp:165] Memory required for data: 941105184
I0601 11:13:14.952419 28894 layer_factory.hpp:77] Creating layer conv9_2_relu
I0601 11:13:14.952425 28894 net.cpp:100] Creating Layer conv9_2_relu
I0601 11:13:14.952430 28894 net.cpp:434] conv9_2_relu <- conv9_2
I0601 11:13:14.952438 28894 net.cpp:395] conv9_2_relu -> conv9_2 (in-place)
I0601 11:13:14.952446 28894 net.cpp:150] Setting up conv9_2_relu
I0601 11:13:14.952452 28894 net.cpp:157] Top shape: 4 256 1 1 (1024)
I0601 11:13:14.952456 28894 net.cpp:165] Memory required for data: 941109280
I0601 11:13:14.952461 28894 layer_factory.hpp:77] Creating layer conv9_2_conv9_2_relu_0_split
I0601 11:13:14.952467 28894 net.cpp:100] Creating Layer conv9_2_conv9_2_relu_0_split
I0601 11:13:14.952471 28894 net.cpp:434] conv9_2_conv9_2_relu_0_split <- conv9_2
I0601 11:13:14.952479 28894 net.cpp:408] conv9_2_conv9_2_relu_0_split -> conv9_2_conv9_2_relu_0_split_0
I0601 11:13:14.952487 28894 net.cpp:408] conv9_2_conv9_2_relu_0_split -> conv9_2_conv9_2_relu_0_split_1
I0601 11:13:14.952497 28894 net.cpp:408] conv9_2_conv9_2_relu_0_split -> conv9_2_conv9_2_relu_0_split_2
I0601 11:13:14.952554 28894 net.cpp:150] Setting up conv9_2_conv9_2_relu_0_split
I0601 11:13:14.952563 28894 net.cpp:157] Top shape: 4 256 1 1 (1024)
I0601 11:13:14.952569 28894 net.cpp:157] Top shape: 4 256 1 1 (1024)
I0601 11:13:14.952574 28894 net.cpp:157] Top shape: 4 256 1 1 (1024)
I0601 11:13:14.952579 28894 net.cpp:165] Memory required for data: 941121568
I0601 11:13:14.952582 28894 layer_factory.hpp:77] Creating layer conv4_3_norm
I0601 11:13:14.952591 28894 net.cpp:100] Creating Layer conv4_3_norm
I0601 11:13:14.952597 28894 net.cpp:434] conv4_3_norm <- conv4_3_relu4_3_0_split_1
I0601 11:13:14.952605 28894 net.cpp:408] conv4_3_norm -> conv4_3_norm
I0601 11:13:14.952775 28894 net.cpp:150] Setting up conv4_3_norm
I0601 11:13:14.952782 28894 net.cpp:157] Top shape: 4 512 38 38 (2957312)
I0601 11:13:14.952787 28894 net.cpp:165] Memory required for data: 952950816
I0601 11:13:14.952793 28894 layer_factory.hpp:77] Creating layer conv4_3_norm_conv4_3_norm_0_split
I0601 11:13:14.952800 28894 net.cpp:100] Creating Layer conv4_3_norm_conv4_3_norm_0_split
I0601 11:13:14.952805 28894 net.cpp:434] conv4_3_norm_conv4_3_norm_0_split <- conv4_3_norm
I0601 11:13:14.952811 28894 net.cpp:408] conv4_3_norm_conv4_3_norm_0_split -> conv4_3_norm_conv4_3_norm_0_split_0
I0601 11:13:14.952819 28894 net.cpp:408] conv4_3_norm_conv4_3_norm_0_split -> conv4_3_norm_conv4_3_norm_0_split_1
I0601 11:13:14.952827 28894 net.cpp:408] conv4_3_norm_conv4_3_norm_0_split -> conv4_3_norm_conv4_3_norm_0_split_2
I0601 11:13:14.952883 28894 net.cpp:150] Setting up conv4_3_norm_conv4_3_norm_0_split
I0601 11:13:14.952891 28894 net.cpp:157] Top shape: 4 512 38 38 (2957312)
I0601 11:13:14.952898 28894 net.cpp:157] Top shape: 4 512 38 38 (2957312)
I0601 11:13:14.952903 28894 net.cpp:157] Top shape: 4 512 38 38 (2957312)
I0601 11:13:14.952906 28894 net.cpp:165] Memory required for data: 988438560
I0601 11:13:14.952911 28894 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_loc
I0601 11:13:14.952921 28894 net.cpp:100] Creating Layer conv4_3_norm_mbox_loc
I0601 11:13:14.952927 28894 net.cpp:434] conv4_3_norm_mbox_loc <- conv4_3_norm_conv4_3_norm_0_split_0
I0601 11:13:14.952936 28894 net.cpp:408] conv4_3_norm_mbox_loc -> conv4_3_norm_mbox_loc
I0601 11:13:14.953769 28894 net.cpp:150] Setting up conv4_3_norm_mbox_loc
I0601 11:13:14.953780 28894 net.cpp:157] Top shape: 4 16 38 38 (92416)
I0601 11:13:14.953795 28894 net.cpp:165] Memory required for data: 988808224
I0601 11:13:14.953804 28894 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_loc_perm
I0601 11:13:14.953814 28894 net.cpp:100] Creating Layer conv4_3_norm_mbox_loc_perm
I0601 11:13:14.953819 28894 net.cpp:434] conv4_3_norm_mbox_loc_perm <- conv4_3_norm_mbox_loc
I0601 11:13:14.953827 28894 net.cpp:408] conv4_3_norm_mbox_loc_perm -> conv4_3_norm_mbox_loc_perm
I0601 11:13:14.953938 28894 net.cpp:150] Setting up conv4_3_norm_mbox_loc_perm
I0601 11:13:14.953948 28894 net.cpp:157] Top shape: 4 38 38 16 (92416)
I0601 11:13:14.953951 28894 net.cpp:165] Memory required for data: 989177888
I0601 11:13:14.953955 28894 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_loc_flat
I0601 11:13:14.953963 28894 net.cpp:100] Creating Layer conv4_3_norm_mbox_loc_flat
I0601 11:13:14.953969 28894 net.cpp:434] conv4_3_norm_mbox_loc_flat <- conv4_3_norm_mbox_loc_perm
I0601 11:13:14.953979 28894 net.cpp:408] conv4_3_norm_mbox_loc_flat -> conv4_3_norm_mbox_loc_flat
I0601 11:13:14.954015 28894 net.cpp:150] Setting up conv4_3_norm_mbox_loc_flat
I0601 11:13:14.954023 28894 net.cpp:157] Top shape: 4 23104 (92416)
I0601 11:13:14.954028 28894 net.cpp:165] Memory required for data: 989547552
I0601 11:13:14.954032 28894 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_conf
I0601 11:13:14.954049 28894 net.cpp:100] Creating Layer conv4_3_norm_mbox_conf
I0601 11:13:14.954056 28894 net.cpp:434] conv4_3_norm_mbox_conf <- conv4_3_norm_conv4_3_norm_0_split_1
I0601 11:13:14.954063 28894 net.cpp:408] conv4_3_norm_mbox_conf -> conv4_3_norm_mbox_conf
I0601 11:13:14.954731 28894 net.cpp:150] Setting up conv4_3_norm_mbox_conf
I0601 11:13:14.954741 28894 net.cpp:157] Top shape: 4 16 38 38 (92416)
I0601 11:13:14.954744 28894 net.cpp:165] Memory required for data: 989917216
I0601 11:13:14.954751 28894 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_conf_perm
I0601 11:13:14.954762 28894 net.cpp:100] Creating Layer conv4_3_norm_mbox_conf_perm
I0601 11:13:14.954768 28894 net.cpp:434] conv4_3_norm_mbox_conf_perm <- conv4_3_norm_mbox_conf
I0601 11:13:14.954776 28894 net.cpp:408] conv4_3_norm_mbox_conf_perm -> conv4_3_norm_mbox_conf_perm
I0601 11:13:14.954885 28894 net.cpp:150] Setting up conv4_3_norm_mbox_conf_perm
I0601 11:13:14.954896 28894 net.cpp:157] Top shape: 4 38 38 16 (92416)
I0601 11:13:14.954900 28894 net.cpp:165] Memory required for data: 990286880
I0601 11:13:14.954905 28894 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_conf_flat
I0601 11:13:14.954912 28894 net.cpp:100] Creating Layer conv4_3_norm_mbox_conf_flat
I0601 11:13:14.954918 28894 net.cpp:434] conv4_3_norm_mbox_conf_flat <- conv4_3_norm_mbox_conf_perm
I0601 11:13:14.954926 28894 net.cpp:408] conv4_3_norm_mbox_conf_flat -> conv4_3_norm_mbox_conf_flat
I0601 11:13:14.954951 28894 net.cpp:150] Setting up conv4_3_norm_mbox_conf_flat
I0601 11:13:14.954957 28894 net.cpp:157] Top shape: 4 23104 (92416)
I0601 11:13:14.954962 28894 net.cpp:165] Memory required for data: 990656544
I0601 11:13:14.954967 28894 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_priorbox
I0601 11:13:14.954975 28894 net.cpp:100] Creating Layer conv4_3_norm_mbox_priorbox
I0601 11:13:14.954980 28894 net.cpp:434] conv4_3_norm_mbox_priorbox <- conv4_3_norm_conv4_3_norm_0_split_2
I0601 11:13:14.954988 28894 net.cpp:434] conv4_3_norm_mbox_priorbox <- data_data_0_split_1
I0601 11:13:14.954994 28894 net.cpp:408] conv4_3_norm_mbox_priorbox -> conv4_3_norm_mbox_priorbox
I0601 11:13:14.955021 28894 net.cpp:150] Setting up conv4_3_norm_mbox_priorbox
I0601 11:13:14.955029 28894 net.cpp:157] Top shape: 1 2 23104 (46208)
I0601 11:13:14.955034 28894 net.cpp:165] Memory required for data: 990841376
I0601 11:13:14.955039 28894 layer_factory.hpp:77] Creating layer fc7_mbox_loc
I0601 11:13:14.955049 28894 net.cpp:100] Creating Layer fc7_mbox_loc
I0601 11:13:14.955055 28894 net.cpp:434] fc7_mbox_loc <- fc7_relu7_0_split_1
I0601 11:13:14.955065 28894 net.cpp:408] fc7_mbox_loc -> fc7_mbox_loc
I0601 11:13:14.956411 28894 net.cpp:150] Setting up fc7_mbox_loc
I0601 11:13:14.956426 28894 net.cpp:157] Top shape: 4 24 19 19 (34656)
I0601 11:13:14.956430 28894 net.cpp:165] Memory required for data: 990980000
I0601 11:13:14.956439 28894 layer_factory.hpp:77] Creating layer fc7_mbox_loc_perm
I0601 11:13:14.956446 28894 net.cpp:100] Creating Layer fc7_mbox_loc_perm
I0601 11:13:14.956451 28894 net.cpp:434] fc7_mbox_loc_perm <- fc7_mbox_loc
I0601 11:13:14.956459 28894 net.cpp:408] fc7_mbox_loc_perm -> fc7_mbox_loc_perm
I0601 11:13:14.956570 28894 net.cpp:150] Setting up fc7_mbox_loc_perm
I0601 11:13:14.956580 28894 net.cpp:157] Top shape: 4 19 19 24 (34656)
I0601 11:13:14.956585 28894 net.cpp:165] Memory required for data: 991118624
I0601 11:13:14.956589 28894 layer_factory.hpp:77] Creating layer fc7_mbox_loc_flat
I0601 11:13:14.956598 28894 net.cpp:100] Creating Layer fc7_mbox_loc_flat
I0601 11:13:14.956603 28894 net.cpp:434] fc7_mbox_loc_flat <- fc7_mbox_loc_perm
I0601 11:13:14.956610 28894 net.cpp:408] fc7_mbox_loc_flat -> fc7_mbox_loc_flat
I0601 11:13:14.956635 28894 net.cpp:150] Setting up fc7_mbox_loc_flat
I0601 11:13:14.956643 28894 net.cpp:157] Top shape: 4 8664 (34656)
I0601 11:13:14.956647 28894 net.cpp:165] Memory required for data: 991257248
I0601 11:13:14.956651 28894 layer_factory.hpp:77] Creating layer fc7_mbox_conf
I0601 11:13:14.956661 28894 net.cpp:100] Creating Layer fc7_mbox_conf
I0601 11:13:14.956667 28894 net.cpp:434] fc7_mbox_conf <- fc7_relu7_0_split_2
I0601 11:13:14.956676 28894 net.cpp:408] fc7_mbox_conf -> fc7_mbox_conf
I0601 11:13:14.958184 28894 net.cpp:150] Setting up fc7_mbox_conf
I0601 11:13:14.958192 28894 net.cpp:157] Top shape: 4 24 19 19 (34656)
I0601 11:13:14.958195 28894 net.cpp:165] Memory required for data: 991395872
I0601 11:13:14.958201 28894 layer_factory.hpp:77] Creating layer fc7_mbox_conf_perm
I0601 11:13:14.958210 28894 net.cpp:100] Creating Layer fc7_mbox_conf_perm
I0601 11:13:14.958215 28894 net.cpp:434] fc7_mbox_conf_perm <- fc7_mbox_conf
I0601 11:13:14.958225 28894 net.cpp:408] fc7_mbox_conf_perm -> fc7_mbox_conf_perm
I0601 11:13:14.958335 28894 net.cpp:150] Setting up fc7_mbox_conf_perm
I0601 11:13:14.958345 28894 net.cpp:157] Top shape: 4 19 19 24 (34656)
I0601 11:13:14.958349 28894 net.cpp:165] Memory required for data: 991534496
I0601 11:13:14.958354 28894 layer_factory.hpp:77] Creating layer fc7_mbox_conf_flat
I0601 11:13:14.958362 28894 net.cpp:100] Creating Layer fc7_mbox_conf_flat
I0601 11:13:14.958369 28894 net.cpp:434] fc7_mbox_conf_flat <- fc7_mbox_conf_perm
I0601 11:13:14.958374 28894 net.cpp:408] fc7_mbox_conf_flat -> fc7_mbox_conf_flat
I0601 11:13:14.958401 28894 net.cpp:150] Setting up fc7_mbox_conf_flat
I0601 11:13:14.958408 28894 net.cpp:157] Top shape: 4 8664 (34656)
I0601 11:13:14.958412 28894 net.cpp:165] Memory required for data: 991673120
I0601 11:13:14.958416 28894 layer_factory.hpp:77] Creating layer fc7_mbox_priorbox
I0601 11:13:14.958425 28894 net.cpp:100] Creating Layer fc7_mbox_priorbox
I0601 11:13:14.958431 28894 net.cpp:434] fc7_mbox_priorbox <- fc7_relu7_0_split_3
I0601 11:13:14.958436 28894 net.cpp:434] fc7_mbox_priorbox <- data_data_0_split_2
I0601 11:13:14.958443 28894 net.cpp:408] fc7_mbox_priorbox -> fc7_mbox_priorbox
I0601 11:13:14.958472 28894 net.cpp:150] Setting up fc7_mbox_priorbox
I0601 11:13:14.958478 28894 net.cpp:157] Top shape: 1 2 8664 (17328)
I0601 11:13:14.958482 28894 net.cpp:165] Memory required for data: 991742432
I0601 11:13:14.958487 28894 layer_factory.hpp:77] Creating layer conv6_2_mbox_loc
I0601 11:13:14.958498 28894 net.cpp:100] Creating Layer conv6_2_mbox_loc
I0601 11:13:14.958503 28894 net.cpp:434] conv6_2_mbox_loc <- conv6_2_conv6_2_relu_0_split_1
I0601 11:13:14.958513 28894 net.cpp:408] conv6_2_mbox_loc -> conv6_2_mbox_loc
I0601 11:13:14.959434 28894 net.cpp:150] Setting up conv6_2_mbox_loc
I0601 11:13:14.959444 28894 net.cpp:157] Top shape: 4 24 10 10 (9600)
I0601 11:13:14.959445 28894 net.cpp:165] Memory required for data: 991780832
I0601 11:13:14.959451 28894 layer_factory.hpp:77] Creating layer conv6_2_mbox_loc_perm
I0601 11:13:14.959470 28894 net.cpp:100] Creating Layer conv6_2_mbox_loc_perm
I0601 11:13:14.959475 28894 net.cpp:434] conv6_2_mbox_loc_perm <- conv6_2_mbox_loc
I0601 11:13:14.959484 28894 net.cpp:408] conv6_2_mbox_loc_perm -> conv6_2_mbox_loc_perm
I0601 11:13:14.959599 28894 net.cpp:150] Setting up conv6_2_mbox_loc_perm
I0601 11:13:14.959610 28894 net.cpp:157] Top shape: 4 10 10 24 (9600)
I0601 11:13:14.959616 28894 net.cpp:165] Memory required for data: 991819232
I0601 11:13:14.959620 28894 layer_factory.hpp:77] Creating layer conv6_2_mbox_loc_flat
I0601 11:13:14.959626 28894 net.cpp:100] Creating Layer conv6_2_mbox_loc_flat
I0601 11:13:14.959631 28894 net.cpp:434] conv6_2_mbox_loc_flat <- conv6_2_mbox_loc_perm
I0601 11:13:14.959640 28894 net.cpp:408] conv6_2_mbox_loc_flat -> conv6_2_mbox_loc_flat
I0601 11:13:14.959666 28894 net.cpp:150] Setting up conv6_2_mbox_loc_flat
I0601 11:13:14.959672 28894 net.cpp:157] Top shape: 4 2400 (9600)
I0601 11:13:14.959676 28894 net.cpp:165] Memory required for data: 991857632
I0601 11:13:14.959682 28894 layer_factory.hpp:77] Creating layer conv6_2_mbox_conf
I0601 11:13:14.959692 28894 net.cpp:100] Creating Layer conv6_2_mbox_conf
I0601 11:13:14.959697 28894 net.cpp:434] conv6_2_mbox_conf <- conv6_2_conv6_2_relu_0_split_2
I0601 11:13:14.959705 28894 net.cpp:408] conv6_2_mbox_conf -> conv6_2_mbox_conf
I0601 11:13:14.960595 28894 net.cpp:150] Setting up conv6_2_mbox_conf
I0601 11:13:14.960604 28894 net.cpp:157] Top shape: 4 24 10 10 (9600)
I0601 11:13:14.960608 28894 net.cpp:165] Memory required for data: 991896032
I0601 11:13:14.960613 28894 layer_factory.hpp:77] Creating layer conv6_2_mbox_conf_perm
I0601 11:13:14.960623 28894 net.cpp:100] Creating Layer conv6_2_mbox_conf_perm
I0601 11:13:14.960628 28894 net.cpp:434] conv6_2_mbox_conf_perm <- conv6_2_mbox_conf
I0601 11:13:14.960635 28894 net.cpp:408] conv6_2_mbox_conf_perm -> conv6_2_mbox_conf_perm
I0601 11:13:14.960747 28894 net.cpp:150] Setting up conv6_2_mbox_conf_perm
I0601 11:13:14.960757 28894 net.cpp:157] Top shape: 4 10 10 24 (9600)
I0601 11:13:14.960762 28894 net.cpp:165] Memory required for data: 991934432
I0601 11:13:14.960765 28894 layer_factory.hpp:77] Creating layer conv6_2_mbox_conf_flat
I0601 11:13:14.960772 28894 net.cpp:100] Creating Layer conv6_2_mbox_conf_flat
I0601 11:13:14.960778 28894 net.cpp:434] conv6_2_mbox_conf_flat <- conv6_2_mbox_conf_perm
I0601 11:13:14.960786 28894 net.cpp:408] conv6_2_mbox_conf_flat -> conv6_2_mbox_conf_flat
I0601 11:13:14.960813 28894 net.cpp:150] Setting up conv6_2_mbox_conf_flat
I0601 11:13:14.960819 28894 net.cpp:157] Top shape: 4 2400 (9600)
I0601 11:13:14.960824 28894 net.cpp:165] Memory required for data: 991972832
I0601 11:13:14.960827 28894 layer_factory.hpp:77] Creating layer conv6_2_mbox_priorbox
I0601 11:13:14.960835 28894 net.cpp:100] Creating Layer conv6_2_mbox_priorbox
I0601 11:13:14.960839 28894 net.cpp:434] conv6_2_mbox_priorbox <- conv6_2_conv6_2_relu_0_split_3
I0601 11:13:14.960846 28894 net.cpp:434] conv6_2_mbox_priorbox <- data_data_0_split_3
I0601 11:13:14.960855 28894 net.cpp:408] conv6_2_mbox_priorbox -> conv6_2_mbox_priorbox
I0601 11:13:14.960889 28894 net.cpp:150] Setting up conv6_2_mbox_priorbox
I0601 11:13:14.960897 28894 net.cpp:157] Top shape: 1 2 2400 (4800)
I0601 11:13:14.960902 28894 net.cpp:165] Memory required for data: 991992032
I0601 11:13:14.960906 28894 layer_factory.hpp:77] Creating layer conv7_2_mbox_loc
I0601 11:13:14.960916 28894 net.cpp:100] Creating Layer conv7_2_mbox_loc
I0601 11:13:14.960922 28894 net.cpp:434] conv7_2_mbox_loc <- conv7_2_conv7_2_relu_0_split_1
I0601 11:13:14.960932 28894 net.cpp:408] conv7_2_mbox_loc -> conv7_2_mbox_loc
I0601 11:13:14.961575 28894 net.cpp:150] Setting up conv7_2_mbox_loc
I0601 11:13:14.961586 28894 net.cpp:157] Top shape: 4 24 5 5 (2400)
I0601 11:13:14.961591 28894 net.cpp:165] Memory required for data: 992001632
I0601 11:13:14.961599 28894 layer_factory.hpp:77] Creating layer conv7_2_mbox_loc_perm
I0601 11:13:14.961609 28894 net.cpp:100] Creating Layer conv7_2_mbox_loc_perm
I0601 11:13:14.961614 28894 net.cpp:434] conv7_2_mbox_loc_perm <- conv7_2_mbox_loc
I0601 11:13:14.961633 28894 net.cpp:408] conv7_2_mbox_loc_perm -> conv7_2_mbox_loc_perm
I0601 11:13:14.961755 28894 net.cpp:150] Setting up conv7_2_mbox_loc_perm
I0601 11:13:14.961763 28894 net.cpp:157] Top shape: 4 5 5 24 (2400)
I0601 11:13:14.961768 28894 net.cpp:165] Memory required for data: 992011232
I0601 11:13:14.961771 28894 layer_factory.hpp:77] Creating layer conv7_2_mbox_loc_flat
I0601 11:13:14.961796 28894 net.cpp:100] Creating Layer conv7_2_mbox_loc_flat
I0601 11:13:14.961802 28894 net.cpp:434] conv7_2_mbox_loc_flat <- conv7_2_mbox_loc_perm
I0601 11:13:14.961822 28894 net.cpp:408] conv7_2_mbox_loc_flat -> conv7_2_mbox_loc_flat
I0601 11:13:14.961875 28894 net.cpp:150] Setting up conv7_2_mbox_loc_flat
I0601 11:13:14.961884 28894 net.cpp:157] Top shape: 4 600 (2400)
I0601 11:13:14.961887 28894 net.cpp:165] Memory required for data: 992020832
I0601 11:13:14.961891 28894 layer_factory.hpp:77] Creating layer conv7_2_mbox_conf
I0601 11:13:14.961916 28894 net.cpp:100] Creating Layer conv7_2_mbox_conf
I0601 11:13:14.961922 28894 net.cpp:434] conv7_2_mbox_conf <- conv7_2_conv7_2_relu_0_split_2
I0601 11:13:14.961946 28894 net.cpp:408] conv7_2_mbox_conf -> conv7_2_mbox_conf
I0601 11:13:14.962555 28894 net.cpp:150] Setting up conv7_2_mbox_conf
I0601 11:13:14.962564 28894 net.cpp:157] Top shape: 4 24 5 5 (2400)
I0601 11:13:14.962568 28894 net.cpp:165] Memory required for data: 992030432
I0601 11:13:14.962589 28894 layer_factory.hpp:77] Creating layer conv7_2_mbox_conf_perm
I0601 11:13:14.962595 28894 net.cpp:100] Creating Layer conv7_2_mbox_conf_perm
I0601 11:13:14.962613 28894 net.cpp:434] conv7_2_mbox_conf_perm <- conv7_2_mbox_conf
I0601 11:13:14.962622 28894 net.cpp:408] conv7_2_mbox_conf_perm -> conv7_2_mbox_conf_perm
I0601 11:13:14.962748 28894 net.cpp:150] Setting up conv7_2_mbox_conf_perm
I0601 11:13:14.962757 28894 net.cpp:157] Top shape: 4 5 5 24 (2400)
I0601 11:13:14.962761 28894 net.cpp:165] Memory required for data: 992040032
I0601 11:13:14.962766 28894 layer_factory.hpp:77] Creating layer conv7_2_mbox_conf_flat
I0601 11:13:14.962774 28894 net.cpp:100] Creating Layer conv7_2_mbox_conf_flat
I0601 11:13:14.962779 28894 net.cpp:434] conv7_2_mbox_conf_flat <- conv7_2_mbox_conf_perm
I0601 11:13:14.962787 28894 net.cpp:408] conv7_2_mbox_conf_flat -> conv7_2_mbox_conf_flat
I0601 11:13:14.962812 28894 net.cpp:150] Setting up conv7_2_mbox_conf_flat
I0601 11:13:14.962819 28894 net.cpp:157] Top shape: 4 600 (2400)
I0601 11:13:14.962823 28894 net.cpp:165] Memory required for data: 992049632
I0601 11:13:14.962827 28894 layer_factory.hpp:77] Creating layer conv7_2_mbox_priorbox
I0601 11:13:14.962836 28894 net.cpp:100] Creating Layer conv7_2_mbox_priorbox
I0601 11:13:14.962842 28894 net.cpp:434] conv7_2_mbox_priorbox <- conv7_2_conv7_2_relu_0_split_3
I0601 11:13:14.962847 28894 net.cpp:434] conv7_2_mbox_priorbox <- data_data_0_split_4
I0601 11:13:14.962855 28894 net.cpp:408] conv7_2_mbox_priorbox -> conv7_2_mbox_priorbox
I0601 11:13:14.962882 28894 net.cpp:150] Setting up conv7_2_mbox_priorbox
I0601 11:13:14.962889 28894 net.cpp:157] Top shape: 1 2 600 (1200)
I0601 11:13:14.962894 28894 net.cpp:165] Memory required for data: 992054432
I0601 11:13:14.962898 28894 layer_factory.hpp:77] Creating layer conv8_2_mbox_loc
I0601 11:13:14.962909 28894 net.cpp:100] Creating Layer conv8_2_mbox_loc
I0601 11:13:14.962915 28894 net.cpp:434] conv8_2_mbox_loc <- conv8_2_conv8_2_relu_0_split_1
I0601 11:13:14.962923 28894 net.cpp:408] conv8_2_mbox_loc -> conv8_2_mbox_loc
I0601 11:13:14.963450 28894 net.cpp:150] Setting up conv8_2_mbox_loc
I0601 11:13:14.963474 28894 net.cpp:157] Top shape: 4 16 3 3 (576)
I0601 11:13:14.963479 28894 net.cpp:165] Memory required for data: 992056736
I0601 11:13:14.963496 28894 layer_factory.hpp:77] Creating layer conv8_2_mbox_loc_perm
I0601 11:13:14.963505 28894 net.cpp:100] Creating Layer conv8_2_mbox_loc_perm
I0601 11:13:14.963511 28894 net.cpp:434] conv8_2_mbox_loc_perm <- conv8_2_mbox_loc
I0601 11:13:14.963533 28894 net.cpp:408] conv8_2_mbox_loc_perm -> conv8_2_mbox_loc_perm
I0601 11:13:14.963655 28894 net.cpp:150] Setting up conv8_2_mbox_loc_perm
I0601 11:13:14.963663 28894 net.cpp:157] Top shape: 4 3 3 16 (576)
I0601 11:13:14.963670 28894 net.cpp:165] Memory required for data: 992059040
I0601 11:13:14.963673 28894 layer_factory.hpp:77] Creating layer conv8_2_mbox_loc_flat
I0601 11:13:14.963680 28894 net.cpp:100] Creating Layer conv8_2_mbox_loc_flat
I0601 11:13:14.963685 28894 net.cpp:434] conv8_2_mbox_loc_flat <- conv8_2_mbox_loc_perm
I0601 11:13:14.963696 28894 net.cpp:408] conv8_2_mbox_loc_flat -> conv8_2_mbox_loc_flat
I0601 11:13:14.963721 28894 net.cpp:150] Setting up conv8_2_mbox_loc_flat
I0601 11:13:14.963728 28894 net.cpp:157] Top shape: 4 144 (576)
I0601 11:13:14.963733 28894 net.cpp:165] Memory required for data: 992061344
I0601 11:13:14.963738 28894 layer_factory.hpp:77] Creating layer conv8_2_mbox_conf
I0601 11:13:14.963749 28894 net.cpp:100] Creating Layer conv8_2_mbox_conf
I0601 11:13:14.963755 28894 net.cpp:434] conv8_2_mbox_conf <- conv8_2_conv8_2_relu_0_split_2
I0601 11:13:14.963763 28894 net.cpp:408] conv8_2_mbox_conf -> conv8_2_mbox_conf
I0601 11:13:14.964300 28894 net.cpp:150] Setting up conv8_2_mbox_conf
I0601 11:13:14.964311 28894 net.cpp:157] Top shape: 4 16 3 3 (576)
I0601 11:13:14.964316 28894 net.cpp:165] Memory required for data: 992063648
I0601 11:13:14.964323 28894 layer_factory.hpp:77] Creating layer conv8_2_mbox_conf_perm
I0601 11:13:14.964332 28894 net.cpp:100] Creating Layer conv8_2_mbox_conf_perm
I0601 11:13:14.964339 28894 net.cpp:434] conv8_2_mbox_conf_perm <- conv8_2_mbox_conf
I0601 11:13:14.964345 28894 net.cpp:408] conv8_2_mbox_conf_perm -> conv8_2_mbox_conf_perm
I0601 11:13:14.964457 28894 net.cpp:150] Setting up conv8_2_mbox_conf_perm
I0601 11:13:14.964464 28894 net.cpp:157] Top shape: 4 3 3 16 (576)
I0601 11:13:14.964469 28894 net.cpp:165] Memory required for data: 992065952
I0601 11:13:14.964473 28894 layer_factory.hpp:77] Creating layer conv8_2_mbox_conf_flat
I0601 11:13:14.964479 28894 net.cpp:100] Creating Layer conv8_2_mbox_conf_flat
I0601 11:13:14.964484 28894 net.cpp:434] conv8_2_mbox_conf_flat <- conv8_2_mbox_conf_perm
I0601 11:13:14.964494 28894 net.cpp:408] conv8_2_mbox_conf_flat -> conv8_2_mbox_conf_flat
I0601 11:13:14.964521 28894 net.cpp:150] Setting up conv8_2_mbox_conf_flat
I0601 11:13:14.964529 28894 net.cpp:157] Top shape: 4 144 (576)
I0601 11:13:14.964532 28894 net.cpp:165] Memory required for data: 992068256
I0601 11:13:14.964537 28894 layer_factory.hpp:77] Creating layer conv8_2_mbox_priorbox
I0601 11:13:14.964545 28894 net.cpp:100] Creating Layer conv8_2_mbox_priorbox
I0601 11:13:14.964550 28894 net.cpp:434] conv8_2_mbox_priorbox <- conv8_2_conv8_2_relu_0_split_3
I0601 11:13:14.964555 28894 net.cpp:434] conv8_2_mbox_priorbox <- data_data_0_split_5
I0601 11:13:14.964566 28894 net.cpp:408] conv8_2_mbox_priorbox -> conv8_2_mbox_priorbox
I0601 11:13:14.964594 28894 net.cpp:150] Setting up conv8_2_mbox_priorbox
I0601 11:13:14.964601 28894 net.cpp:157] Top shape: 1 2 144 (288)
I0601 11:13:14.964606 28894 net.cpp:165] Memory required for data: 992069408
I0601 11:13:14.964612 28894 layer_factory.hpp:77] Creating layer conv9_2_mbox_loc
I0601 11:13:14.964622 28894 net.cpp:100] Creating Layer conv9_2_mbox_loc
I0601 11:13:14.964627 28894 net.cpp:434] conv9_2_mbox_loc <- conv9_2_conv9_2_relu_0_split_0
I0601 11:13:14.964637 28894 net.cpp:408] conv9_2_mbox_loc -> conv9_2_mbox_loc
I0601 11:13:14.965175 28894 net.cpp:150] Setting up conv9_2_mbox_loc
I0601 11:13:14.965186 28894 net.cpp:157] Top shape: 4 16 1 1 (64)
I0601 11:13:14.965190 28894 net.cpp:165] Memory required for data: 992069664
I0601 11:13:14.965198 28894 layer_factory.hpp:77] Creating layer conv9_2_mbox_loc_perm
I0601 11:13:14.965206 28894 net.cpp:100] Creating Layer conv9_2_mbox_loc_perm
I0601 11:13:14.965214 28894 net.cpp:434] conv9_2_mbox_loc_perm <- conv9_2_mbox_loc
I0601 11:13:14.965221 28894 net.cpp:408] conv9_2_mbox_loc_perm -> conv9_2_mbox_loc_perm
I0601 11:13:14.965327 28894 net.cpp:150] Setting up conv9_2_mbox_loc_perm
I0601 11:13:14.965335 28894 net.cpp:157] Top shape: 4 1 1 16 (64)
I0601 11:13:14.965349 28894 net.cpp:165] Memory required for data: 992069920
I0601 11:13:14.965354 28894 layer_factory.hpp:77] Creating layer conv9_2_mbox_loc_flat
I0601 11:13:14.965363 28894 net.cpp:100] Creating Layer conv9_2_mbox_loc_flat
I0601 11:13:14.965368 28894 net.cpp:434] conv9_2_mbox_loc_flat <- conv9_2_mbox_loc_perm
I0601 11:13:14.965375 28894 net.cpp:408] conv9_2_mbox_loc_flat -> conv9_2_mbox_loc_flat
I0601 11:13:14.965400 28894 net.cpp:150] Setting up conv9_2_mbox_loc_flat
I0601 11:13:14.965407 28894 net.cpp:157] Top shape: 4 16 (64)
I0601 11:13:14.965411 28894 net.cpp:165] Memory required for data: 992070176
I0601 11:13:14.965416 28894 layer_factory.hpp:77] Creating layer conv9_2_mbox_conf
I0601 11:13:14.965426 28894 net.cpp:100] Creating Layer conv9_2_mbox_conf
I0601 11:13:14.965432 28894 net.cpp:434] conv9_2_mbox_conf <- conv9_2_conv9_2_relu_0_split_1
I0601 11:13:14.965440 28894 net.cpp:408] conv9_2_mbox_conf -> conv9_2_mbox_conf
I0601 11:13:14.965939 28894 net.cpp:150] Setting up conv9_2_mbox_conf
I0601 11:13:14.965948 28894 net.cpp:157] Top shape: 4 16 1 1 (64)
I0601 11:13:14.965950 28894 net.cpp:165] Memory required for data: 992070432
I0601 11:13:14.965955 28894 layer_factory.hpp:77] Creating layer conv9_2_mbox_conf_perm
I0601 11:13:14.965963 28894 net.cpp:100] Creating Layer conv9_2_mbox_conf_perm
I0601 11:13:14.965968 28894 net.cpp:434] conv9_2_mbox_conf_perm <- conv9_2_mbox_conf
I0601 11:13:14.965976 28894 net.cpp:408] conv9_2_mbox_conf_perm -> conv9_2_mbox_conf_perm
I0601 11:13:14.966087 28894 net.cpp:150] Setting up conv9_2_mbox_conf_perm
I0601 11:13:14.966099 28894 net.cpp:157] Top shape: 4 1 1 16 (64)
I0601 11:13:14.966102 28894 net.cpp:165] Memory required for data: 992070688
I0601 11:13:14.966106 28894 layer_factory.hpp:77] Creating layer conv9_2_mbox_conf_flat
I0601 11:13:14.966114 28894 net.cpp:100] Creating Layer conv9_2_mbox_conf_flat
I0601 11:13:14.966120 28894 net.cpp:434] conv9_2_mbox_conf_flat <- conv9_2_mbox_conf_perm
I0601 11:13:14.966126 28894 net.cpp:408] conv9_2_mbox_conf_flat -> conv9_2_mbox_conf_flat
I0601 11:13:14.966151 28894 net.cpp:150] Setting up conv9_2_mbox_conf_flat
I0601 11:13:14.966157 28894 net.cpp:157] Top shape: 4 16 (64)
I0601 11:13:14.966162 28894 net.cpp:165] Memory required for data: 992070944
I0601 11:13:14.966166 28894 layer_factory.hpp:77] Creating layer conv9_2_mbox_priorbox
I0601 11:13:14.966174 28894 net.cpp:100] Creating Layer conv9_2_mbox_priorbox
I0601 11:13:14.966179 28894 net.cpp:434] conv9_2_mbox_priorbox <- conv9_2_conv9_2_relu_0_split_2
I0601 11:13:14.966186 28894 net.cpp:434] conv9_2_mbox_priorbox <- data_data_0_split_6
I0601 11:13:14.966193 28894 net.cpp:408] conv9_2_mbox_priorbox -> conv9_2_mbox_priorbox
I0601 11:13:14.966218 28894 net.cpp:150] Setting up conv9_2_mbox_priorbox
I0601 11:13:14.966225 28894 net.cpp:157] Top shape: 1 2 16 (32)
I0601 11:13:14.966230 28894 net.cpp:165] Memory required for data: 992071072
I0601 11:13:14.966234 28894 layer_factory.hpp:77] Creating layer mbox_loc
I0601 11:13:14.966241 28894 net.cpp:100] Creating Layer mbox_loc
I0601 11:13:14.966248 28894 net.cpp:434] mbox_loc <- conv4_3_norm_mbox_loc_flat
I0601 11:13:14.966254 28894 net.cpp:434] mbox_loc <- fc7_mbox_loc_flat
I0601 11:13:14.966260 28894 net.cpp:434] mbox_loc <- conv6_2_mbox_loc_flat
I0601 11:13:14.966266 28894 net.cpp:434] mbox_loc <- conv7_2_mbox_loc_flat
I0601 11:13:14.966271 28894 net.cpp:434] mbox_loc <- conv8_2_mbox_loc_flat
I0601 11:13:14.966277 28894 net.cpp:434] mbox_loc <- conv9_2_mbox_loc_flat
I0601 11:13:14.966284 28894 net.cpp:408] mbox_loc -> mbox_loc
I0601 11:13:14.966310 28894 net.cpp:150] Setting up mbox_loc
I0601 11:13:14.966317 28894 net.cpp:157] Top shape: 4 34928 (139712)
I0601 11:13:14.966322 28894 net.cpp:165] Memory required for data: 992629920
I0601 11:13:14.966325 28894 layer_factory.hpp:77] Creating layer mbox_conf
I0601 11:13:14.966332 28894 net.cpp:100] Creating Layer mbox_conf
I0601 11:13:14.966337 28894 net.cpp:434] mbox_conf <- conv4_3_norm_mbox_conf_flat
I0601 11:13:14.966344 28894 net.cpp:434] mbox_conf <- fc7_mbox_conf_flat
I0601 11:13:14.966358 28894 net.cpp:434] mbox_conf <- conv6_2_mbox_conf_flat
I0601 11:13:14.966364 28894 net.cpp:434] mbox_conf <- conv7_2_mbox_conf_flat
I0601 11:13:14.966369 28894 net.cpp:434] mbox_conf <- conv8_2_mbox_conf_flat
I0601 11:13:14.966375 28894 net.cpp:434] mbox_conf <- conv9_2_mbox_conf_flat
I0601 11:13:14.966382 28894 net.cpp:408] mbox_conf -> mbox_conf
I0601 11:13:14.966405 28894 net.cpp:150] Setting up mbox_conf
I0601 11:13:14.966413 28894 net.cpp:157] Top shape: 4 34928 (139712)
I0601 11:13:14.966418 28894 net.cpp:165] Memory required for data: 993188768
I0601 11:13:14.966421 28894 layer_factory.hpp:77] Creating layer mbox_priorbox
I0601 11:13:14.966426 28894 net.cpp:100] Creating Layer mbox_priorbox
I0601 11:13:14.966431 28894 net.cpp:434] mbox_priorbox <- conv4_3_norm_mbox_priorbox
I0601 11:13:14.966437 28894 net.cpp:434] mbox_priorbox <- fc7_mbox_priorbox
I0601 11:13:14.966444 28894 net.cpp:434] mbox_priorbox <- conv6_2_mbox_priorbox
I0601 11:13:14.966447 28894 net.cpp:434] mbox_priorbox <- conv7_2_mbox_priorbox
I0601 11:13:14.966452 28894 net.cpp:434] mbox_priorbox <- conv8_2_mbox_priorbox
I0601 11:13:14.966457 28894 net.cpp:434] mbox_priorbox <- conv9_2_mbox_priorbox
I0601 11:13:14.966465 28894 net.cpp:408] mbox_priorbox -> mbox_priorbox
I0601 11:13:14.966490 28894 net.cpp:150] Setting up mbox_priorbox
I0601 11:13:14.966497 28894 net.cpp:157] Top shape: 1 2 34928 (69856)
I0601 11:13:14.966501 28894 net.cpp:165] Memory required for data: 993468192
I0601 11:13:14.966506 28894 layer_factory.hpp:77] Creating layer mbox_conf_reshape
I0601 11:13:14.966512 28894 net.cpp:100] Creating Layer mbox_conf_reshape
I0601 11:13:14.966517 28894 net.cpp:434] mbox_conf_reshape <- mbox_conf
I0601 11:13:14.966526 28894 net.cpp:408] mbox_conf_reshape -> mbox_conf_reshape
I0601 11:13:14.966557 28894 net.cpp:150] Setting up mbox_conf_reshape
I0601 11:13:14.966565 28894 net.cpp:157] Top shape: 4 8732 4 (139712)
I0601 11:13:14.966570 28894 net.cpp:165] Memory required for data: 994027040
I0601 11:13:14.966575 28894 layer_factory.hpp:77] Creating layer mbox_conf_softmax
I0601 11:13:14.966583 28894 net.cpp:100] Creating Layer mbox_conf_softmax
I0601 11:13:14.966588 28894 net.cpp:434] mbox_conf_softmax <- mbox_conf_reshape
I0601 11:13:14.966593 28894 net.cpp:408] mbox_conf_softmax -> mbox_conf_softmax
I0601 11:13:14.966660 28894 net.cpp:150] Setting up mbox_conf_softmax
I0601 11:13:14.966666 28894 net.cpp:157] Top shape: 4 8732 4 (139712)
I0601 11:13:14.966671 28894 net.cpp:165] Memory required for data: 994585888
I0601 11:13:14.966675 28894 layer_factory.hpp:77] Creating layer mbox_conf_flatten
I0601 11:13:14.966681 28894 net.cpp:100] Creating Layer mbox_conf_flatten
I0601 11:13:14.966686 28894 net.cpp:434] mbox_conf_flatten <- mbox_conf_softmax
I0601 11:13:14.966696 28894 net.cpp:408] mbox_conf_flatten -> mbox_conf_flatten
I0601 11:13:14.966720 28894 net.cpp:150] Setting up mbox_conf_flatten
I0601 11:13:14.966728 28894 net.cpp:157] Top shape: 4 34928 (139712)
I0601 11:13:14.966732 28894 net.cpp:165] Memory required for data: 995144736
I0601 11:13:14.966737 28894 layer_factory.hpp:77] Creating layer detection_out
I0601 11:13:14.966749 28894 net.cpp:100] Creating Layer detection_out
I0601 11:13:14.966755 28894 net.cpp:434] detection_out <- mbox_loc
I0601 11:13:14.966761 28894 net.cpp:434] detection_out <- mbox_conf_flatten
I0601 11:13:14.966766 28894 net.cpp:434] detection_out <- mbox_priorbox
I0601 11:13:14.966773 28894 net.cpp:408] detection_out -> detection_out
I0601 11:13:14.968566 28894 net.cpp:150] Setting up detection_out
I0601 11:13:14.968577 28894 net.cpp:157] Top shape: 1 1 1 7 (7)
I0601 11:13:14.968580 28894 net.cpp:165] Memory required for data: 995144764
I0601 11:13:14.968583 28894 layer_factory.hpp:77] Creating layer detection_eval
I0601 11:13:14.968592 28894 net.cpp:100] Creating Layer detection_eval
I0601 11:13:14.968598 28894 net.cpp:434] detection_eval <- detection_out
I0601 11:13:14.968605 28894 net.cpp:434] detection_eval <- label
I0601 11:13:14.968611 28894 net.cpp:408] detection_eval -> detection_eval
I0601 11:13:14.969667 28894 net.cpp:150] Setting up detection_eval
I0601 11:13:14.969676 28894 net.cpp:157] Top shape: 1 1 4 5 (20)
I0601 11:13:14.969679 28894 net.cpp:165] Memory required for data: 995144844
I0601 11:13:14.969683 28894 net.cpp:228] detection_eval does not need backward computation.
I0601 11:13:14.969691 28894 net.cpp:228] detection_out does not need backward computation.
I0601 11:13:14.969694 28894 net.cpp:228] mbox_conf_flatten does not need backward computation.
I0601 11:13:14.969699 28894 net.cpp:228] mbox_conf_softmax does not need backward computation.
I0601 11:13:14.969703 28894 net.cpp:228] mbox_conf_reshape does not need backward computation.
I0601 11:13:14.969709 28894 net.cpp:228] mbox_priorbox does not need backward computation.
I0601 11:13:14.969715 28894 net.cpp:228] mbox_conf does not need backward computation.
I0601 11:13:14.969722 28894 net.cpp:228] mbox_loc does not need backward computation.
I0601 11:13:14.969728 28894 net.cpp:228] conv9_2_mbox_priorbox does not need backward computation.
I0601 11:13:14.969734 28894 net.cpp:228] conv9_2_mbox_conf_flat does not need backward computation.
I0601 11:13:14.969739 28894 net.cpp:228] conv9_2_mbox_conf_perm does not need backward computation.
I0601 11:13:14.969744 28894 net.cpp:228] conv9_2_mbox_conf does not need backward computation.
I0601 11:13:14.969749 28894 net.cpp:228] conv9_2_mbox_loc_flat does not need backward computation.
I0601 11:13:14.969754 28894 net.cpp:228] conv9_2_mbox_loc_perm does not need backward computation.
I0601 11:13:14.969759 28894 net.cpp:228] conv9_2_mbox_loc does not need backward computation.
I0601 11:13:14.969764 28894 net.cpp:228] conv8_2_mbox_priorbox does not need backward computation.
I0601 11:13:14.969769 28894 net.cpp:228] conv8_2_mbox_conf_flat does not need backward computation.
I0601 11:13:14.969775 28894 net.cpp:228] conv8_2_mbox_conf_perm does not need backward computation.
I0601 11:13:14.969780 28894 net.cpp:228] conv8_2_mbox_conf does not need backward computation.
I0601 11:13:14.969784 28894 net.cpp:228] conv8_2_mbox_loc_flat does not need backward computation.
I0601 11:13:14.969789 28894 net.cpp:228] conv8_2_mbox_loc_perm does not need backward computation.
I0601 11:13:14.969795 28894 net.cpp:228] conv8_2_mbox_loc does not need backward computation.
I0601 11:13:14.969801 28894 net.cpp:228] conv7_2_mbox_priorbox does not need backward computation.
I0601 11:13:14.969806 28894 net.cpp:228] conv7_2_mbox_conf_flat does not need backward computation.
I0601 11:13:14.969810 28894 net.cpp:228] conv7_2_mbox_conf_perm does not need backward computation.
I0601 11:13:14.969815 28894 net.cpp:228] conv7_2_mbox_conf does not need backward computation.
I0601 11:13:14.969821 28894 net.cpp:228] conv7_2_mbox_loc_flat does not need backward computation.
I0601 11:13:14.969825 28894 net.cpp:228] conv7_2_mbox_loc_perm does not need backward computation.
I0601 11:13:14.969830 28894 net.cpp:228] conv7_2_mbox_loc does not need backward computation.
I0601 11:13:14.969835 28894 net.cpp:228] conv6_2_mbox_priorbox does not need backward computation.
I0601 11:13:14.969842 28894 net.cpp:228] conv6_2_mbox_conf_flat does not need backward computation.
I0601 11:13:14.969847 28894 net.cpp:228] conv6_2_mbox_conf_perm does not need backward computation.
I0601 11:13:14.969852 28894 net.cpp:228] conv6_2_mbox_conf does not need backward computation.
I0601 11:13:14.969857 28894 net.cpp:228] conv6_2_mbox_loc_flat does not need backward computation.
I0601 11:13:14.969862 28894 net.cpp:228] conv6_2_mbox_loc_perm does not need backward computation.
I0601 11:13:14.969867 28894 net.cpp:228] conv6_2_mbox_loc does not need backward computation.
I0601 11:13:14.969872 28894 net.cpp:228] fc7_mbox_priorbox does not need backward computation.
I0601 11:13:14.969878 28894 net.cpp:228] fc7_mbox_conf_flat does not need backward computation.
I0601 11:13:14.969883 28894 net.cpp:228] fc7_mbox_conf_perm does not need backward computation.
I0601 11:13:14.969888 28894 net.cpp:228] fc7_mbox_conf does not need backward computation.
I0601 11:13:14.969903 28894 net.cpp:228] fc7_mbox_loc_flat does not need backward computation.
I0601 11:13:14.969909 28894 net.cpp:228] fc7_mbox_loc_perm does not need backward computation.
I0601 11:13:14.969915 28894 net.cpp:228] fc7_mbox_loc does not need backward computation.
I0601 11:13:14.969920 28894 net.cpp:228] conv4_3_norm_mbox_priorbox does not need backward computation.
I0601 11:13:14.969926 28894 net.cpp:228] conv4_3_norm_mbox_conf_flat does not need backward computation.
I0601 11:13:14.969931 28894 net.cpp:228] conv4_3_norm_mbox_conf_perm does not need backward computation.
I0601 11:13:14.969938 28894 net.cpp:228] conv4_3_norm_mbox_conf does not need backward computation.
I0601 11:13:14.969943 28894 net.cpp:228] conv4_3_norm_mbox_loc_flat does not need backward computation.
I0601 11:13:14.969947 28894 net.cpp:228] conv4_3_norm_mbox_loc_perm does not need backward computation.
I0601 11:13:14.969952 28894 net.cpp:228] conv4_3_norm_mbox_loc does not need backward computation.
I0601 11:13:14.969957 28894 net.cpp:228] conv4_3_norm_conv4_3_norm_0_split does not need backward computation.
I0601 11:13:14.969962 28894 net.cpp:228] conv4_3_norm does not need backward computation.
I0601 11:13:14.969969 28894 net.cpp:228] conv9_2_conv9_2_relu_0_split does not need backward computation.
I0601 11:13:14.969974 28894 net.cpp:228] conv9_2_relu does not need backward computation.
I0601 11:13:14.969979 28894 net.cpp:228] conv9_2 does not need backward computation.
I0601 11:13:14.969983 28894 net.cpp:228] conv9_1_relu does not need backward computation.
I0601 11:13:14.969988 28894 net.cpp:228] conv9_1 does not need backward computation.
I0601 11:13:14.969993 28894 net.cpp:228] conv8_2_conv8_2_relu_0_split does not need backward computation.
I0601 11:13:14.969998 28894 net.cpp:228] conv8_2_relu does not need backward computation.
I0601 11:13:14.970003 28894 net.cpp:228] conv8_2 does not need backward computation.
I0601 11:13:14.970008 28894 net.cpp:228] conv8_1_relu does not need backward computation.
I0601 11:13:14.970012 28894 net.cpp:228] conv8_1 does not need backward computation.
I0601 11:13:14.970018 28894 net.cpp:228] conv7_2_conv7_2_relu_0_split does not need backward computation.
I0601 11:13:14.970023 28894 net.cpp:228] conv7_2_relu does not need backward computation.
I0601 11:13:14.970028 28894 net.cpp:228] conv7_2 does not need backward computation.
I0601 11:13:14.970032 28894 net.cpp:228] conv7_1_relu does not need backward computation.
I0601 11:13:14.970038 28894 net.cpp:228] conv7_1 does not need backward computation.
I0601 11:13:14.970043 28894 net.cpp:228] conv6_2_conv6_2_relu_0_split does not need backward computation.
I0601 11:13:14.970048 28894 net.cpp:228] conv6_2_relu does not need backward computation.
I0601 11:13:14.970053 28894 net.cpp:228] conv6_2 does not need backward computation.
I0601 11:13:14.970058 28894 net.cpp:228] conv6_1_relu does not need backward computation.
I0601 11:13:14.970062 28894 net.cpp:228] conv6_1 does not need backward computation.
I0601 11:13:14.970068 28894 net.cpp:228] fc7_relu7_0_split does not need backward computation.
I0601 11:13:14.970073 28894 net.cpp:228] relu7 does not need backward computation.
I0601 11:13:14.970078 28894 net.cpp:228] fc7 does not need backward computation.
I0601 11:13:14.970082 28894 net.cpp:228] relu6 does not need backward computation.
I0601 11:13:14.970087 28894 net.cpp:228] fc6 does not need backward computation.
I0601 11:13:14.970090 28894 net.cpp:228] pool5 does not need backward computation.
I0601 11:13:14.970095 28894 net.cpp:228] relu5_3 does not need backward computation.
I0601 11:13:14.970100 28894 net.cpp:228] conv5_3 does not need backward computation.
I0601 11:13:14.970104 28894 net.cpp:228] relu5_2 does not need backward computation.
I0601 11:13:14.970109 28894 net.cpp:228] conv5_2 does not need backward computation.
I0601 11:13:14.970114 28894 net.cpp:228] relu5_1 does not need backward computation.
I0601 11:13:14.970119 28894 net.cpp:228] conv5_1 does not need backward computation.
I0601 11:13:14.970124 28894 net.cpp:228] pool4 does not need backward computation.
I0601 11:13:14.970135 28894 net.cpp:228] conv4_3_relu4_3_0_split does not need backward computation.
I0601 11:13:14.970141 28894 net.cpp:228] relu4_3 does not need backward computation.
I0601 11:13:14.970146 28894 net.cpp:228] conv4_3 does not need backward computation.
I0601 11:13:14.970151 28894 net.cpp:228] relu4_2 does not need backward computation.
I0601 11:13:14.970155 28894 net.cpp:228] conv4_2 does not need backward computation.
I0601 11:13:14.970161 28894 net.cpp:228] relu4_1 does not need backward computation.
I0601 11:13:14.970165 28894 net.cpp:228] conv4_1 does not need backward computation.
I0601 11:13:14.970170 28894 net.cpp:228] pool3 does not need backward computation.
I0601 11:13:14.970175 28894 net.cpp:228] relu3_3 does not need backward computation.
I0601 11:13:14.970180 28894 net.cpp:228] conv3_3 does not need backward computation.
I0601 11:13:14.970185 28894 net.cpp:228] relu3_2 does not need backward computation.
I0601 11:13:14.970190 28894 net.cpp:228] conv3_2 does not need backward computation.
I0601 11:13:14.970193 28894 net.cpp:228] relu3_1 does not need backward computation.
I0601 11:13:14.970198 28894 net.cpp:228] conv3_1 does not need backward computation.
I0601 11:13:14.970203 28894 net.cpp:228] pool2 does not need backward computation.
I0601 11:13:14.970208 28894 net.cpp:228] relu2_2 does not need backward computation.
I0601 11:13:14.970212 28894 net.cpp:228] conv2_2 does not need backward computation.
I0601 11:13:14.970218 28894 net.cpp:228] relu2_1 does not need backward computation.
I0601 11:13:14.970222 28894 net.cpp:228] conv2_1 does not need backward computation.
I0601 11:13:14.970227 28894 net.cpp:228] pool1 does not need backward computation.
I0601 11:13:14.970230 28894 net.cpp:228] relu1_2 does not need backward computation.
I0601 11:13:14.970234 28894 net.cpp:228] conv1_2 does not need backward computation.
I0601 11:13:14.970237 28894 net.cpp:228] relu1_1 does not need backward computation.
I0601 11:13:14.970242 28894 net.cpp:228] conv1_1 does not need backward computation.
I0601 11:13:14.970247 28894 net.cpp:228] data_data_0_split does not need backward computation.
I0601 11:13:14.970253 28894 net.cpp:228] data does not need backward computation.
I0601 11:13:14.970257 28894 net.cpp:270] This network produces output detection_eval
I0601 11:13:14.970350 28894 net.cpp:283] Network initialization done.
I0601 11:13:14.970654 28894 solver.cpp:75] Solver scaffolding done.
I0601 11:13:14.973188 28894 caffe.cpp:155] Finetuning from models/VGGNet/VGG_ILSVRC_16_layers_fc_reduced.caffemodel
I0601 11:13:15.002220 28894 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: models/VGGNet/VGG_ILSVRC_16_layers_fc_reduced.caffemodel
I0601 11:13:15.002239 28894 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.
W0601 11:13:15.002243 28894 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.
I0601 11:13:15.014353 28894 net.cpp:761] Ignoring source layer drop6
I0601 11:13:15.015338 28894 net.cpp:761] Ignoring source layer drop7
I0601 11:13:15.015350 28894 net.cpp:761] Ignoring source layer fc8
I0601 11:13:15.015354 28894 net.cpp:761] Ignoring source layer prob
I0601 11:13:15.046736 28894 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: models/VGGNet/VGG_ILSVRC_16_layers_fc_reduced.caffemodel
I0601 11:13:15.046753 28894 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.
W0601 11:13:15.046756 28894 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.
I0601 11:13:15.058542 28894 net.cpp:761] Ignoring source layer drop6
I0601 11:13:15.059444 28894 net.cpp:761] Ignoring source layer drop7
I0601 11:13:15.059458 28894 net.cpp:761] Ignoring source layer fc8
I0601 11:13:15.059463 28894 net.cpp:761] Ignoring source layer prob
I0601 11:13:15.060353 28894 caffe.cpp:251] Starting Optimization
I0601 11:13:15.060364 28894 solver.cpp:294] Solving VGG_tbs_300x300_HSIL_10x_SSD_300x300_train
I0601 11:13:15.060379 28894 solver.cpp:295] Learning Rate Policy: multistep
I0601 11:13:15.067806 28894 blocking_queue.cpp:50] Data layer prefetch queue empty
I0601 11:13:15.897241 28894 solver.cpp:243] Iteration 0, loss = 17.4069
I0601 11:13:15.897280 28894 solver.cpp:259]     Train net output #0: mbox_loss = 17.4069 (* 1 = 17.4069 loss)
I0601 11:13:15.897313 28894 sgd_solver.cpp:138] Iteration 0, lr = 2.5e-05
I0601 11:13:22.382608 28894 solver.cpp:243] Iteration 10, loss = 16.8552
I0601 11:13:22.382632 28894 solver.cpp:259]     Train net output #0: mbox_loss = 16.2244 (* 1 = 16.2244 loss)
I0601 11:13:22.382637 28894 sgd_solver.cpp:138] Iteration 10, lr = 2.5e-05
I0601 11:13:28.853663 28894 solver.cpp:243] Iteration 20, loss = 15.0669
I0601 11:13:28.853691 28894 solver.cpp:259]     Train net output #0: mbox_loss = 13.3916 (* 1 = 13.3916 loss)
I0601 11:13:28.853696 28894 sgd_solver.cpp:138] Iteration 20, lr = 2.5e-05
I0601 11:13:35.329035 28894 solver.cpp:243] Iteration 30, loss = 12.7537
I0601 11:13:35.329062 28894 solver.cpp:259]     Train net output #0: mbox_loss = 11.9958 (* 1 = 11.9958 loss)
I0601 11:13:35.329067 28894 sgd_solver.cpp:138] Iteration 30, lr = 2.5e-05
I0601 11:13:41.836956 28894 solver.cpp:243] Iteration 40, loss = 11.4811
I0601 11:13:41.836979 28894 solver.cpp:259]     Train net output #0: mbox_loss = 10.8079 (* 1 = 10.8079 loss)
I0601 11:13:41.836985 28894 sgd_solver.cpp:138] Iteration 40, lr = 2.5e-05
I0601 11:13:48.306143 28894 solver.cpp:243] Iteration 50, loss = 10.6578
I0601 11:13:48.306215 28894 solver.cpp:259]     Train net output #0: mbox_loss = 9.83698 (* 1 = 9.83698 loss)
I0601 11:13:48.306221 28894 sgd_solver.cpp:138] Iteration 50, lr = 2.5e-05
I0601 11:13:54.824308 28894 solver.cpp:243] Iteration 60, loss = 10.0622
I0601 11:13:54.824334 28894 solver.cpp:259]     Train net output #0: mbox_loss = 9.58941 (* 1 = 9.58941 loss)
I0601 11:13:54.824340 28894 sgd_solver.cpp:138] Iteration 60, lr = 2.5e-05
I0601 11:14:01.322459 28894 solver.cpp:243] Iteration 70, loss = 9.67928
I0601 11:14:01.322485 28894 solver.cpp:259]     Train net output #0: mbox_loss = 10.1641 (* 1 = 10.1641 loss)
I0601 11:14:01.322491 28894 sgd_solver.cpp:138] Iteration 70, lr = 2.5e-05
I0601 11:14:07.851577 28894 solver.cpp:243] Iteration 80, loss = 9.45577
I0601 11:14:07.851603 28894 solver.cpp:259]     Train net output #0: mbox_loss = 9.31781 (* 1 = 9.31781 loss)
I0601 11:14:07.851609 28894 sgd_solver.cpp:138] Iteration 80, lr = 2.5e-05
I0601 11:14:14.364379 28894 solver.cpp:243] Iteration 90, loss = 9.54156
I0601 11:14:14.364405 28894 solver.cpp:259]     Train net output #0: mbox_loss = 9.63073 (* 1 = 9.63073 loss)
I0601 11:14:14.364410 28894 sgd_solver.cpp:138] Iteration 90, lr = 2.5e-05
I0601 11:14:20.246188 28894 solver.cpp:433] Iteration 100, Testing net (#0)
I0601 11:14:20.271575 28894 net.cpp:693] Ignoring source layer mbox_loss
I0601 11:14:22.655565 28894 solver.cpp:546]     Test net output #0: detection_eval = 0.0124181
I0601 11:14:23.286646 28894 solver.cpp:243] Iteration 100, loss = 9.1722
I0601 11:14:23.286671 28894 solver.cpp:259]     Train net output #0: mbox_loss = 9.29616 (* 1 = 9.29616 loss)
I0601 11:14:23.286676 28894 sgd_solver.cpp:138] Iteration 100, lr = 2.5e-05
I0601 11:14:29.823027 28894 solver.cpp:243] Iteration 110, loss = 9.33173
I0601 11:14:29.823050 28894 solver.cpp:259]     Train net output #0: mbox_loss = 9.68409 (* 1 = 9.68409 loss)
I0601 11:14:29.823056 28894 sgd_solver.cpp:138] Iteration 110, lr = 2.5e-05
I0601 11:14:36.326544 28894 solver.cpp:243] Iteration 120, loss = 9.18713
I0601 11:14:36.326570 28894 solver.cpp:259]     Train net output #0: mbox_loss = 9.59769 (* 1 = 9.59769 loss)
I0601 11:14:36.326575 28894 sgd_solver.cpp:138] Iteration 120, lr = 2.5e-05
I0601 11:14:42.906924 28894 solver.cpp:243] Iteration 130, loss = 9.11917
I0601 11:14:42.906949 28894 solver.cpp:259]     Train net output #0: mbox_loss = 9.36222 (* 1 = 9.36222 loss)
I0601 11:14:42.906955 28894 sgd_solver.cpp:138] Iteration 130, lr = 2.5e-05
I0601 11:14:49.569134 28894 solver.cpp:243] Iteration 140, loss = 9.04295
I0601 11:14:49.569160 28894 solver.cpp:259]     Train net output #0: mbox_loss = 8.74828 (* 1 = 8.74828 loss)
I0601 11:14:49.569165 28894 sgd_solver.cpp:138] Iteration 140, lr = 2.5e-05
I0601 11:14:56.219461 28894 solver.cpp:243] Iteration 150, loss = 9.04546
I0601 11:14:56.219615 28894 solver.cpp:259]     Train net output #0: mbox_loss = 8.73191 (* 1 = 8.73191 loss)
I0601 11:14:56.219622 28894 sgd_solver.cpp:138] Iteration 150, lr = 2.5e-05
I0601 11:15:02.809440 28894 solver.cpp:243] Iteration 160, loss = 9.13632
I0601 11:15:02.809465 28894 solver.cpp:259]     Train net output #0: mbox_loss = 8.7769 (* 1 = 8.7769 loss)
I0601 11:15:02.809471 28894 sgd_solver.cpp:138] Iteration 160, lr = 2.5e-05
I0601 11:15:09.535090 28894 solver.cpp:243] Iteration 170, loss = 8.9369
I0601 11:15:09.535116 28894 solver.cpp:259]     Train net output #0: mbox_loss = 9.21162 (* 1 = 9.21162 loss)
I0601 11:15:09.535122 28894 sgd_solver.cpp:138] Iteration 170, lr = 2.5e-05
I0601 11:15:16.192710 28894 solver.cpp:243] Iteration 180, loss = 9.01572
I0601 11:15:16.192736 28894 solver.cpp:259]     Train net output #0: mbox_loss = 8.55067 (* 1 = 8.55067 loss)
I0601 11:15:16.192741 28894 sgd_solver.cpp:138] Iteration 180, lr = 2.5e-05
I0601 11:15:22.893182 28894 solver.cpp:243] Iteration 190, loss = 8.82918
I0601 11:15:22.893208 28894 solver.cpp:259]     Train net output #0: mbox_loss = 9.07722 (* 1 = 9.07722 loss)
I0601 11:15:22.893213 28894 sgd_solver.cpp:138] Iteration 190, lr = 2.5e-05
I0601 11:15:28.814682 28894 solver.cpp:433] Iteration 200, Testing net (#0)
I0601 11:15:28.814831 28894 net.cpp:693] Ignoring source layer mbox_loss
I0601 11:15:31.217375 28894 solver.cpp:546]     Test net output #0: detection_eval = 0.0245866
I0601 11:15:31.858258 28894 solver.cpp:243] Iteration 200, loss = 8.91426
I0601 11:15:31.858283 28894 solver.cpp:259]     Train net output #0: mbox_loss = 8.70185 (* 1 = 8.70185 loss)
I0601 11:15:31.858289 28894 sgd_solver.cpp:138] Iteration 200, lr = 2.5e-05
I0601 11:15:38.616442 28894 solver.cpp:243] Iteration 210, loss = 8.81813
I0601 11:15:38.616468 28894 solver.cpp:259]     Train net output #0: mbox_loss = 8.9249 (* 1 = 8.9249 loss)
I0601 11:15:38.616474 28894 sgd_solver.cpp:138] Iteration 210, lr = 2.5e-05
I0601 11:15:45.296037 28894 solver.cpp:243] Iteration 220, loss = 8.78718
I0601 11:15:45.296063 28894 solver.cpp:259]     Train net output #0: mbox_loss = 8.48488 (* 1 = 8.48488 loss)
I0601 11:15:45.296069 28894 sgd_solver.cpp:138] Iteration 220, lr = 2.5e-05
I0601 11:15:52.044571 28894 solver.cpp:243] Iteration 230, loss = 9.03008
I0601 11:15:52.044597 28894 solver.cpp:259]     Train net output #0: mbox_loss = 10.6395 (* 1 = 10.6395 loss)
I0601 11:15:52.044603 28894 sgd_solver.cpp:138] Iteration 230, lr = 2.5e-05
I0601 11:15:58.709362 28894 solver.cpp:243] Iteration 240, loss = 8.63121
I0601 11:15:58.709389 28894 solver.cpp:259]     Train net output #0: mbox_loss = 8.53654 (* 1 = 8.53654 loss)
I0601 11:15:58.709395 28894 sgd_solver.cpp:138] Iteration 240, lr = 2.5e-05
I0601 11:16:05.366396 28894 solver.cpp:243] Iteration 250, loss = 8.73928
I0601 11:16:05.366524 28894 solver.cpp:259]     Train net output #0: mbox_loss = 8.48512 (* 1 = 8.48512 loss)
I0601 11:16:05.366531 28894 sgd_solver.cpp:138] Iteration 250, lr = 2.5e-05
I0601 11:16:11.942317 28894 solver.cpp:243] Iteration 260, loss = 8.67476
I0601 11:16:11.942340 28894 solver.cpp:259]     Train net output #0: mbox_loss = 8.99399 (* 1 = 8.99399 loss)
I0601 11:16:11.942348 28894 sgd_solver.cpp:138] Iteration 260, lr = 2.5e-05
I0601 11:16:18.656576 28894 solver.cpp:243] Iteration 270, loss = 8.66445
I0601 11:16:18.656600 28894 solver.cpp:259]     Train net output #0: mbox_loss = 8.77279 (* 1 = 8.77279 loss)
I0601 11:16:18.656606 28894 sgd_solver.cpp:138] Iteration 270, lr = 2.5e-05
I0601 11:16:25.437602 28894 solver.cpp:243] Iteration 280, loss = 8.47872
I0601 11:16:25.437628 28894 solver.cpp:259]     Train net output #0: mbox_loss = 8.16937 (* 1 = 8.16937 loss)
I0601 11:16:25.437633 28894 sgd_solver.cpp:138] Iteration 280, lr = 2.5e-05
I0601 11:16:32.152532 28894 solver.cpp:243] Iteration 290, loss = 8.61007
I0601 11:16:32.152560 28894 solver.cpp:259]     Train net output #0: mbox_loss = 8.87444 (* 1 = 8.87444 loss)
I0601 11:16:32.152566 28894 sgd_solver.cpp:138] Iteration 290, lr = 2.5e-05
I0601 11:16:38.286875 28894 solver.cpp:433] Iteration 300, Testing net (#0)
I0601 11:16:38.287046 28894 net.cpp:693] Ignoring source layer mbox_loss
I0601 11:16:40.857242 28894 solver.cpp:546]     Test net output #0: detection_eval = 0.046823
I0601 11:16:41.565793 28894 solver.cpp:243] Iteration 300, loss = 8.48819
I0601 11:16:41.565817 28894 solver.cpp:259]     Train net output #0: mbox_loss = 8.21676 (* 1 = 8.21676 loss)
I0601 11:16:41.565824 28894 sgd_solver.cpp:138] Iteration 300, lr = 2.5e-05
I0601 11:16:48.637416 28894 solver.cpp:243] Iteration 310, loss = 8.70596
I0601 11:16:48.637470 28894 solver.cpp:259]     Train net output #0: mbox_loss = 8.50681 (* 1 = 8.50681 loss)
I0601 11:16:48.637475 28894 sgd_solver.cpp:138] Iteration 310, lr = 2.5e-05
I0601 11:16:55.390734 28894 solver.cpp:243] Iteration 320, loss = 8.57787
I0601 11:16:55.390760 28894 solver.cpp:259]     Train net output #0: mbox_loss = 8.64733 (* 1 = 8.64733 loss)
I0601 11:16:55.390766 28894 sgd_solver.cpp:138] Iteration 320, lr = 2.5e-05
I0601 11:17:02.096570 28894 solver.cpp:243] Iteration 330, loss = 8.54462
I0601 11:17:02.096596 28894 solver.cpp:259]     Train net output #0: mbox_loss = 9.13039 (* 1 = 9.13039 loss)
I0601 11:17:02.096601 28894 sgd_solver.cpp:138] Iteration 330, lr = 2.5e-05
I0601 11:17:08.800182 28894 solver.cpp:243] Iteration 340, loss = 8.49362
I0601 11:17:08.800348 28894 solver.cpp:259]     Train net output #0: mbox_loss = 8.24419 (* 1 = 8.24419 loss)
I0601 11:17:08.800355 28894 sgd_solver.cpp:138] Iteration 340, lr = 2.5e-05
I0601 11:17:15.474318 28894 solver.cpp:243] Iteration 350, loss = 8.53178
I0601 11:17:15.474345 28894 solver.cpp:259]     Train net output #0: mbox_loss = 8.5938 (* 1 = 8.5938 loss)
I0601 11:17:15.474350 28894 sgd_solver.cpp:138] Iteration 350, lr = 2.5e-05
I0601 11:17:22.204089 28894 solver.cpp:243] Iteration 360, loss = 8.42777
I0601 11:17:22.204116 28894 solver.cpp:259]     Train net output #0: mbox_loss = 8.2209 (* 1 = 8.2209 loss)
I0601 11:17:22.204123 28894 sgd_solver.cpp:138] Iteration 360, lr = 2.5e-05
I0601 11:17:29.107830 28894 solver.cpp:243] Iteration 370, loss = 8.44892
I0601 11:17:29.107853 28894 solver.cpp:259]     Train net output #0: mbox_loss = 8.29223 (* 1 = 8.29223 loss)
I0601 11:17:29.107859 28894 sgd_solver.cpp:138] Iteration 370, lr = 2.5e-05
I0601 11:17:36.040715 28894 solver.cpp:243] Iteration 380, loss = 8.48478
I0601 11:17:36.040742 28894 solver.cpp:259]     Train net output #0: mbox_loss = 7.96469 (* 1 = 7.96469 loss)
I0601 11:17:36.040748 28894 sgd_solver.cpp:138] Iteration 380, lr = 2.5e-05
I0601 11:17:43.105661 28894 solver.cpp:243] Iteration 390, loss = 8.47435
I0601 11:17:43.105820 28894 solver.cpp:259]     Train net output #0: mbox_loss = 9.15032 (* 1 = 9.15032 loss)
I0601 11:17:43.105829 28894 sgd_solver.cpp:138] Iteration 390, lr = 2.5e-05
I0601 11:17:49.218523 28894 solver.cpp:433] Iteration 400, Testing net (#0)
I0601 11:17:49.218569 28894 net.cpp:693] Ignoring source layer mbox_loss
I0601 11:17:51.663345 28894 solver.cpp:546]     Test net output #0: detection_eval = 0.0267894
I0601 11:17:52.313311 28894 solver.cpp:243] Iteration 400, loss = 8.30541
I0601 11:17:52.313336 28894 solver.cpp:259]     Train net output #0: mbox_loss = 8.10944 (* 1 = 8.10944 loss)
I0601 11:17:52.313343 28894 sgd_solver.cpp:138] Iteration 400, lr = 2.5e-05
I0601 11:17:59.111905 28894 solver.cpp:243] Iteration 410, loss = 8.30497
I0601 11:17:59.111930 28894 solver.cpp:259]     Train net output #0: mbox_loss = 8.4534 (* 1 = 8.4534 loss)
I0601 11:17:59.111937 28894 sgd_solver.cpp:138] Iteration 410, lr = 2.5e-05
I0601 11:18:06.260475 28894 solver.cpp:243] Iteration 420, loss = 8.32869
I0601 11:18:06.260501 28894 solver.cpp:259]     Train net output #0: mbox_loss = 8.52518 (* 1 = 8.52518 loss)
I0601 11:18:06.260507 28894 sgd_solver.cpp:138] Iteration 420, lr = 2.5e-05
I0601 11:18:13.659545 28894 solver.cpp:243] Iteration 430, loss = 8.35014
I0601 11:18:13.659683 28894 solver.cpp:259]     Train net output #0: mbox_loss = 8.6672 (* 1 = 8.6672 loss)
I0601 11:18:13.659692 28894 sgd_solver.cpp:138] Iteration 430, lr = 2.5e-05
I0601 11:18:20.831212 28894 solver.cpp:243] Iteration 440, loss = 8.22141
I0601 11:18:20.831238 28894 solver.cpp:259]     Train net output #0: mbox_loss = 8.22159 (* 1 = 8.22159 loss)
I0601 11:18:20.831244 28894 sgd_solver.cpp:138] Iteration 440, lr = 2.5e-05
I0601 11:18:27.945875 28894 solver.cpp:243] Iteration 450, loss = 8.27607
I0601 11:18:27.945900 28894 solver.cpp:259]     Train net output #0: mbox_loss = 8.29311 (* 1 = 8.29311 loss)
I0601 11:18:27.945906 28894 sgd_solver.cpp:138] Iteration 450, lr = 2.5e-05
I0601 11:18:35.135032 28894 solver.cpp:243] Iteration 460, loss = 8.28176
I0601 11:18:35.135058 28894 solver.cpp:259]     Train net output #0: mbox_loss = 7.9413 (* 1 = 7.9413 loss)
I0601 11:18:35.135064 28894 sgd_solver.cpp:138] Iteration 460, lr = 2.5e-05
I0601 11:18:42.290923 28894 solver.cpp:243] Iteration 470, loss = 8.15313
I0601 11:18:42.290949 28894 solver.cpp:259]     Train net output #0: mbox_loss = 7.73376 (* 1 = 7.73376 loss)
I0601 11:18:42.290954 28894 sgd_solver.cpp:138] Iteration 470, lr = 2.5e-05
I0601 11:18:49.527688 28894 solver.cpp:243] Iteration 480, loss = 8.33859
I0601 11:18:49.527819 28894 solver.cpp:259]     Train net output #0: mbox_loss = 8.08172 (* 1 = 8.08172 loss)
I0601 11:18:49.527827 28894 sgd_solver.cpp:138] Iteration 480, lr = 2.5e-05
I0601 11:18:56.693279 28894 solver.cpp:243] Iteration 490, loss = 8.07281
I0601 11:18:56.693305 28894 solver.cpp:259]     Train net output #0: mbox_loss = 8.0891 (* 1 = 8.0891 loss)
I0601 11:18:56.693310 28894 sgd_solver.cpp:138] Iteration 490, lr = 2.5e-05
I0601 11:19:02.973961 28894 solver.cpp:433] Iteration 500, Testing net (#0)
I0601 11:19:02.974035 28894 net.cpp:693] Ignoring source layer mbox_loss
I0601 11:19:05.503900 28894 solver.cpp:546]     Test net output #0: detection_eval = 0.0257955
I0601 11:19:06.179774 28894 solver.cpp:243] Iteration 500, loss = 8.14118
I0601 11:19:06.179800 28894 solver.cpp:259]     Train net output #0: mbox_loss = 7.90905 (* 1 = 7.90905 loss)
I0601 11:19:06.179805 28894 sgd_solver.cpp:138] Iteration 500, lr = 2.5e-05
I0601 11:19:13.241228 28894 solver.cpp:243] Iteration 510, loss = 8.07319
I0601 11:19:13.241255 28894 solver.cpp:259]     Train net output #0: mbox_loss = 8.4842 (* 1 = 8.4842 loss)
I0601 11:19:13.241261 28894 sgd_solver.cpp:138] Iteration 510, lr = 2.5e-05
I0601 11:19:20.574928 28894 solver.cpp:243] Iteration 520, loss = 8.20626
I0601 11:19:20.575037 28894 solver.cpp:259]     Train net output #0: mbox_loss = 7.91182 (* 1 = 7.91182 loss)
I0601 11:19:20.575057 28894 sgd_solver.cpp:138] Iteration 520, lr = 2.5e-05
I0601 11:19:27.929100 28894 solver.cpp:243] Iteration 530, loss = 8.0416
I0601 11:19:27.929127 28894 solver.cpp:259]     Train net output #0: mbox_loss = 8.08705 (* 1 = 8.08705 loss)
I0601 11:19:27.929133 28894 sgd_solver.cpp:138] Iteration 530, lr = 2.5e-05
I0601 11:19:35.089828 28894 solver.cpp:243] Iteration 540, loss = 8.12993
I0601 11:19:35.089871 28894 solver.cpp:259]     Train net output #0: mbox_loss = 7.80627 (* 1 = 7.80627 loss)
I0601 11:19:35.089890 28894 sgd_solver.cpp:138] Iteration 540, lr = 2.5e-05
I0601 11:19:42.591001 28894 solver.cpp:243] Iteration 550, loss = 7.98813
I0601 11:19:42.591028 28894 solver.cpp:259]     Train net output #0: mbox_loss = 8.98822 (* 1 = 8.98822 loss)
I0601 11:19:42.591037 28894 sgd_solver.cpp:138] Iteration 550, lr = 2.5e-05
I0601 11:19:49.830793 28894 solver.cpp:243] Iteration 560, loss = 7.8995
I0601 11:19:49.830817 28894 solver.cpp:259]     Train net output #0: mbox_loss = 7.97337 (* 1 = 7.97337 loss)
I0601 11:19:49.830823 28894 sgd_solver.cpp:138] Iteration 560, lr = 2.5e-05
I0601 11:19:57.024284 28894 solver.cpp:243] Iteration 570, loss = 8.17992
I0601 11:19:57.024441 28894 solver.cpp:259]     Train net output #0: mbox_loss = 8.26449 (* 1 = 8.26449 loss)
I0601 11:19:57.024449 28894 sgd_solver.cpp:138] Iteration 570, lr = 2.5e-05
I0601 11:20:04.246495 28894 solver.cpp:243] Iteration 580, loss = 7.98126
I0601 11:20:04.246536 28894 solver.cpp:259]     Train net output #0: mbox_loss = 8.18897 (* 1 = 8.18897 loss)
I0601 11:20:04.246546 28894 sgd_solver.cpp:138] Iteration 580, lr = 2.5e-05
I0601 11:20:11.759251 28894 solver.cpp:243] Iteration 590, loss = 8.05041
I0601 11:20:11.759277 28894 solver.cpp:259]     Train net output #0: mbox_loss = 8.79802 (* 1 = 8.79802 loss)
I0601 11:20:11.759284 28894 sgd_solver.cpp:138] Iteration 590, lr = 2.5e-05
I0601 11:20:18.137097 28894 solver.cpp:433] Iteration 600, Testing net (#0)
I0601 11:20:18.137143 28894 net.cpp:693] Ignoring source layer mbox_loss
I0601 11:20:20.551977 28894 solver.cpp:546]     Test net output #0: detection_eval = 0.03715
I0601 11:20:21.216158 28894 solver.cpp:243] Iteration 600, loss = 7.94297
I0601 11:20:21.216182 28894 solver.cpp:259]     Train net output #0: mbox_loss = 7.96878 (* 1 = 7.96878 loss)
I0601 11:20:21.216188 28894 sgd_solver.cpp:138] Iteration 600, lr = 2.5e-05
I0601 11:20:27.964643 28894 solver.cpp:243] Iteration 610, loss = 7.98791
I0601 11:20:27.964746 28894 solver.cpp:259]     Train net output #0: mbox_loss = 8.26554 (* 1 = 8.26554 loss)
I0601 11:20:27.964767 28894 sgd_solver.cpp:138] Iteration 610, lr = 2.5e-05
I0601 11:20:35.151497 28894 solver.cpp:243] Iteration 620, loss = 7.73041
I0601 11:20:35.151522 28894 solver.cpp:259]     Train net output #0: mbox_loss = 7.40219 (* 1 = 7.40219 loss)
I0601 11:20:35.151528 28894 sgd_solver.cpp:138] Iteration 620, lr = 2.5e-05
I0601 11:20:41.824620 28894 solver.cpp:243] Iteration 630, loss = 7.84982
I0601 11:20:41.824647 28894 solver.cpp:259]     Train net output #0: mbox_loss = 7.88136 (* 1 = 7.88136 loss)
I0601 11:20:41.824653 28894 sgd_solver.cpp:138] Iteration 630, lr = 2.5e-05
I0601 11:20:48.708988 28894 solver.cpp:243] Iteration 640, loss = 7.8037
I0601 11:20:48.709014 28894 solver.cpp:259]     Train net output #0: mbox_loss = 7.62473 (* 1 = 7.62473 loss)
I0601 11:20:48.709019 28894 sgd_solver.cpp:138] Iteration 640, lr = 2.5e-05
I0601 11:20:55.490736 28894 solver.cpp:243] Iteration 650, loss = 7.77467
I0601 11:20:55.490761 28894 solver.cpp:259]     Train net output #0: mbox_loss = 7.98124 (* 1 = 7.98124 loss)
I0601 11:20:55.490768 28894 sgd_solver.cpp:138] Iteration 650, lr = 2.5e-05
I0601 11:21:02.551021 28894 solver.cpp:243] Iteration 660, loss = 7.60598
I0601 11:21:02.551156 28894 solver.cpp:259]     Train net output #0: mbox_loss = 7.58767 (* 1 = 7.58767 loss)
I0601 11:21:02.551163 28894 sgd_solver.cpp:138] Iteration 660, lr = 2.5e-05
I0601 11:21:09.424921 28894 solver.cpp:243] Iteration 670, loss = 7.7496
I0601 11:21:09.424947 28894 solver.cpp:259]     Train net output #0: mbox_loss = 7.29627 (* 1 = 7.29627 loss)
I0601 11:21:09.424968 28894 sgd_solver.cpp:138] Iteration 670, lr = 2.5e-05
I0601 11:21:16.477924 28894 solver.cpp:243] Iteration 680, loss = 7.81113
I0601 11:21:16.477949 28894 solver.cpp:259]     Train net output #0: mbox_loss = 7.74804 (* 1 = 7.74804 loss)
I0601 11:21:16.477953 28894 sgd_solver.cpp:138] Iteration 680, lr = 2.5e-05
I0601 11:21:23.433428 28894 solver.cpp:243] Iteration 690, loss = 7.62307
I0601 11:21:23.433470 28894 solver.cpp:259]     Train net output #0: mbox_loss = 7.69116 (* 1 = 7.69116 loss)
I0601 11:21:23.433477 28894 sgd_solver.cpp:138] Iteration 690, lr = 2.5e-05
I0601 11:21:29.492137 28894 solver.cpp:433] Iteration 700, Testing net (#0)
I0601 11:21:29.492202 28894 net.cpp:693] Ignoring source layer mbox_loss
I0601 11:21:31.958113 28894 solver.cpp:546]     Test net output #0: detection_eval = 0.0416035
I0601 11:21:32.656848 28894 solver.cpp:243] Iteration 700, loss = 7.81159
I0601 11:21:32.656966 28894 solver.cpp:259]     Train net output #0: mbox_loss = 7.40043 (* 1 = 7.40043 loss)
I0601 11:21:32.656986 28894 sgd_solver.cpp:138] Iteration 700, lr = 2.5e-05
I0601 11:21:39.384054 28894 solver.cpp:243] Iteration 710, loss = 7.66732
I0601 11:21:39.384079 28894 solver.cpp:259]     Train net output #0: mbox_loss = 9.32482 (* 1 = 9.32482 loss)
I0601 11:21:39.384084 28894 sgd_solver.cpp:138] Iteration 710, lr = 2.5e-05
I0601 11:21:46.104081 28894 solver.cpp:243] Iteration 720, loss = 7.63906
I0601 11:21:46.104111 28894 solver.cpp:259]     Train net output #0: mbox_loss = 7.18561 (* 1 = 7.18561 loss)
I0601 11:21:46.104118 28894 sgd_solver.cpp:138] Iteration 720, lr = 2.5e-05
I0601 11:21:52.877212 28894 solver.cpp:243] Iteration 730, loss = 7.63298
I0601 11:21:52.877236 28894 solver.cpp:259]     Train net output #0: mbox_loss = 7.73755 (* 1 = 7.73755 loss)
I0601 11:21:52.877241 28894 sgd_solver.cpp:138] Iteration 730, lr = 2.5e-05
I0601 11:21:59.529628 28894 solver.cpp:243] Iteration 740, loss = 7.53644
I0601 11:21:59.529654 28894 solver.cpp:259]     Train net output #0: mbox_loss = 7.56228 (* 1 = 7.56228 loss)
I0601 11:21:59.529659 28894 sgd_solver.cpp:138] Iteration 740, lr = 2.5e-05
I0601 11:22:06.302183 28894 solver.cpp:243] Iteration 750, loss = 7.54588
I0601 11:22:06.302333 28894 solver.cpp:259]     Train net output #0: mbox_loss = 7.50406 (* 1 = 7.50406 loss)
I0601 11:22:06.302340 28894 sgd_solver.cpp:138] Iteration 750, lr = 2.5e-05
I0601 11:22:13.049219 28894 solver.cpp:243] Iteration 760, loss = 7.46013
I0601 11:22:13.049243 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.84992 (* 1 = 6.84992 loss)
I0601 11:22:13.049249 28894 sgd_solver.cpp:138] Iteration 760, lr = 2.5e-05
I0601 11:22:19.844068 28894 solver.cpp:243] Iteration 770, loss = 7.45349
I0601 11:22:19.844094 28894 solver.cpp:259]     Train net output #0: mbox_loss = 7.5285 (* 1 = 7.5285 loss)
I0601 11:22:19.844100 28894 sgd_solver.cpp:138] Iteration 770, lr = 2.5e-05
I0601 11:22:26.627897 28894 solver.cpp:243] Iteration 780, loss = 7.51557
I0601 11:22:26.627923 28894 solver.cpp:259]     Train net output #0: mbox_loss = 7.16516 (* 1 = 7.16516 loss)
I0601 11:22:26.627928 28894 sgd_solver.cpp:138] Iteration 780, lr = 2.5e-05
I0601 11:22:33.349252 28894 solver.cpp:243] Iteration 790, loss = 7.51321
I0601 11:22:33.349277 28894 solver.cpp:259]     Train net output #0: mbox_loss = 7.31764 (* 1 = 7.31764 loss)
I0601 11:22:33.349283 28894 sgd_solver.cpp:138] Iteration 790, lr = 2.5e-05
I0601 11:22:39.421994 28894 solver.cpp:433] Iteration 800, Testing net (#0)
I0601 11:22:39.422166 28894 net.cpp:693] Ignoring source layer mbox_loss
I0601 11:22:41.852574 28894 solver.cpp:546]     Test net output #0: detection_eval = 0.0393101
I0601 11:22:42.538761 28894 solver.cpp:243] Iteration 800, loss = 7.45459
I0601 11:22:42.538786 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.90965 (* 1 = 6.90965 loss)
I0601 11:22:42.538791 28894 sgd_solver.cpp:138] Iteration 800, lr = 2.5e-05
I0601 11:22:49.228564 28894 solver.cpp:243] Iteration 810, loss = 7.4137
I0601 11:22:49.228590 28894 solver.cpp:259]     Train net output #0: mbox_loss = 7.71991 (* 1 = 7.71991 loss)
I0601 11:22:49.228596 28894 sgd_solver.cpp:138] Iteration 810, lr = 2.5e-05
I0601 11:22:55.888532 28894 solver.cpp:243] Iteration 820, loss = 7.26357
I0601 11:22:55.888557 28894 solver.cpp:259]     Train net output #0: mbox_loss = 7.03142 (* 1 = 7.03142 loss)
I0601 11:22:55.888562 28894 sgd_solver.cpp:138] Iteration 820, lr = 2.5e-05
I0601 11:23:02.574213 28894 solver.cpp:243] Iteration 830, loss = 7.41392
I0601 11:23:02.574239 28894 solver.cpp:259]     Train net output #0: mbox_loss = 7.19733 (* 1 = 7.19733 loss)
I0601 11:23:02.574244 28894 sgd_solver.cpp:138] Iteration 830, lr = 2.5e-05
I0601 11:23:09.306582 28894 solver.cpp:243] Iteration 840, loss = 7.25837
I0601 11:23:09.306607 28894 solver.cpp:259]     Train net output #0: mbox_loss = 7.37243 (* 1 = 7.37243 loss)
I0601 11:23:09.306612 28894 sgd_solver.cpp:138] Iteration 840, lr = 2.5e-05
I0601 11:23:15.991106 28894 solver.cpp:243] Iteration 850, loss = 7.24673
I0601 11:23:15.991221 28894 solver.cpp:259]     Train net output #0: mbox_loss = 7.38612 (* 1 = 7.38612 loss)
I0601 11:23:15.991242 28894 sgd_solver.cpp:138] Iteration 850, lr = 2.5e-05
I0601 11:23:22.783264 28894 solver.cpp:243] Iteration 860, loss = 7.4256
I0601 11:23:22.783293 28894 solver.cpp:259]     Train net output #0: mbox_loss = 7.22608 (* 1 = 7.22608 loss)
I0601 11:23:22.783298 28894 sgd_solver.cpp:138] Iteration 860, lr = 2.5e-05
I0601 11:23:29.601505 28894 solver.cpp:243] Iteration 870, loss = 7.23488
I0601 11:23:29.601531 28894 solver.cpp:259]     Train net output #0: mbox_loss = 7.8798 (* 1 = 7.8798 loss)
I0601 11:23:29.601536 28894 sgd_solver.cpp:138] Iteration 870, lr = 2.5e-05
I0601 11:23:36.531446 28894 solver.cpp:243] Iteration 880, loss = 7.28786
I0601 11:23:36.531473 28894 solver.cpp:259]     Train net output #0: mbox_loss = 7.19562 (* 1 = 7.19562 loss)
I0601 11:23:36.531479 28894 sgd_solver.cpp:138] Iteration 880, lr = 2.5e-05
I0601 11:23:43.641472 28894 solver.cpp:243] Iteration 890, loss = 7.28969
I0601 11:23:43.641496 28894 solver.cpp:259]     Train net output #0: mbox_loss = 7.31479 (* 1 = 7.31479 loss)
I0601 11:23:43.641501 28894 sgd_solver.cpp:138] Iteration 890, lr = 2.5e-05
I0601 11:23:49.891273 28894 solver.cpp:433] Iteration 900, Testing net (#0)
I0601 11:23:49.891469 28894 net.cpp:693] Ignoring source layer mbox_loss
I0601 11:23:52.441619 28894 solver.cpp:546]     Test net output #0: detection_eval = 0.0444134
I0601 11:23:53.143247 28894 solver.cpp:243] Iteration 900, loss = 7.14905
I0601 11:23:53.143270 28894 solver.cpp:259]     Train net output #0: mbox_loss = 7.30881 (* 1 = 7.30881 loss)
I0601 11:23:53.143277 28894 sgd_solver.cpp:138] Iteration 900, lr = 2.5e-05
I0601 11:23:59.769629 28894 solver.cpp:243] Iteration 910, loss = 7.16115
I0601 11:23:59.769654 28894 solver.cpp:259]     Train net output #0: mbox_loss = 7.5546 (* 1 = 7.5546 loss)
I0601 11:23:59.769659 28894 sgd_solver.cpp:138] Iteration 910, lr = 2.5e-05
I0601 11:24:06.418294 28894 solver.cpp:243] Iteration 920, loss = 7.14563
I0601 11:24:06.418323 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.40357 (* 1 = 6.40357 loss)
I0601 11:24:06.418329 28894 sgd_solver.cpp:138] Iteration 920, lr = 2.5e-05
I0601 11:24:13.800287 28894 solver.cpp:243] Iteration 930, loss = 7.19164
I0601 11:24:13.800318 28894 solver.cpp:259]     Train net output #0: mbox_loss = 7.48703 (* 1 = 7.48703 loss)
I0601 11:24:13.800339 28894 sgd_solver.cpp:138] Iteration 930, lr = 2.5e-05
I0601 11:24:20.852785 28894 solver.cpp:243] Iteration 940, loss = 7.08381
I0601 11:24:20.852910 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.76417 (* 1 = 6.76417 loss)
I0601 11:24:20.852916 28894 sgd_solver.cpp:138] Iteration 940, lr = 2.5e-05
I0601 11:24:27.661689 28894 solver.cpp:243] Iteration 950, loss = 7.22607
I0601 11:24:27.661716 28894 solver.cpp:259]     Train net output #0: mbox_loss = 7.13592 (* 1 = 7.13592 loss)
I0601 11:24:27.661721 28894 sgd_solver.cpp:138] Iteration 950, lr = 2.5e-05
I0601 11:24:35.127991 28894 solver.cpp:243] Iteration 960, loss = 7.27112
I0601 11:24:35.128018 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.78236 (* 1 = 6.78236 loss)
I0601 11:24:35.128024 28894 sgd_solver.cpp:138] Iteration 960, lr = 2.5e-05
I0601 11:24:42.053519 28894 solver.cpp:243] Iteration 970, loss = 7.13724
I0601 11:24:42.053547 28894 solver.cpp:259]     Train net output #0: mbox_loss = 7.38591 (* 1 = 7.38591 loss)
I0601 11:24:42.053555 28894 sgd_solver.cpp:138] Iteration 970, lr = 2.5e-05
I0601 11:24:48.843570 28894 solver.cpp:243] Iteration 980, loss = 7.05528
I0601 11:24:48.843600 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.88509 (* 1 = 6.88509 loss)
I0601 11:24:48.843610 28894 sgd_solver.cpp:138] Iteration 980, lr = 2.5e-05
I0601 11:24:56.268970 28894 solver.cpp:243] Iteration 990, loss = 7.07066
I0601 11:24:56.269122 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.66699 (* 1 = 6.66699 loss)
I0601 11:24:56.269147 28894 sgd_solver.cpp:138] Iteration 990, lr = 2.5e-05
I0601 11:25:02.710166 28894 solver.cpp:433] Iteration 1000, Testing net (#0)
I0601 11:25:02.710211 28894 net.cpp:693] Ignoring source layer mbox_loss
I0601 11:25:05.198545 28894 solver.cpp:546]     Test net output #0: detection_eval = 0.0435618
I0601 11:25:05.854027 28894 solver.cpp:243] Iteration 1000, loss = 6.97338
I0601 11:25:05.854051 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.71556 (* 1 = 6.71556 loss)
I0601 11:25:05.854058 28894 sgd_solver.cpp:138] Iteration 1000, lr = 2.5e-05
I0601 11:25:12.692162 28894 solver.cpp:243] Iteration 1010, loss = 7.05268
I0601 11:25:12.692185 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.93157 (* 1 = 6.93157 loss)
I0601 11:25:12.692191 28894 sgd_solver.cpp:138] Iteration 1010, lr = 2.5e-05
I0601 11:25:19.477154 28894 solver.cpp:243] Iteration 1020, loss = 7.02276
I0601 11:25:19.477181 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.73585 (* 1 = 6.73585 loss)
I0601 11:25:19.477187 28894 sgd_solver.cpp:138] Iteration 1020, lr = 2.5e-05
I0601 11:25:26.269074 28894 solver.cpp:243] Iteration 1030, loss = 7.16977
I0601 11:25:26.269197 28894 solver.cpp:259]     Train net output #0: mbox_loss = 7.93096 (* 1 = 7.93096 loss)
I0601 11:25:26.269218 28894 sgd_solver.cpp:138] Iteration 1030, lr = 2.5e-05
I0601 11:25:33.258828 28894 solver.cpp:243] Iteration 1040, loss = 6.98329
I0601 11:25:33.258852 28894 solver.cpp:259]     Train net output #0: mbox_loss = 7.20238 (* 1 = 7.20238 loss)
I0601 11:25:33.258857 28894 sgd_solver.cpp:138] Iteration 1040, lr = 2.5e-05
I0601 11:25:39.928021 28894 solver.cpp:243] Iteration 1050, loss = 7.05767
I0601 11:25:39.928045 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.93923 (* 1 = 6.93923 loss)
I0601 11:25:39.928050 28894 sgd_solver.cpp:138] Iteration 1050, lr = 2.5e-05
I0601 11:25:46.957931 28894 solver.cpp:243] Iteration 1060, loss = 6.97984
I0601 11:25:46.957983 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.87422 (* 1 = 6.87422 loss)
I0601 11:25:46.957988 28894 sgd_solver.cpp:138] Iteration 1060, lr = 2.5e-05
I0601 11:25:53.823433 28894 solver.cpp:243] Iteration 1070, loss = 7.09809
I0601 11:25:53.823458 28894 solver.cpp:259]     Train net output #0: mbox_loss = 7.24769 (* 1 = 7.24769 loss)
I0601 11:25:53.823463 28894 sgd_solver.cpp:138] Iteration 1070, lr = 2.5e-05
I0601 11:26:00.649963 28894 solver.cpp:243] Iteration 1080, loss = 6.92925
I0601 11:26:00.650095 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.58446 (* 1 = 6.58446 loss)
I0601 11:26:00.650101 28894 sgd_solver.cpp:138] Iteration 1080, lr = 2.5e-05
I0601 11:26:07.674831 28894 solver.cpp:243] Iteration 1090, loss = 6.96694
I0601 11:26:07.674860 28894 solver.cpp:259]     Train net output #0: mbox_loss = 7.28365 (* 1 = 7.28365 loss)
I0601 11:26:07.674866 28894 sgd_solver.cpp:138] Iteration 1090, lr = 2.5e-05
I0601 11:26:13.853322 28894 solver.cpp:433] Iteration 1100, Testing net (#0)
I0601 11:26:13.853381 28894 net.cpp:693] Ignoring source layer mbox_loss
I0601 11:26:16.297783 28894 solver.cpp:546]     Test net output #0: detection_eval = 0.0482149
I0601 11:26:17.027381 28894 solver.cpp:243] Iteration 1100, loss = 7.00117
I0601 11:26:17.027406 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.61003 (* 1 = 6.61003 loss)
I0601 11:26:17.027412 28894 sgd_solver.cpp:138] Iteration 1100, lr = 2.5e-05
I0601 11:26:23.862196 28894 solver.cpp:243] Iteration 1110, loss = 6.97574
I0601 11:26:23.862221 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.84604 (* 1 = 6.84604 loss)
I0601 11:26:23.862226 28894 sgd_solver.cpp:138] Iteration 1110, lr = 2.5e-05
I0601 11:26:30.763847 28894 solver.cpp:243] Iteration 1120, loss = 6.71789
I0601 11:26:30.763958 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.50058 (* 1 = 6.50058 loss)
I0601 11:26:30.763965 28894 sgd_solver.cpp:138] Iteration 1120, lr = 2.5e-05
I0601 11:26:37.649349 28894 solver.cpp:243] Iteration 1130, loss = 6.96562
I0601 11:26:37.649374 28894 solver.cpp:259]     Train net output #0: mbox_loss = 7.35509 (* 1 = 7.35509 loss)
I0601 11:26:37.649380 28894 sgd_solver.cpp:138] Iteration 1130, lr = 2.5e-05
I0601 11:26:44.476161 28894 solver.cpp:243] Iteration 1140, loss = 6.84224
I0601 11:26:44.476183 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.69996 (* 1 = 6.69996 loss)
I0601 11:26:44.476189 28894 sgd_solver.cpp:138] Iteration 1140, lr = 2.5e-05
I0601 11:26:51.226313 28894 solver.cpp:243] Iteration 1150, loss = 6.86605
I0601 11:26:51.226339 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.6124 (* 1 = 6.6124 loss)
I0601 11:26:51.226346 28894 sgd_solver.cpp:138] Iteration 1150, lr = 2.5e-05
I0601 11:26:58.070519 28894 solver.cpp:243] Iteration 1160, loss = 6.86855
I0601 11:26:58.070547 28894 solver.cpp:259]     Train net output #0: mbox_loss = 7.41745 (* 1 = 7.41745 loss)
I0601 11:26:58.070554 28894 sgd_solver.cpp:138] Iteration 1160, lr = 2.5e-05
I0601 11:27:05.238418 28894 solver.cpp:243] Iteration 1170, loss = 6.70356
I0601 11:27:05.238603 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.6427 (* 1 = 6.6427 loss)
I0601 11:27:05.238611 28894 sgd_solver.cpp:138] Iteration 1170, lr = 2.5e-05
I0601 11:27:12.015318 28894 solver.cpp:243] Iteration 1180, loss = 6.87248
I0601 11:27:12.015343 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.53589 (* 1 = 6.53589 loss)
I0601 11:27:12.015348 28894 sgd_solver.cpp:138] Iteration 1180, lr = 2.5e-05
I0601 11:27:18.954316 28894 solver.cpp:243] Iteration 1190, loss = 6.94008
I0601 11:27:18.954341 28894 solver.cpp:259]     Train net output #0: mbox_loss = 7.4654 (* 1 = 7.4654 loss)
I0601 11:27:18.954347 28894 sgd_solver.cpp:138] Iteration 1190, lr = 2.5e-05
I0601 11:27:25.188721 28894 solver.cpp:433] Iteration 1200, Testing net (#0)
I0601 11:27:25.188768 28894 net.cpp:693] Ignoring source layer mbox_loss
I0601 11:27:27.587810 28894 solver.cpp:546]     Test net output #0: detection_eval = 0.0511794
I0601 11:27:28.437858 28894 solver.cpp:243] Iteration 1200, loss = 6.73581
I0601 11:27:28.437886 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.44835 (* 1 = 6.44835 loss)
I0601 11:27:28.437892 28894 sgd_solver.cpp:138] Iteration 1200, lr = 2.5e-05
I0601 11:27:35.264165 28894 solver.cpp:243] Iteration 1210, loss = 6.77769
I0601 11:27:35.264299 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.52918 (* 1 = 6.52918 loss)
I0601 11:27:35.264307 28894 sgd_solver.cpp:138] Iteration 1210, lr = 2.5e-05
I0601 11:27:42.279584 28894 solver.cpp:243] Iteration 1220, loss = 6.65927
I0601 11:27:42.279611 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.85581 (* 1 = 6.85581 loss)
I0601 11:27:42.279618 28894 sgd_solver.cpp:138] Iteration 1220, lr = 2.5e-05
I0601 11:27:49.177296 28894 solver.cpp:243] Iteration 1230, loss = 6.76175
I0601 11:27:49.177320 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.60836 (* 1 = 6.60836 loss)
I0601 11:27:49.177327 28894 sgd_solver.cpp:138] Iteration 1230, lr = 2.5e-05
I0601 11:27:56.568455 28894 solver.cpp:243] Iteration 1240, loss = 6.73526
I0601 11:27:56.568482 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.21341 (* 1 = 6.21341 loss)
I0601 11:27:56.568488 28894 sgd_solver.cpp:138] Iteration 1240, lr = 2.5e-05
I0601 11:28:03.620219 28894 solver.cpp:243] Iteration 1250, loss = 6.87111
I0601 11:28:03.620246 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.51939 (* 1 = 6.51939 loss)
I0601 11:28:03.620252 28894 sgd_solver.cpp:138] Iteration 1250, lr = 2.5e-05
I0601 11:28:10.551883 28894 solver.cpp:243] Iteration 1260, loss = 6.51245
I0601 11:28:10.552045 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.05342 (* 1 = 6.05342 loss)
I0601 11:28:10.552052 28894 sgd_solver.cpp:138] Iteration 1260, lr = 2.5e-05
I0601 11:28:17.494446 28894 solver.cpp:243] Iteration 1270, loss = 6.83762
I0601 11:28:17.494470 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.70141 (* 1 = 6.70141 loss)
I0601 11:28:17.494477 28894 sgd_solver.cpp:138] Iteration 1270, lr = 2.5e-05
I0601 11:28:24.386508 28894 solver.cpp:243] Iteration 1280, loss = 6.62848
I0601 11:28:24.386534 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.45052 (* 1 = 6.45052 loss)
I0601 11:28:24.386539 28894 sgd_solver.cpp:138] Iteration 1280, lr = 2.5e-05
I0601 11:28:31.106223 28894 solver.cpp:243] Iteration 1290, loss = 6.65444
I0601 11:28:31.106248 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.86528 (* 1 = 6.86528 loss)
I0601 11:28:31.106253 28894 sgd_solver.cpp:138] Iteration 1290, lr = 2.5e-05
I0601 11:28:37.103852 28894 solver.cpp:433] Iteration 1300, Testing net (#0)
I0601 11:28:37.103899 28894 net.cpp:693] Ignoring source layer mbox_loss
I0601 11:28:39.522080 28894 solver.cpp:546]     Test net output #0: detection_eval = 0.0576304
I0601 11:28:40.221259 28894 solver.cpp:243] Iteration 1300, loss = 6.6709
I0601 11:28:40.221284 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.55695 (* 1 = 6.55695 loss)
I0601 11:28:40.221290 28894 sgd_solver.cpp:138] Iteration 1300, lr = 2.5e-05
I0601 11:28:47.065137 28894 solver.cpp:243] Iteration 1310, loss = 6.6766
I0601 11:28:47.065290 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.46997 (* 1 = 6.46997 loss)
I0601 11:28:47.065297 28894 sgd_solver.cpp:138] Iteration 1310, lr = 2.5e-05
I0601 11:28:54.048494 28894 solver.cpp:243] Iteration 1320, loss = 6.50503
I0601 11:28:54.048519 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.36439 (* 1 = 6.36439 loss)
I0601 11:28:54.048527 28894 sgd_solver.cpp:138] Iteration 1320, lr = 2.5e-05
I0601 11:29:01.051084 28894 solver.cpp:243] Iteration 1330, loss = 6.54156
I0601 11:29:01.051110 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.69878 (* 1 = 6.69878 loss)
I0601 11:29:01.051115 28894 sgd_solver.cpp:138] Iteration 1330, lr = 2.5e-05
I0601 11:29:07.759341 28894 solver.cpp:243] Iteration 1340, loss = 6.5602
I0601 11:29:07.759366 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.12724 (* 1 = 6.12724 loss)
I0601 11:29:07.759372 28894 sgd_solver.cpp:138] Iteration 1340, lr = 2.5e-05
I0601 11:29:14.540158 28894 solver.cpp:243] Iteration 1350, loss = 6.53086
I0601 11:29:14.540181 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.7802 (* 1 = 6.7802 loss)
I0601 11:29:14.540187 28894 sgd_solver.cpp:138] Iteration 1350, lr = 2.5e-05
I0601 11:29:21.857192 28894 solver.cpp:243] Iteration 1360, loss = 6.49269
I0601 11:29:21.857306 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.61315 (* 1 = 6.61315 loss)
I0601 11:29:21.857312 28894 sgd_solver.cpp:138] Iteration 1360, lr = 2.5e-05
I0601 11:29:28.568801 28894 solver.cpp:243] Iteration 1370, loss = 6.51436
I0601 11:29:28.568828 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.37729 (* 1 = 6.37729 loss)
I0601 11:29:28.568833 28894 sgd_solver.cpp:138] Iteration 1370, lr = 2.5e-05
I0601 11:29:35.354449 28894 solver.cpp:243] Iteration 1380, loss = 6.58594
I0601 11:29:35.354473 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.19752 (* 1 = 6.19752 loss)
I0601 11:29:35.354480 28894 sgd_solver.cpp:138] Iteration 1380, lr = 2.5e-05
I0601 11:29:42.195166 28894 solver.cpp:243] Iteration 1390, loss = 6.39128
I0601 11:29:42.195190 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.37183 (* 1 = 6.37183 loss)
I0601 11:29:42.195195 28894 sgd_solver.cpp:138] Iteration 1390, lr = 2.5e-05
I0601 11:29:48.351850 28894 solver.cpp:433] Iteration 1400, Testing net (#0)
I0601 11:29:48.351894 28894 net.cpp:693] Ignoring source layer mbox_loss
I0601 11:29:50.777631 28894 solver.cpp:546]     Test net output #0: detection_eval = 0.0580001
I0601 11:29:51.448233 28894 solver.cpp:243] Iteration 1400, loss = 6.53974
I0601 11:29:51.448258 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.17534 (* 1 = 6.17534 loss)
I0601 11:29:51.448263 28894 sgd_solver.cpp:138] Iteration 1400, lr = 2.5e-05
I0601 11:29:58.282912 28894 solver.cpp:243] Iteration 1410, loss = 6.66543
I0601 11:29:58.283027 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.73475 (* 1 = 6.73475 loss)
I0601 11:29:58.283049 28894 sgd_solver.cpp:138] Iteration 1410, lr = 2.5e-05
I0601 11:30:05.188791 28894 solver.cpp:243] Iteration 1420, loss = 6.39281
I0601 11:30:05.188815 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.00896 (* 1 = 6.00896 loss)
I0601 11:30:05.188822 28894 sgd_solver.cpp:138] Iteration 1420, lr = 2.5e-05
I0601 11:30:11.878716 28894 solver.cpp:243] Iteration 1430, loss = 6.53923
I0601 11:30:11.878742 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.47036 (* 1 = 6.47036 loss)
I0601 11:30:11.878748 28894 sgd_solver.cpp:138] Iteration 1430, lr = 2.5e-05
I0601 11:30:18.684674 28894 solver.cpp:243] Iteration 1440, loss = 6.47994
I0601 11:30:18.684700 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.32793 (* 1 = 6.32793 loss)
I0601 11:30:18.684705 28894 sgd_solver.cpp:138] Iteration 1440, lr = 2.5e-05
I0601 11:30:25.391674 28894 solver.cpp:243] Iteration 1450, loss = 6.41106
I0601 11:30:25.391700 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.81671 (* 1 = 6.81671 loss)
I0601 11:30:25.391706 28894 sgd_solver.cpp:138] Iteration 1450, lr = 2.5e-05
I0601 11:30:32.349328 28894 solver.cpp:243] Iteration 1460, loss = 6.41293
I0601 11:30:32.349501 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.24634 (* 1 = 6.24634 loss)
I0601 11:30:32.349509 28894 sgd_solver.cpp:138] Iteration 1460, lr = 2.5e-05
I0601 11:30:39.798935 28894 solver.cpp:243] Iteration 1470, loss = 6.4051
I0601 11:30:39.798962 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.46186 (* 1 = 6.46186 loss)
I0601 11:30:39.798969 28894 sgd_solver.cpp:138] Iteration 1470, lr = 2.5e-05
I0601 11:30:47.145710 28894 solver.cpp:243] Iteration 1480, loss = 6.39345
I0601 11:30:47.145738 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.10596 (* 1 = 6.10596 loss)
I0601 11:30:47.145745 28894 sgd_solver.cpp:138] Iteration 1480, lr = 2.5e-05
I0601 11:30:54.363277 28894 solver.cpp:243] Iteration 1490, loss = 6.35471
I0601 11:30:54.363304 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.2792 (* 1 = 6.2792 loss)
I0601 11:30:54.363310 28894 sgd_solver.cpp:138] Iteration 1490, lr = 2.5e-05
I0601 11:31:00.570241 28894 solver.cpp:433] Iteration 1500, Testing net (#0)
I0601 11:31:00.570286 28894 net.cpp:693] Ignoring source layer mbox_loss
I0601 11:31:02.986670 28894 solver.cpp:546]     Test net output #0: detection_eval = 0.056975
I0601 11:31:03.669878 28894 solver.cpp:243] Iteration 1500, loss = 6.52603
I0601 11:31:03.669901 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.07405 (* 1 = 6.07405 loss)
I0601 11:31:03.669906 28894 sgd_solver.cpp:138] Iteration 1500, lr = 2.5e-05
I0601 11:31:10.572952 28894 solver.cpp:243] Iteration 1510, loss = 6.32446
I0601 11:31:10.572978 28894 solver.cpp:259]     Train net output #0: mbox_loss = 7.57434 (* 1 = 7.57434 loss)
I0601 11:31:10.572983 28894 sgd_solver.cpp:138] Iteration 1510, lr = 2.5e-05
I0601 11:31:18.076283 28894 solver.cpp:243] Iteration 1520, loss = 6.43261
I0601 11:31:18.076308 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.37338 (* 1 = 6.37338 loss)
I0601 11:31:18.076315 28894 sgd_solver.cpp:138] Iteration 1520, lr = 2.5e-05
I0601 11:31:25.298691 28894 solver.cpp:243] Iteration 1530, loss = 6.33175
I0601 11:31:25.298717 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.22836 (* 1 = 6.22836 loss)
I0601 11:31:25.298722 28894 sgd_solver.cpp:138] Iteration 1530, lr = 2.5e-05
I0601 11:31:31.984407 28894 solver.cpp:243] Iteration 1540, loss = 6.32119
I0601 11:31:31.984434 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.52774 (* 1 = 6.52774 loss)
I0601 11:31:31.984441 28894 sgd_solver.cpp:138] Iteration 1540, lr = 2.5e-05
I0601 11:31:39.103127 28894 solver.cpp:243] Iteration 1550, loss = 6.31455
I0601 11:31:39.103237 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.22631 (* 1 = 6.22631 loss)
I0601 11:31:39.103243 28894 sgd_solver.cpp:138] Iteration 1550, lr = 2.5e-05
I0601 11:31:46.414945 28894 solver.cpp:243] Iteration 1560, loss = 6.25899
I0601 11:31:46.414971 28894 solver.cpp:259]     Train net output #0: mbox_loss = 5.97699 (* 1 = 5.97699 loss)
I0601 11:31:46.414978 28894 sgd_solver.cpp:138] Iteration 1560, lr = 2.5e-05
I0601 11:31:53.885625 28894 solver.cpp:243] Iteration 1570, loss = 6.28441
I0601 11:31:53.885653 28894 solver.cpp:259]     Train net output #0: mbox_loss = 5.9173 (* 1 = 5.9173 loss)
I0601 11:31:53.885658 28894 sgd_solver.cpp:138] Iteration 1570, lr = 2.5e-05
I0601 11:32:00.902701 28894 solver.cpp:243] Iteration 1580, loss = 6.30258
I0601 11:32:00.902729 28894 solver.cpp:259]     Train net output #0: mbox_loss = 5.68896 (* 1 = 5.68896 loss)
I0601 11:32:00.902735 28894 sgd_solver.cpp:138] Iteration 1580, lr = 2.5e-05
I0601 11:32:07.604959 28894 solver.cpp:243] Iteration 1590, loss = 6.2691
I0601 11:32:07.604986 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.05401 (* 1 = 6.05401 loss)
I0601 11:32:07.604993 28894 sgd_solver.cpp:138] Iteration 1590, lr = 2.5e-05
I0601 11:32:13.637182 28894 solver.cpp:433] Iteration 1600, Testing net (#0)
I0601 11:32:13.637351 28894 net.cpp:693] Ignoring source layer mbox_loss
I0601 11:32:15.979600 28894 solver.cpp:546]     Test net output #0: detection_eval = 0.068739
I0601 11:32:16.625388 28894 solver.cpp:243] Iteration 1600, loss = 6.20431
I0601 11:32:16.625412 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.0777 (* 1 = 6.0777 loss)
I0601 11:32:16.625417 28894 sgd_solver.cpp:138] Iteration 1600, lr = 2.5e-05
I0601 11:32:23.385329 28894 solver.cpp:243] Iteration 1610, loss = 6.18555
I0601 11:32:23.385356 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.61898 (* 1 = 6.61898 loss)
I0601 11:32:23.385362 28894 sgd_solver.cpp:138] Iteration 1610, lr = 2.5e-05
I0601 11:32:30.153693 28894 solver.cpp:243] Iteration 1620, loss = 6.23208
I0601 11:32:30.153717 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.28426 (* 1 = 6.28426 loss)
I0601 11:32:30.153723 28894 sgd_solver.cpp:138] Iteration 1620, lr = 2.5e-05
I0601 11:32:37.255116 28894 solver.cpp:243] Iteration 1630, loss = 6.28969
I0601 11:32:37.255142 28894 solver.cpp:259]     Train net output #0: mbox_loss = 5.87475 (* 1 = 5.87475 loss)
I0601 11:32:37.255147 28894 sgd_solver.cpp:138] Iteration 1630, lr = 2.5e-05
I0601 11:32:44.219714 28894 solver.cpp:243] Iteration 1640, loss = 6.28335
I0601 11:32:44.219830 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.04761 (* 1 = 6.04761 loss)
I0601 11:32:44.219836 28894 sgd_solver.cpp:138] Iteration 1640, lr = 2.5e-05
I0601 11:32:51.102407 28894 solver.cpp:243] Iteration 1650, loss = 6.26526
I0601 11:32:51.102432 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.15269 (* 1 = 6.15269 loss)
I0601 11:32:51.102439 28894 sgd_solver.cpp:138] Iteration 1650, lr = 2.5e-05
I0601 11:32:57.950953 28894 solver.cpp:243] Iteration 1660, loss = 6.23542
I0601 11:32:57.950984 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.65305 (* 1 = 6.65305 loss)
I0601 11:32:57.950992 28894 sgd_solver.cpp:138] Iteration 1660, lr = 2.5e-05
I0601 11:33:05.001504 28894 solver.cpp:243] Iteration 1670, loss = 6.25401
I0601 11:33:05.001530 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.98876 (* 1 = 6.98876 loss)
I0601 11:33:05.001536 28894 sgd_solver.cpp:138] Iteration 1670, lr = 2.5e-05
I0601 11:33:11.840268 28894 solver.cpp:243] Iteration 1680, loss = 6.18973
I0601 11:33:11.840293 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.06431 (* 1 = 6.06431 loss)
I0601 11:33:11.840298 28894 sgd_solver.cpp:138] Iteration 1680, lr = 2.5e-05
I0601 11:33:18.766193 28894 solver.cpp:243] Iteration 1690, loss = 6.19051
I0601 11:33:18.766335 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.01672 (* 1 = 6.01672 loss)
I0601 11:33:18.766341 28894 sgd_solver.cpp:138] Iteration 1690, lr = 2.5e-05
I0601 11:33:24.848585 28894 solver.cpp:433] Iteration 1700, Testing net (#0)
I0601 11:33:24.848649 28894 net.cpp:693] Ignoring source layer mbox_loss
I0601 11:33:27.447329 28894 solver.cpp:546]     Test net output #0: detection_eval = 0.0639499
I0601 11:33:28.155359 28894 solver.cpp:243] Iteration 1700, loss = 6.2609
I0601 11:33:28.155385 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.359 (* 1 = 6.359 loss)
I0601 11:33:28.155390 28894 sgd_solver.cpp:138] Iteration 1700, lr = 2.5e-05
I0601 11:33:35.251035 28894 solver.cpp:243] Iteration 1710, loss = 6.06548
I0601 11:33:35.251060 28894 solver.cpp:259]     Train net output #0: mbox_loss = 5.86701 (* 1 = 5.86701 loss)
I0601 11:33:35.251065 28894 sgd_solver.cpp:138] Iteration 1710, lr = 2.5e-05
I0601 11:33:42.344800 28894 solver.cpp:243] Iteration 1720, loss = 6.17021
I0601 11:33:42.344826 28894 solver.cpp:259]     Train net output #0: mbox_loss = 5.69907 (* 1 = 5.69907 loss)
I0601 11:33:42.344831 28894 sgd_solver.cpp:138] Iteration 1720, lr = 2.5e-05
I0601 11:33:49.146550 28894 solver.cpp:243] Iteration 1730, loss = 6.06211
I0601 11:33:49.146704 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.64037 (* 1 = 6.64037 loss)
I0601 11:33:49.146711 28894 sgd_solver.cpp:138] Iteration 1730, lr = 2.5e-05
I0601 11:33:56.263860 28894 solver.cpp:243] Iteration 1740, loss = 6.10829
I0601 11:33:56.263886 28894 solver.cpp:259]     Train net output #0: mbox_loss = 5.82938 (* 1 = 5.82938 loss)
I0601 11:33:56.263891 28894 sgd_solver.cpp:138] Iteration 1740, lr = 2.5e-05
I0601 11:34:03.421010 28894 solver.cpp:243] Iteration 1750, loss = 6.22335
I0601 11:34:03.421035 28894 solver.cpp:259]     Train net output #0: mbox_loss = 5.6677 (* 1 = 5.6677 loss)
I0601 11:34:03.421039 28894 sgd_solver.cpp:138] Iteration 1750, lr = 2.5e-05
I0601 11:34:10.123339 28894 solver.cpp:243] Iteration 1760, loss = 6.08331
I0601 11:34:10.123368 28894 solver.cpp:259]     Train net output #0: mbox_loss = 5.77463 (* 1 = 5.77463 loss)
I0601 11:34:10.123373 28894 sgd_solver.cpp:138] Iteration 1760, lr = 2.5e-05
I0601 11:34:17.254026 28894 solver.cpp:243] Iteration 1770, loss = 5.9993
I0601 11:34:17.254052 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.61534 (* 1 = 6.61534 loss)
I0601 11:34:17.254058 28894 sgd_solver.cpp:138] Iteration 1770, lr = 2.5e-05
I0601 11:34:24.255910 28894 solver.cpp:243] Iteration 1780, loss = 6.08233
I0601 11:34:24.256068 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.06925 (* 1 = 6.06925 loss)
I0601 11:34:24.256077 28894 sgd_solver.cpp:138] Iteration 1780, lr = 2.5e-05
I0601 11:34:31.507937 28894 solver.cpp:243] Iteration 1790, loss = 6.15108
I0601 11:34:31.507963 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.19824 (* 1 = 6.19824 loss)
I0601 11:34:31.507969 28894 sgd_solver.cpp:138] Iteration 1790, lr = 2.5e-05
I0601 11:34:37.759183 28894 solver.cpp:433] Iteration 1800, Testing net (#0)
I0601 11:34:37.759229 28894 net.cpp:693] Ignoring source layer mbox_loss
I0601 11:34:40.204473 28894 solver.cpp:546]     Test net output #0: detection_eval = 0.0675382
I0601 11:34:40.879462 28894 solver.cpp:243] Iteration 1800, loss = 6.09882
I0601 11:34:40.879487 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.0586 (* 1 = 6.0586 loss)
I0601 11:34:40.879492 28894 sgd_solver.cpp:138] Iteration 1800, lr = 2.5e-05
I0601 11:34:47.609982 28894 solver.cpp:243] Iteration 1810, loss = 5.98524
I0601 11:34:47.610008 28894 solver.cpp:259]     Train net output #0: mbox_loss = 5.72401 (* 1 = 5.72401 loss)
I0601 11:34:47.610013 28894 sgd_solver.cpp:138] Iteration 1810, lr = 2.5e-05
I0601 11:34:54.449311 28894 solver.cpp:243] Iteration 1820, loss = 6.04897
I0601 11:34:54.449407 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.02994 (* 1 = 6.02994 loss)
I0601 11:34:54.449414 28894 sgd_solver.cpp:138] Iteration 1820, lr = 2.5e-05
I0601 11:35:01.337805 28894 solver.cpp:243] Iteration 1830, loss = 6.09489
I0601 11:35:01.337831 28894 solver.cpp:259]     Train net output #0: mbox_loss = 7.35272 (* 1 = 7.35272 loss)
I0601 11:35:01.337836 28894 sgd_solver.cpp:138] Iteration 1830, lr = 2.5e-05
I0601 11:35:08.408134 28894 solver.cpp:243] Iteration 1840, loss = 6.03015
I0601 11:35:08.408159 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.01986 (* 1 = 6.01986 loss)
I0601 11:35:08.408165 28894 sgd_solver.cpp:138] Iteration 1840, lr = 2.5e-05
I0601 11:35:15.204494 28894 solver.cpp:243] Iteration 1850, loss = 5.99912
I0601 11:35:15.204520 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.1286 (* 1 = 6.1286 loss)
I0601 11:35:15.204525 28894 sgd_solver.cpp:138] Iteration 1850, lr = 2.5e-05
I0601 11:35:21.954991 28894 solver.cpp:243] Iteration 1860, loss = 6.18444
I0601 11:35:21.955018 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.59333 (* 1 = 6.59333 loss)
I0601 11:35:21.955024 28894 sgd_solver.cpp:138] Iteration 1860, lr = 2.5e-05
I0601 11:35:28.595713 28894 solver.cpp:243] Iteration 1870, loss = 5.98685
I0601 11:35:28.595850 28894 solver.cpp:259]     Train net output #0: mbox_loss = 5.7545 (* 1 = 5.7545 loss)
I0601 11:35:28.595857 28894 sgd_solver.cpp:138] Iteration 1870, lr = 2.5e-05
I0601 11:35:35.442466 28894 solver.cpp:243] Iteration 1880, loss = 6.03501
I0601 11:35:35.442492 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.61216 (* 1 = 6.61216 loss)
I0601 11:35:35.442497 28894 sgd_solver.cpp:138] Iteration 1880, lr = 2.5e-05
I0601 11:35:42.401773 28894 solver.cpp:243] Iteration 1890, loss = 6.21813
I0601 11:35:42.401798 28894 solver.cpp:259]     Train net output #0: mbox_loss = 5.76565 (* 1 = 5.76565 loss)
I0601 11:35:42.401803 28894 sgd_solver.cpp:138] Iteration 1890, lr = 2.5e-05
I0601 11:35:48.757083 28894 solver.cpp:433] Iteration 1900, Testing net (#0)
I0601 11:35:48.757146 28894 net.cpp:693] Ignoring source layer mbox_loss
I0601 11:35:51.297358 28894 solver.cpp:546]     Test net output #0: detection_eval = 0.0756664
I0601 11:35:51.988741 28894 solver.cpp:243] Iteration 1900, loss = 5.91706
I0601 11:35:51.988766 28894 solver.cpp:259]     Train net output #0: mbox_loss = 5.40229 (* 1 = 5.40229 loss)
I0601 11:35:51.988771 28894 sgd_solver.cpp:138] Iteration 1900, lr = 2.5e-05
I0601 11:35:58.909523 28894 solver.cpp:243] Iteration 1910, loss = 6.12525
I0601 11:35:58.911797 28894 solver.cpp:259]     Train net output #0: mbox_loss = 5.73812 (* 1 = 5.73812 loss)
I0601 11:35:58.911804 28894 sgd_solver.cpp:138] Iteration 1910, lr = 2.5e-05
I0601 11:36:05.982328 28894 solver.cpp:243] Iteration 1920, loss = 5.86882
I0601 11:36:05.982355 28894 solver.cpp:259]     Train net output #0: mbox_loss = 5.96955 (* 1 = 5.96955 loss)
I0601 11:36:05.982362 28894 sgd_solver.cpp:138] Iteration 1920, lr = 2.5e-05
I0601 11:36:13.179500 28894 solver.cpp:243] Iteration 1930, loss = 6.00152
I0601 11:36:13.179527 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.80333 (* 1 = 6.80333 loss)
I0601 11:36:13.179532 28894 sgd_solver.cpp:138] Iteration 1930, lr = 2.5e-05
I0601 11:36:20.135133 28894 solver.cpp:243] Iteration 1940, loss = 6.09172
I0601 11:36:20.135159 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.23049 (* 1 = 6.23049 loss)
I0601 11:36:20.135164 28894 sgd_solver.cpp:138] Iteration 1940, lr = 2.5e-05
I0601 11:36:26.931030 28894 solver.cpp:243] Iteration 1950, loss = 6.01912
I0601 11:36:26.931056 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.16841 (* 1 = 6.16841 loss)
I0601 11:36:26.931061 28894 sgd_solver.cpp:138] Iteration 1950, lr = 2.5e-05
I0601 11:36:33.799827 28894 solver.cpp:243] Iteration 1960, loss = 5.87004
I0601 11:36:33.799944 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.08495 (* 1 = 6.08495 loss)
I0601 11:36:33.799964 28894 sgd_solver.cpp:138] Iteration 1960, lr = 2.5e-05
I0601 11:36:40.474583 28894 solver.cpp:243] Iteration 1970, loss = 6.0601
I0601 11:36:40.474607 28894 solver.cpp:259]     Train net output #0: mbox_loss = 5.40898 (* 1 = 5.40898 loss)
I0601 11:36:40.474614 28894 sgd_solver.cpp:138] Iteration 1970, lr = 2.5e-05
I0601 11:36:47.136977 28894 solver.cpp:243] Iteration 1980, loss = 6.06704
I0601 11:36:47.137001 28894 solver.cpp:259]     Train net output #0: mbox_loss = 5.90972 (* 1 = 5.90972 loss)
I0601 11:36:47.137007 28894 sgd_solver.cpp:138] Iteration 1980, lr = 2.5e-05
I0601 11:36:54.053256 28894 solver.cpp:243] Iteration 1990, loss = 5.89633
I0601 11:36:54.053287 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.61124 (* 1 = 6.61124 loss)
I0601 11:36:54.053292 28894 sgd_solver.cpp:138] Iteration 1990, lr = 2.5e-05
I0601 11:37:00.300909 28894 solver.cpp:596] Snapshotting to binary proto file models/VGGNet/tbs/SSD_300x300/VGG_tbs_300x300_HSIL_10x_SSD_300x300_iter_2000.caffemodel
I0601 11:37:00.618649 28894 sgd_solver.cpp:307] Snapshotting solver state to binary proto file models/VGGNet/tbs/SSD_300x300/VGG_tbs_300x300_HSIL_10x_SSD_300x300_iter_2000.solverstate
I0601 11:37:00.745463 28894 solver.cpp:433] Iteration 2000, Testing net (#0)
I0601 11:37:00.745528 28894 net.cpp:693] Ignoring source layer mbox_loss
I0601 11:37:03.205088 28894 solver.cpp:546]     Test net output #0: detection_eval = 0.0729837
I0601 11:37:03.854532 28894 solver.cpp:243] Iteration 2000, loss = 5.93858
I0601 11:37:03.854666 28894 solver.cpp:259]     Train net output #0: mbox_loss = 5.7028 (* 1 = 5.7028 loss)
I0601 11:37:03.854673 28894 sgd_solver.cpp:138] Iteration 2000, lr = 2.5e-05
I0601 11:37:10.871537 28894 solver.cpp:243] Iteration 2010, loss = 6.05786
I0601 11:37:10.871564 28894 solver.cpp:259]     Train net output #0: mbox_loss = 5.82856 (* 1 = 5.82856 loss)
I0601 11:37:10.871570 28894 sgd_solver.cpp:138] Iteration 2010, lr = 2.5e-05
I0601 11:37:17.596664 28894 solver.cpp:243] Iteration 2020, loss = 6.09743
I0601 11:37:17.596689 28894 solver.cpp:259]     Train net output #0: mbox_loss = 5.8564 (* 1 = 5.8564 loss)
I0601 11:37:17.596696 28894 sgd_solver.cpp:138] Iteration 2020, lr = 2.5e-05
I0601 11:37:24.328711 28894 solver.cpp:243] Iteration 2030, loss = 5.96537
I0601 11:37:24.328737 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.19559 (* 1 = 6.19559 loss)
I0601 11:37:24.328743 28894 sgd_solver.cpp:138] Iteration 2030, lr = 2.5e-05
I0601 11:37:31.090654 28894 solver.cpp:243] Iteration 2040, loss = 5.90467
I0601 11:37:31.090678 28894 solver.cpp:259]     Train net output #0: mbox_loss = 5.1764 (* 1 = 5.1764 loss)
I0601 11:37:31.090684 28894 sgd_solver.cpp:138] Iteration 2040, lr = 2.5e-05
I0601 11:37:37.847046 28894 solver.cpp:243] Iteration 2050, loss = 6.00482
I0601 11:37:37.849146 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.96415 (* 1 = 6.96415 loss)
I0601 11:37:37.849153 28894 sgd_solver.cpp:138] Iteration 2050, lr = 2.5e-05
I0601 11:37:44.789011 28894 solver.cpp:243] Iteration 2060, loss = 5.92529
I0601 11:37:44.789036 28894 solver.cpp:259]     Train net output #0: mbox_loss = 5.52075 (* 1 = 5.52075 loss)
I0601 11:37:44.789041 28894 sgd_solver.cpp:138] Iteration 2060, lr = 2.5e-05
I0601 11:37:51.612402 28894 solver.cpp:243] Iteration 2070, loss = 6.00195
I0601 11:37:51.612426 28894 solver.cpp:259]     Train net output #0: mbox_loss = 5.69048 (* 1 = 5.69048 loss)
I0601 11:37:51.612447 28894 sgd_solver.cpp:138] Iteration 2070, lr = 2.5e-05
I0601 11:37:58.285430 28894 solver.cpp:243] Iteration 2080, loss = 5.8852
I0601 11:37:58.285454 28894 solver.cpp:259]     Train net output #0: mbox_loss = 5.53753 (* 1 = 5.53753 loss)
I0601 11:37:58.285460 28894 sgd_solver.cpp:138] Iteration 2080, lr = 2.5e-05
I0601 11:38:05.018216 28894 solver.cpp:243] Iteration 2090, loss = 6.02234
I0601 11:38:05.018242 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.92356 (* 1 = 6.92356 loss)
I0601 11:38:05.018249 28894 sgd_solver.cpp:138] Iteration 2090, lr = 2.5e-05
I0601 11:38:11.092316 28894 solver.cpp:433] Iteration 2100, Testing net (#0)
I0601 11:38:11.092492 28894 net.cpp:693] Ignoring source layer mbox_loss
I0601 11:38:13.397614 28894 solver.cpp:546]     Test net output #0: detection_eval = 0.0751682
I0601 11:38:14.066443 28894 solver.cpp:243] Iteration 2100, loss = 5.78577
I0601 11:38:14.066470 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.24306 (* 1 = 6.24306 loss)
I0601 11:38:14.066475 28894 sgd_solver.cpp:138] Iteration 2100, lr = 2.5e-05
I0601 11:38:20.765308 28894 solver.cpp:243] Iteration 2110, loss = 6.11323
I0601 11:38:20.765336 28894 solver.cpp:259]     Train net output #0: mbox_loss = 5.47184 (* 1 = 5.47184 loss)
I0601 11:38:20.765341 28894 sgd_solver.cpp:138] Iteration 2110, lr = 2.5e-05
I0601 11:38:27.517753 28894 solver.cpp:243] Iteration 2120, loss = 5.89901
I0601 11:38:27.517774 28894 solver.cpp:259]     Train net output #0: mbox_loss = 5.77091 (* 1 = 5.77091 loss)
I0601 11:38:27.517779 28894 sgd_solver.cpp:138] Iteration 2120, lr = 2.5e-05
I0601 11:38:34.494753 28894 solver.cpp:243] Iteration 2130, loss = 5.95881
I0601 11:38:34.494782 28894 solver.cpp:259]     Train net output #0: mbox_loss = 5.28966 (* 1 = 5.28966 loss)
I0601 11:38:34.494789 28894 sgd_solver.cpp:138] Iteration 2130, lr = 2.5e-05
I0601 11:38:41.751565 28894 solver.cpp:243] Iteration 2140, loss = 5.90834
I0601 11:38:41.751706 28894 solver.cpp:259]     Train net output #0: mbox_loss = 5.80002 (* 1 = 5.80002 loss)
I0601 11:38:41.751727 28894 sgd_solver.cpp:138] Iteration 2140, lr = 2.5e-05
I0601 11:38:49.363952 28894 solver.cpp:243] Iteration 2150, loss = 5.68663
I0601 11:38:49.363978 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.47111 (* 1 = 6.47111 loss)
I0601 11:38:49.363984 28894 sgd_solver.cpp:138] Iteration 2150, lr = 2.5e-05
I0601 11:38:56.258090 28894 solver.cpp:243] Iteration 2160, loss = 5.74387
I0601 11:38:56.258117 28894 solver.cpp:259]     Train net output #0: mbox_loss = 5.4353 (* 1 = 5.4353 loss)
I0601 11:38:56.258122 28894 sgd_solver.cpp:138] Iteration 2160, lr = 2.5e-05
I0601 11:39:03.167301 28894 solver.cpp:243] Iteration 2170, loss = 5.85237
I0601 11:39:03.167326 28894 solver.cpp:259]     Train net output #0: mbox_loss = 5.76085 (* 1 = 5.76085 loss)
I0601 11:39:03.167333 28894 sgd_solver.cpp:138] Iteration 2170, lr = 2.5e-05
I0601 11:39:10.971509 28894 solver.cpp:243] Iteration 2180, loss = 6.01196
I0601 11:39:10.971549 28894 solver.cpp:259]     Train net output #0: mbox_loss = 5.92969 (* 1 = 5.92969 loss)
I0601 11:39:10.971556 28894 sgd_solver.cpp:138] Iteration 2180, lr = 2.5e-05
I0601 11:39:18.134790 28894 solver.cpp:243] Iteration 2190, loss = 5.79852
I0601 11:39:18.134836 28894 solver.cpp:259]     Train net output #0: mbox_loss = 5.68952 (* 1 = 5.68952 loss)
I0601 11:39:18.134843 28894 sgd_solver.cpp:138] Iteration 2190, lr = 2.5e-05
I0601 11:39:24.531023 28894 solver.cpp:433] Iteration 2200, Testing net (#0)
I0601 11:39:24.531085 28894 net.cpp:693] Ignoring source layer mbox_loss
I0601 11:39:26.921751 28894 solver.cpp:546]     Test net output #0: detection_eval = 0.0755051
I0601 11:39:27.606887 28894 solver.cpp:243] Iteration 2200, loss = 5.91385
I0601 11:39:27.606910 28894 solver.cpp:259]     Train net output #0: mbox_loss = 5.43699 (* 1 = 5.43699 loss)
I0601 11:39:27.606915 28894 sgd_solver.cpp:138] Iteration 2200, lr = 2.5e-05
I0601 11:39:34.526245 28894 solver.cpp:243] Iteration 2210, loss = 5.86182
I0601 11:39:34.526270 28894 solver.cpp:259]     Train net output #0: mbox_loss = 5.67643 (* 1 = 5.67643 loss)
I0601 11:39:34.526276 28894 sgd_solver.cpp:138] Iteration 2210, lr = 2.5e-05
I0601 11:39:41.443758 28894 solver.cpp:243] Iteration 2220, loss = 5.79835
I0601 11:39:41.443783 28894 solver.cpp:259]     Train net output #0: mbox_loss = 5.73407 (* 1 = 5.73407 loss)
I0601 11:39:41.443787 28894 sgd_solver.cpp:138] Iteration 2220, lr = 2.5e-05
I0601 11:39:48.418125 28894 solver.cpp:243] Iteration 2230, loss = 5.89883
I0601 11:39:48.418298 28894 solver.cpp:259]     Train net output #0: mbox_loss = 5.40301 (* 1 = 5.40301 loss)
I0601 11:39:48.418306 28894 sgd_solver.cpp:138] Iteration 2230, lr = 2.5e-05
I0601 11:39:55.562353 28894 solver.cpp:243] Iteration 2240, loss = 5.86447
I0601 11:39:55.562379 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.50745 (* 1 = 6.50745 loss)
I0601 11:39:55.562386 28894 sgd_solver.cpp:138] Iteration 2240, lr = 2.5e-05
I0601 11:40:02.724849 28894 solver.cpp:243] Iteration 2250, loss = 6.00817
I0601 11:40:02.724877 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.47232 (* 1 = 6.47232 loss)
I0601 11:40:02.724900 28894 sgd_solver.cpp:138] Iteration 2250, lr = 2.5e-05
I0601 11:40:09.419646 28894 solver.cpp:243] Iteration 2260, loss = 5.93581
I0601 11:40:09.419672 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.02857 (* 1 = 6.02857 loss)
I0601 11:40:09.419678 28894 sgd_solver.cpp:138] Iteration 2260, lr = 2.5e-05
I0601 11:40:16.145028 28894 solver.cpp:243] Iteration 2270, loss = 5.86515
I0601 11:40:16.145053 28894 solver.cpp:259]     Train net output #0: mbox_loss = 5.06488 (* 1 = 5.06488 loss)
I0601 11:40:16.145059 28894 sgd_solver.cpp:138] Iteration 2270, lr = 2.5e-05
I0601 11:40:23.170933 28894 solver.cpp:243] Iteration 2280, loss = 5.89658
I0601 11:40:23.171041 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.21878 (* 1 = 6.21878 loss)
I0601 11:40:23.171061 28894 sgd_solver.cpp:138] Iteration 2280, lr = 2.5e-05
I0601 11:40:30.938246 28894 solver.cpp:243] Iteration 2290, loss = 5.74818
I0601 11:40:30.938292 28894 solver.cpp:259]     Train net output #0: mbox_loss = 5.82508 (* 1 = 5.82508 loss)
I0601 11:40:30.938297 28894 sgd_solver.cpp:138] Iteration 2290, lr = 2.5e-05
I0601 11:40:37.164567 28894 solver.cpp:433] Iteration 2300, Testing net (#0)
I0601 11:40:37.164609 28894 net.cpp:693] Ignoring source layer mbox_loss
I0601 11:40:39.850402 28894 solver.cpp:546]     Test net output #0: detection_eval = 0.0828281
I0601 11:40:40.503002 28894 solver.cpp:243] Iteration 2300, loss = 5.76302
I0601 11:40:40.503032 28894 solver.cpp:259]     Train net output #0: mbox_loss = 5.67451 (* 1 = 5.67451 loss)
I0601 11:40:40.503039 28894 sgd_solver.cpp:138] Iteration 2300, lr = 2.5e-05
I0601 11:40:47.618520 28894 solver.cpp:243] Iteration 2310, loss = 5.84489
I0601 11:40:47.618546 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.87941 (* 1 = 6.87941 loss)
I0601 11:40:47.618551 28894 sgd_solver.cpp:138] Iteration 2310, lr = 2.5e-05
I0601 11:40:54.300714 28894 solver.cpp:243] Iteration 2320, loss = 5.90377
I0601 11:40:54.300884 28894 solver.cpp:259]     Train net output #0: mbox_loss = 5.79458 (* 1 = 5.79458 loss)
I0601 11:40:54.300891 28894 sgd_solver.cpp:138] Iteration 2320, lr = 2.5e-05
I0601 11:41:01.376541 28894 solver.cpp:243] Iteration 2330, loss = 5.82464
I0601 11:41:01.376569 28894 solver.cpp:259]     Train net output #0: mbox_loss = 5.55547 (* 1 = 5.55547 loss)
I0601 11:41:01.376575 28894 sgd_solver.cpp:138] Iteration 2330, lr = 2.5e-05
I0601 11:41:08.056483 28894 solver.cpp:243] Iteration 2340, loss = 5.8728
I0601 11:41:08.056509 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.05618 (* 1 = 6.05618 loss)
I0601 11:41:08.056515 28894 sgd_solver.cpp:138] Iteration 2340, lr = 2.5e-05
I0601 11:41:14.722496 28894 solver.cpp:243] Iteration 2350, loss = 5.72219
I0601 11:41:14.722520 28894 solver.cpp:259]     Train net output #0: mbox_loss = 5.73637 (* 1 = 5.73637 loss)
I0601 11:41:14.722527 28894 sgd_solver.cpp:138] Iteration 2350, lr = 2.5e-05
I0601 11:41:21.480613 28894 solver.cpp:243] Iteration 2360, loss = 5.81551
I0601 11:41:21.480639 28894 solver.cpp:259]     Train net output #0: mbox_loss = 5.37749 (* 1 = 5.37749 loss)
I0601 11:41:21.480645 28894 sgd_solver.cpp:138] Iteration 2360, lr = 2.5e-05
I0601 11:41:28.255566 28894 solver.cpp:243] Iteration 2370, loss = 5.89641
I0601 11:41:28.255688 28894 solver.cpp:259]     Train net output #0: mbox_loss = 5.90217 (* 1 = 5.90217 loss)
I0601 11:41:28.255709 28894 sgd_solver.cpp:138] Iteration 2370, lr = 2.5e-05
I0601 11:41:34.976197 28894 solver.cpp:243] Iteration 2380, loss = 5.73848
I0601 11:41:34.976222 28894 solver.cpp:259]     Train net output #0: mbox_loss = 5.55456 (* 1 = 5.55456 loss)
I0601 11:41:34.976227 28894 sgd_solver.cpp:138] Iteration 2380, lr = 2.5e-05
I0601 11:41:41.682938 28894 solver.cpp:243] Iteration 2390, loss = 6.15048
I0601 11:41:41.682965 28894 solver.cpp:259]     Train net output #0: mbox_loss = 5.96635 (* 1 = 5.96635 loss)
I0601 11:41:41.682971 28894 sgd_solver.cpp:138] Iteration 2390, lr = 2.5e-05
I0601 11:41:47.680065 28894 solver.cpp:433] Iteration 2400, Testing net (#0)
I0601 11:41:47.680111 28894 net.cpp:693] Ignoring source layer mbox_loss
I0601 11:41:50.039592 28894 solver.cpp:546]     Test net output #0: detection_eval = 0.0791114
I0601 11:41:50.732363 28894 solver.cpp:243] Iteration 2400, loss = 5.84471
I0601 11:41:50.732389 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.45402 (* 1 = 6.45402 loss)
I0601 11:41:50.732394 28894 sgd_solver.cpp:138] Iteration 2400, lr = 2.5e-05
I0601 11:41:57.409705 28894 solver.cpp:243] Iteration 2410, loss = 5.94027
I0601 11:41:57.409729 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.20609 (* 1 = 6.20609 loss)
I0601 11:41:57.409735 28894 sgd_solver.cpp:138] Iteration 2410, lr = 2.5e-05
I0601 11:42:04.096966 28894 solver.cpp:243] Iteration 2420, loss = 5.66418
I0601 11:42:04.097117 28894 solver.cpp:259]     Train net output #0: mbox_loss = 5.95551 (* 1 = 5.95551 loss)
I0601 11:42:04.097126 28894 sgd_solver.cpp:138] Iteration 2420, lr = 2.5e-05
I0601 11:42:10.962893 28894 solver.cpp:243] Iteration 2430, loss = 5.87506
I0601 11:42:10.962920 28894 solver.cpp:259]     Train net output #0: mbox_loss = 6.07066 (* 1 = 6.07066 loss)
I0601 11:42:10.962926 28894 sgd_solver.cpp:138] Iteration 2430, lr = 2.5e-05
I0601 11:42:18.101047 28894 solver.cpp:243] Iteration 2440, loss = 5.66124
I0601 11:42:18.101073 28894 solver.cpp:259]     Train net output #0: mbox_loss = 5.53844 (* 1 = 5.53844 loss)
I0601 11:42:18.101079 28894 sgd_solver.cpp:138] Iteration 2440, lr = 2.5e-05
I0601 11:42:24.937942 28894 solver.cpp:243] Iteration 2450, loss = 5.79735
I0601 11:42:24.937971 28894 solver.cpp:259]     Train net output #0: mbox_loss = 5.34749 (* 1 = 5.34749 loss)
I0601 11:42:24.937994 28894 sgd_solver.cpp:138] Iteration 2450, lr = 2.5e-05
