I0608 12:20:21.638454 30581 caffe.cpp:217] Using GPUs 0
I0608 12:20:21.682941 30581 caffe.cpp:222] GPU 0: TITAN X (Pascal)
I0608 12:20:22.093286 30581 solver.cpp:63] Initializing solver from parameters: 
train_net: "models/VGGNet/sharpen_tbs_v2.0/SSD_300x300/train.prototxt"
test_net: "models/VGGNet/sharpen_tbs_v2.0/SSD_300x300/test.prototxt"
test_iter: 25
test_interval: 200
base_lr: 0.0005
display: 10
max_iter: 200000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
snapshot: 2000
snapshot_prefix: "models/VGGNet/sharpen_tbs_v2.0/SSD_300x300/VGG_sharpen_tbs_v2.0_SSD_300x300"
solver_mode: GPU
device_id: 0
debug_info: false
train_state {
  level: 0
  stage: ""
}
snapshot_after_train: true
test_initialization: false
average_loss: 10
stepvalue: 180000
stepvalue: 200000
stepvalue: 220000
iter_size: 1
type: "SGD"
eval_type: "detection"
ap_version: "11point"
I0608 12:20:22.093451 30581 solver.cpp:96] Creating training net from train_net file: models/VGGNet/sharpen_tbs_v2.0/SSD_300x300/train.prototxt
I0608 12:20:22.095479 30581 net.cpp:58] Initializing net from parameters: 
name: "VGG_sharpen_tbs_v2.0_SSD_300x300_train"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "AnnotatedData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    mean_value: 104
    mean_value: 117
    mean_value: 123
    resize_param {
      prob: 1
      resize_mode: WARP
      height: 300
      width: 300
      interp_mode: LINEAR
      interp_mode: AREA
      interp_mode: NEAREST
      interp_mode: CUBIC
      interp_mode: LANCZOS4
    }
    emit_constraint {
      emit_type: CENTER
    }
    distort_param {
      brightness_prob: 0.5
      brightness_delta: 32
      contrast_prob: 0.5
      contrast_lower: 0.5
      contrast_upper: 1.5
      hue_prob: 0.5
      hue_delta: 18
      saturation_prob: 0.5
      saturation_lower: 0.5
      saturation_upper: 1.5
      random_order_prob: 0
    }
    expand_param {
      prob: 0.5
      max_expand_ratio: 4
    }
  }
  data_param {
    source: "examples/sharpen_tbs_v2.0/sharpen_tbs_v2.0_trainval_lmdb"
    batch_size: 32
    backend: LMDB
  }
  annotated_data_param {
    batch_sampler {
      max_sample: 1
      max_trials: 1
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.1
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.3
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.5
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.7
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.9
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        max_jaccard_overlap: 1
      }
      max_sample: 1
      max_trials: 50
    }
    label_map_file: "data/sharpen_tbs_v2.0/labelmap_voc.prototxt"
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "fc6"
  type: "Convolution"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    pad: 6
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 6
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "fc7"
  type: "Convolution"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "conv6_1"
  type: "Convolution"
  bottom: "fc7"
  top: "conv6_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6_1_relu"
  type: "ReLU"
  bottom: "conv6_1"
  top: "conv6_1"
}
layer {
  name: "conv6_2"
  type: "Convolution"
  bottom: "conv6_1"
  top: "conv6_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6_2_relu"
  type: "ReLU"
  bottom: "conv6_2"
  top: "conv6_2"
}
layer {
  name: "conv7_1"
  type: "Convolution"
  bottom: "conv6_2"
  top: "conv7_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv7_1_relu"
  type: "ReLU"
  bottom: "conv7_1"
  top: "conv7_1"
}
layer {
  name: "conv7_2"
  type: "Convolution"
  bottom: "conv7_1"
  top: "conv7_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv7_2_relu"
  type: "ReLU"
  bottom: "conv7_2"
  top: "conv7_2"
}
layer {
  name: "conv8_1"
  type: "Convolution"
  bottom: "conv7_2"
  top: "conv8_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv8_1_relu"
  type: "ReLU"
  bottom: "conv8_1"
  top: "conv8_1"
}
layer {
  name: "conv8_2"
  type: "Convolution"
  bottom: "conv8_1"
  top: "conv8_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv8_2_relu"
  type: "ReLU"
  bottom: "conv8_2"
  top: "conv8_2"
}
layer {
  name: "conv9_1"
  type: "Convolution"
  bottom: "conv8_2"
  top: "conv9_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv9_1_relu"
  type: "ReLU"
  bottom: "conv9_1"
  top: "conv9_1"
}
layer {
  name: "conv9_2"
  type: "Convolution"
  bottom: "conv9_1"
  top: "conv9_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv9_2_relu"
  type: "ReLU"
  bottom: "conv9_2"
  top: "conv9_2"
}
layer {
  name: "conv4_3_norm"
  type: "Normalize"
  bottom: "conv4_3"
  top: "conv4_3_norm"
  norm_param {
    across_spatial: false
    scale_filler {
      type: "constant"
      value: 20
    }
    channel_shared: false
  }
}
layer {
  name: "conv4_3_norm_mbox_loc"
  type: "Convolution"
  bottom: "conv4_3_norm"
  top: "conv4_3_norm_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_3_norm_mbox_loc_perm"
  type: "Permute"
  bottom: "conv4_3_norm_mbox_loc"
  top: "conv4_3_norm_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv4_3_norm_mbox_loc_perm"
  top: "conv4_3_norm_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_conf"
  type: "Convolution"
  bottom: "conv4_3_norm"
  top: "conv4_3_norm_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_3_norm_mbox_conf_perm"
  type: "Permute"
  bottom: "conv4_3_norm_mbox_conf"
  top: "conv4_3_norm_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv4_3_norm_mbox_conf_perm"
  top: "conv4_3_norm_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv4_3_norm"
  bottom: "data"
  top: "conv4_3_norm_mbox_priorbox"
  prior_box_param {
    min_size: 30
    max_size: 60
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 8
    offset: 0.5
  }
}
layer {
  name: "fc7_mbox_loc"
  type: "Convolution"
  bottom: "fc7"
  top: "fc7_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc7_mbox_loc_perm"
  type: "Permute"
  bottom: "fc7_mbox_loc"
  top: "fc7_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "fc7_mbox_loc_flat"
  type: "Flatten"
  bottom: "fc7_mbox_loc_perm"
  top: "fc7_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "fc7_mbox_conf"
  type: "Convolution"
  bottom: "fc7"
  top: "fc7_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 12
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc7_mbox_conf_perm"
  type: "Permute"
  bottom: "fc7_mbox_conf"
  top: "fc7_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "fc7_mbox_conf_flat"
  type: "Flatten"
  bottom: "fc7_mbox_conf_perm"
  top: "fc7_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "fc7_mbox_priorbox"
  type: "PriorBox"
  bottom: "fc7"
  bottom: "data"
  top: "fc7_mbox_priorbox"
  prior_box_param {
    min_size: 60
    max_size: 111
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 16
    offset: 0.5
  }
}
layer {
  name: "conv6_2_mbox_loc"
  type: "Convolution"
  bottom: "conv6_2"
  top: "conv6_2_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6_2_mbox_loc_perm"
  type: "Permute"
  bottom: "conv6_2_mbox_loc"
  top: "conv6_2_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv6_2_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv6_2_mbox_loc_perm"
  top: "conv6_2_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv6_2_mbox_conf"
  type: "Convolution"
  bottom: "conv6_2"
  top: "conv6_2_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 12
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6_2_mbox_conf_perm"
  type: "Permute"
  bottom: "conv6_2_mbox_conf"
  top: "conv6_2_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv6_2_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv6_2_mbox_conf_perm"
  top: "conv6_2_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv6_2_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv6_2"
  bottom: "data"
  top: "conv6_2_mbox_priorbox"
  prior_box_param {
    min_size: 111
    max_size: 162
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 32
    offset: 0.5
  }
}
layer {
  name: "conv7_2_mbox_loc"
  type: "Convolution"
  bottom: "conv7_2"
  top: "conv7_2_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv7_2_mbox_loc_perm"
  type: "Permute"
  bottom: "conv7_2_mbox_loc"
  top: "conv7_2_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv7_2_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv7_2_mbox_loc_perm"
  top: "conv7_2_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv7_2_mbox_conf"
  type: "Convolution"
  bottom: "conv7_2"
  top: "conv7_2_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 12
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv7_2_mbox_conf_perm"
  type: "Permute"
  bottom: "conv7_2_mbox_conf"
  top: "conv7_2_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv7_2_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv7_2_mbox_conf_perm"
  top: "conv7_2_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv7_2_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv7_2"
  bottom: "data"
  top: "conv7_2_mbox_priorbox"
  prior_box_param {
    min_size: 162
    max_size: 213
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 64
    offset: 0.5
  }
}
layer {
  name: "conv8_2_mbox_loc"
  type: "Convolution"
  bottom: "conv8_2"
  top: "conv8_2_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv8_2_mbox_loc_perm"
  type: "Permute"
  bottom: "conv8_2_mbox_loc"
  top: "conv8_2_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv8_2_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv8_2_mbox_loc_perm"
  top: "conv8_2_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv8_2_mbox_conf"
  type: "Convolution"
  bottom: "conv8_2"
  top: "conv8_2_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv8_2_mbox_conf_perm"
  type: "Permute"
  bottom: "conv8_2_mbox_conf"
  top: "conv8_2_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv8_2_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv8_2_mbox_conf_perm"
  top: "conv8_2_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv8_2_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv8_2"
  bottom: "data"
  top: "conv8_2_mbox_priorbox"
  prior_box_param {
    min_size: 213
    max_size: 264
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 100
    offset: 0.5
  }
}
layer {
  name: "conv9_2_mbox_loc"
  type: "Convolution"
  bottom: "conv9_2"
  top: "conv9_2_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv9_2_mbox_loc_perm"
  type: "Permute"
  bottom: "conv9_2_mbox_loc"
  top: "conv9_2_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv9_2_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv9_2_mbox_loc_perm"
  top: "conv9_2_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv9_2_mbox_conf"
  type: "Convolution"
  bottom: "conv9_2"
  top: "conv9_2_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv9_2_mbox_conf_perm"
  type: "Permute"
  bottom: "conv9_2_mbox_conf"
  top: "conv9_2_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv9_2_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv9_2_mbox_conf_perm"
  top: "conv9_2_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv9_2_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv9_2"
  bottom: "data"
  top: "conv9_2_mbox_priorbox"
  prior_box_param {
    min_size: 264
    max_size: 315
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 300
    offset: 0.5
  }
}
layer {
  name: "mbox_loc"
  type: "Concat"
  bottom: "conv4_3_norm_mbox_loc_flat"
  bottom: "fc7_mbox_loc_flat"
  bottom: "conv6_2_mbox_loc_flat"
  bottom: "conv7_2_mbox_loc_flat"
  bottom: "conv8_2_mbox_loc_flat"
  bottom: "conv9_2_mbox_loc_flat"
  top: "mbox_loc"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mbox_conf"
  type: "Concat"
  bottom: "conv4_3_norm_mbox_conf_flat"
  bottom: "fc7_mbox_conf_flat"
  bottom: "conv6_2_mbox_conf_flat"
  bottom: "conv7_2_mbox_conf_flat"
  bottom: "conv8_2_mbox_conf_flat"
  bottom: "conv9_2_mbox_conf_flat"
  top: "mbox_conf"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mbox_priorbox"
  type: "Concat"
  bottom: "conv4_3_norm_mbox_priorbox"
  bottom: "fc7_mbox_priorbox"
  bottom: "conv6_2_mbox_priorbox"
  bottom: "conv7_2_mbox_priorbox"
  bottom: "conv8_2_mbox_priorbox"
  bottom: "conv9_2_mbox_priorbox"
  top: "mbox_priorbox"
  concat_param {
    axis: 2
  }
}
layer {
  name: "mbox_loss"
  type: "MultiBoxLoss"
  bottom: "mbox_loc"
  bottom: "mbox_conf"
  bottom: "mbox_priorbox"
  bottom: "label"
  top: "mbox_loss"
  include {
    phase: TRAIN
  }
  propagate_down: true
  propagate_down: true
  propagate_down: false
  propagate_down: false
  loss_param {
    normalization: VALID
  }
  multibox_loss_param {
    loc_loss_type: SMOOTH_L1
    conf_loss_type: SOFTMAX
    loc_weight: 1
    num_classes: 2
    share_location: true
    match_type: PER_PREDICTION
    overlap_threshold: 0.5
    use_prior_for_matching: true
    background_label_id: 0
    use_difficult_gt: true
    neg_pos_ratio: 3
    neg_overlap: 0.5
    code_type: CENTER_SIZE
    ignore_cross_boundary_bbox: false
    mining_type: MAX_NEGATIVE
  }
}
I0608 12:20:22.096057 30581 layer_factory.hpp:77] Creating layer data
I0608 12:20:22.096238 30581 net.cpp:100] Creating Layer data
I0608 12:20:22.096257 30581 net.cpp:408] data -> data
I0608 12:20:22.096298 30581 net.cpp:408] data -> label
I0608 12:20:22.096858 30599 db_lmdb.cpp:35] Opened lmdb examples/sharpen_tbs_v2.0/sharpen_tbs_v2.0_trainval_lmdb
I0608 12:20:22.124303 30581 annotated_data_layer.cpp:62] output data size: 32,3,300,300
I0608 12:20:22.183904 30581 net.cpp:150] Setting up data
I0608 12:20:22.183928 30581 net.cpp:157] Top shape: 32 3 300 300 (8640000)
I0608 12:20:22.183948 30581 net.cpp:157] Top shape: 1 1 1 8 (8)
I0608 12:20:22.183962 30581 net.cpp:165] Memory required for data: 34560032
I0608 12:20:22.183971 30581 layer_factory.hpp:77] Creating layer data_data_0_split
I0608 12:20:22.184000 30581 net.cpp:100] Creating Layer data_data_0_split
I0608 12:20:22.184020 30581 net.cpp:434] data_data_0_split <- data
I0608 12:20:22.184029 30581 net.cpp:408] data_data_0_split -> data_data_0_split_0
I0608 12:20:22.184038 30581 net.cpp:408] data_data_0_split -> data_data_0_split_1
I0608 12:20:22.184046 30581 net.cpp:408] data_data_0_split -> data_data_0_split_2
I0608 12:20:22.184065 30581 net.cpp:408] data_data_0_split -> data_data_0_split_3
I0608 12:20:22.184072 30581 net.cpp:408] data_data_0_split -> data_data_0_split_4
I0608 12:20:22.184077 30581 net.cpp:408] data_data_0_split -> data_data_0_split_5
I0608 12:20:22.184084 30581 net.cpp:408] data_data_0_split -> data_data_0_split_6
I0608 12:20:22.184186 30581 net.cpp:150] Setting up data_data_0_split
I0608 12:20:22.184192 30581 net.cpp:157] Top shape: 32 3 300 300 (8640000)
I0608 12:20:22.184195 30581 net.cpp:157] Top shape: 32 3 300 300 (8640000)
I0608 12:20:22.184200 30581 net.cpp:157] Top shape: 32 3 300 300 (8640000)
I0608 12:20:22.184206 30581 net.cpp:157] Top shape: 32 3 300 300 (8640000)
I0608 12:20:22.184211 30581 net.cpp:157] Top shape: 32 3 300 300 (8640000)
I0608 12:20:22.184231 30581 net.cpp:157] Top shape: 32 3 300 300 (8640000)
I0608 12:20:22.184237 30581 net.cpp:157] Top shape: 32 3 300 300 (8640000)
I0608 12:20:22.184242 30581 net.cpp:165] Memory required for data: 276480032
I0608 12:20:22.184244 30581 layer_factory.hpp:77] Creating layer conv1_1
I0608 12:20:22.184273 30581 net.cpp:100] Creating Layer conv1_1
I0608 12:20:22.184276 30581 net.cpp:434] conv1_1 <- data_data_0_split_0
I0608 12:20:22.184283 30581 net.cpp:408] conv1_1 -> conv1_1
I0608 12:20:22.505749 30581 net.cpp:150] Setting up conv1_1
I0608 12:20:22.505769 30581 net.cpp:157] Top shape: 32 64 300 300 (184320000)
I0608 12:20:22.505772 30581 net.cpp:165] Memory required for data: 1013760032
I0608 12:20:22.505801 30581 layer_factory.hpp:77] Creating layer relu1_1
I0608 12:20:22.505810 30581 net.cpp:100] Creating Layer relu1_1
I0608 12:20:22.505815 30581 net.cpp:434] relu1_1 <- conv1_1
I0608 12:20:22.505818 30581 net.cpp:395] relu1_1 -> conv1_1 (in-place)
I0608 12:20:22.506006 30581 net.cpp:150] Setting up relu1_1
I0608 12:20:22.506014 30581 net.cpp:157] Top shape: 32 64 300 300 (184320000)
I0608 12:20:22.506016 30581 net.cpp:165] Memory required for data: 1751040032
I0608 12:20:22.506018 30581 layer_factory.hpp:77] Creating layer conv1_2
I0608 12:20:22.506029 30581 net.cpp:100] Creating Layer conv1_2
I0608 12:20:22.506047 30581 net.cpp:434] conv1_2 <- conv1_1
I0608 12:20:22.506052 30581 net.cpp:408] conv1_2 -> conv1_2
I0608 12:20:22.508458 30581 net.cpp:150] Setting up conv1_2
I0608 12:20:22.508471 30581 net.cpp:157] Top shape: 32 64 300 300 (184320000)
I0608 12:20:22.508473 30581 net.cpp:165] Memory required for data: 2488320032
I0608 12:20:22.508481 30581 layer_factory.hpp:77] Creating layer relu1_2
I0608 12:20:22.508486 30581 net.cpp:100] Creating Layer relu1_2
I0608 12:20:22.508488 30581 net.cpp:434] relu1_2 <- conv1_2
I0608 12:20:22.508492 30581 net.cpp:395] relu1_2 -> conv1_2 (in-place)
I0608 12:20:22.509039 30581 net.cpp:150] Setting up relu1_2
I0608 12:20:22.509048 30581 net.cpp:157] Top shape: 32 64 300 300 (184320000)
I0608 12:20:22.509052 30581 net.cpp:165] Memory required for data: 3225600032
I0608 12:20:22.509055 30581 layer_factory.hpp:77] Creating layer pool1
I0608 12:20:22.509063 30581 net.cpp:100] Creating Layer pool1
I0608 12:20:22.509068 30581 net.cpp:434] pool1 <- conv1_2
I0608 12:20:22.509073 30581 net.cpp:408] pool1 -> pool1
I0608 12:20:22.509115 30581 net.cpp:150] Setting up pool1
I0608 12:20:22.509121 30581 net.cpp:157] Top shape: 32 64 150 150 (46080000)
I0608 12:20:22.509124 30581 net.cpp:165] Memory required for data: 3409920032
I0608 12:20:22.509127 30581 layer_factory.hpp:77] Creating layer conv2_1
I0608 12:20:22.509136 30581 net.cpp:100] Creating Layer conv2_1
I0608 12:20:22.509150 30581 net.cpp:434] conv2_1 <- pool1
I0608 12:20:22.509156 30581 net.cpp:408] conv2_1 -> conv2_1
I0608 12:20:22.510777 30581 net.cpp:150] Setting up conv2_1
I0608 12:20:22.510787 30581 net.cpp:157] Top shape: 32 128 150 150 (92160000)
I0608 12:20:22.510790 30581 net.cpp:165] Memory required for data: 3778560032
I0608 12:20:22.510800 30581 layer_factory.hpp:77] Creating layer relu2_1
I0608 12:20:22.510807 30581 net.cpp:100] Creating Layer relu2_1
I0608 12:20:22.510812 30581 net.cpp:434] relu2_1 <- conv2_1
I0608 12:20:22.510817 30581 net.cpp:395] relu2_1 -> conv2_1 (in-place)
I0608 12:20:22.511354 30581 net.cpp:150] Setting up relu2_1
I0608 12:20:22.511363 30581 net.cpp:157] Top shape: 32 128 150 150 (92160000)
I0608 12:20:22.511366 30581 net.cpp:165] Memory required for data: 4147200032
I0608 12:20:22.511369 30581 layer_factory.hpp:77] Creating layer conv2_2
I0608 12:20:22.511379 30581 net.cpp:100] Creating Layer conv2_2
I0608 12:20:22.511384 30581 net.cpp:434] conv2_2 <- conv2_1
I0608 12:20:22.511389 30581 net.cpp:408] conv2_2 -> conv2_2
I0608 12:20:22.513272 30581 net.cpp:150] Setting up conv2_2
I0608 12:20:22.513280 30581 net.cpp:157] Top shape: 32 128 150 150 (92160000)
I0608 12:20:22.513284 30581 net.cpp:165] Memory required for data: 4515840032
I0608 12:20:22.513293 30581 layer_factory.hpp:77] Creating layer relu2_2
I0608 12:20:22.513298 30581 net.cpp:100] Creating Layer relu2_2
I0608 12:20:22.513312 30581 net.cpp:434] relu2_2 <- conv2_2
I0608 12:20:22.513320 30581 net.cpp:395] relu2_2 -> conv2_2 (in-place)
I0608 12:20:22.513447 30581 net.cpp:150] Setting up relu2_2
I0608 12:20:22.513453 30581 net.cpp:157] Top shape: 32 128 150 150 (92160000)
I0608 12:20:22.513456 30581 net.cpp:165] Memory required for data: 4884480032
I0608 12:20:22.513460 30581 layer_factory.hpp:77] Creating layer pool2
I0608 12:20:22.513468 30581 net.cpp:100] Creating Layer pool2
I0608 12:20:22.513471 30581 net.cpp:434] pool2 <- conv2_2
I0608 12:20:22.513476 30581 net.cpp:408] pool2 -> pool2
I0608 12:20:22.513509 30581 net.cpp:150] Setting up pool2
I0608 12:20:22.513515 30581 net.cpp:157] Top shape: 32 128 75 75 (23040000)
I0608 12:20:22.513519 30581 net.cpp:165] Memory required for data: 4976640032
I0608 12:20:22.513521 30581 layer_factory.hpp:77] Creating layer conv3_1
I0608 12:20:22.513530 30581 net.cpp:100] Creating Layer conv3_1
I0608 12:20:22.513532 30581 net.cpp:434] conv3_1 <- pool2
I0608 12:20:22.513536 30581 net.cpp:408] conv3_1 -> conv3_1
I0608 12:20:22.517175 30581 net.cpp:150] Setting up conv3_1
I0608 12:20:22.517191 30581 net.cpp:157] Top shape: 32 256 75 75 (46080000)
I0608 12:20:22.517194 30581 net.cpp:165] Memory required for data: 5160960032
I0608 12:20:22.517204 30581 layer_factory.hpp:77] Creating layer relu3_1
I0608 12:20:22.517211 30581 net.cpp:100] Creating Layer relu3_1
I0608 12:20:22.517215 30581 net.cpp:434] relu3_1 <- conv3_1
I0608 12:20:22.517220 30581 net.cpp:395] relu3_1 -> conv3_1 (in-place)
I0608 12:20:22.517361 30581 net.cpp:150] Setting up relu3_1
I0608 12:20:22.517369 30581 net.cpp:157] Top shape: 32 256 75 75 (46080000)
I0608 12:20:22.517372 30581 net.cpp:165] Memory required for data: 5345280032
I0608 12:20:22.517375 30581 layer_factory.hpp:77] Creating layer conv3_2
I0608 12:20:22.517382 30581 net.cpp:100] Creating Layer conv3_2
I0608 12:20:22.517385 30581 net.cpp:434] conv3_2 <- conv3_1
I0608 12:20:22.517390 30581 net.cpp:408] conv3_2 -> conv3_2
I0608 12:20:22.522009 30581 net.cpp:150] Setting up conv3_2
I0608 12:20:22.522027 30581 net.cpp:157] Top shape: 32 256 75 75 (46080000)
I0608 12:20:22.522030 30581 net.cpp:165] Memory required for data: 5529600032
I0608 12:20:22.522037 30581 layer_factory.hpp:77] Creating layer relu3_2
I0608 12:20:22.522044 30581 net.cpp:100] Creating Layer relu3_2
I0608 12:20:22.522049 30581 net.cpp:434] relu3_2 <- conv3_2
I0608 12:20:22.522053 30581 net.cpp:395] relu3_2 -> conv3_2 (in-place)
I0608 12:20:22.522192 30581 net.cpp:150] Setting up relu3_2
I0608 12:20:22.522198 30581 net.cpp:157] Top shape: 32 256 75 75 (46080000)
I0608 12:20:22.522200 30581 net.cpp:165] Memory required for data: 5713920032
I0608 12:20:22.522213 30581 layer_factory.hpp:77] Creating layer conv3_3
I0608 12:20:22.522225 30581 net.cpp:100] Creating Layer conv3_3
I0608 12:20:22.522229 30581 net.cpp:434] conv3_3 <- conv3_2
I0608 12:20:22.522233 30581 net.cpp:408] conv3_3 -> conv3_3
I0608 12:20:22.526746 30581 net.cpp:150] Setting up conv3_3
I0608 12:20:22.526762 30581 net.cpp:157] Top shape: 32 256 75 75 (46080000)
I0608 12:20:22.526763 30581 net.cpp:165] Memory required for data: 5898240032
I0608 12:20:22.526784 30581 layer_factory.hpp:77] Creating layer relu3_3
I0608 12:20:22.526790 30581 net.cpp:100] Creating Layer relu3_3
I0608 12:20:22.526794 30581 net.cpp:434] relu3_3 <- conv3_3
I0608 12:20:22.526798 30581 net.cpp:395] relu3_3 -> conv3_3 (in-place)
I0608 12:20:22.526934 30581 net.cpp:150] Setting up relu3_3
I0608 12:20:22.526954 30581 net.cpp:157] Top shape: 32 256 75 75 (46080000)
I0608 12:20:22.526957 30581 net.cpp:165] Memory required for data: 6082560032
I0608 12:20:22.526958 30581 layer_factory.hpp:77] Creating layer pool3
I0608 12:20:22.526978 30581 net.cpp:100] Creating Layer pool3
I0608 12:20:22.526981 30581 net.cpp:434] pool3 <- conv3_3
I0608 12:20:22.526985 30581 net.cpp:408] pool3 -> pool3
I0608 12:20:22.527030 30581 net.cpp:150] Setting up pool3
I0608 12:20:22.527035 30581 net.cpp:157] Top shape: 32 256 38 38 (11829248)
I0608 12:20:22.527037 30581 net.cpp:165] Memory required for data: 6129877024
I0608 12:20:22.527040 30581 layer_factory.hpp:77] Creating layer conv4_1
I0608 12:20:22.527047 30581 net.cpp:100] Creating Layer conv4_1
I0608 12:20:22.527065 30581 net.cpp:434] conv4_1 <- pool3
I0608 12:20:22.527070 30581 net.cpp:408] conv4_1 -> conv4_1
I0608 12:20:22.535387 30581 net.cpp:150] Setting up conv4_1
I0608 12:20:22.535404 30581 net.cpp:157] Top shape: 32 512 38 38 (23658496)
I0608 12:20:22.535408 30581 net.cpp:165] Memory required for data: 6224511008
I0608 12:20:22.535415 30581 layer_factory.hpp:77] Creating layer relu4_1
I0608 12:20:22.535424 30581 net.cpp:100] Creating Layer relu4_1
I0608 12:20:22.535428 30581 net.cpp:434] relu4_1 <- conv4_1
I0608 12:20:22.535447 30581 net.cpp:395] relu4_1 -> conv4_1 (in-place)
I0608 12:20:22.536290 30581 net.cpp:150] Setting up relu4_1
I0608 12:20:22.536303 30581 net.cpp:157] Top shape: 32 512 38 38 (23658496)
I0608 12:20:22.536309 30581 net.cpp:165] Memory required for data: 6319144992
I0608 12:20:22.536312 30581 layer_factory.hpp:77] Creating layer conv4_2
I0608 12:20:22.536324 30581 net.cpp:100] Creating Layer conv4_2
I0608 12:20:22.536330 30581 net.cpp:434] conv4_2 <- conv4_1
I0608 12:20:22.536337 30581 net.cpp:408] conv4_2 -> conv4_2
I0608 12:20:22.548243 30581 net.cpp:150] Setting up conv4_2
I0608 12:20:22.548261 30581 net.cpp:157] Top shape: 32 512 38 38 (23658496)
I0608 12:20:22.548266 30581 net.cpp:165] Memory required for data: 6413778976
I0608 12:20:22.548280 30581 layer_factory.hpp:77] Creating layer relu4_2
I0608 12:20:22.548302 30581 net.cpp:100] Creating Layer relu4_2
I0608 12:20:22.548310 30581 net.cpp:434] relu4_2 <- conv4_2
I0608 12:20:22.548317 30581 net.cpp:395] relu4_2 -> conv4_2 (in-place)
I0608 12:20:22.549165 30581 net.cpp:150] Setting up relu4_2
I0608 12:20:22.549175 30581 net.cpp:157] Top shape: 32 512 38 38 (23658496)
I0608 12:20:22.549180 30581 net.cpp:165] Memory required for data: 6508412960
I0608 12:20:22.549183 30581 layer_factory.hpp:77] Creating layer conv4_3
I0608 12:20:22.549195 30581 net.cpp:100] Creating Layer conv4_3
I0608 12:20:22.549198 30581 net.cpp:434] conv4_3 <- conv4_2
I0608 12:20:22.549206 30581 net.cpp:408] conv4_3 -> conv4_3
I0608 12:20:22.562216 30581 net.cpp:150] Setting up conv4_3
I0608 12:20:22.562233 30581 net.cpp:157] Top shape: 32 512 38 38 (23658496)
I0608 12:20:22.562237 30581 net.cpp:165] Memory required for data: 6603046944
I0608 12:20:22.562245 30581 layer_factory.hpp:77] Creating layer relu4_3
I0608 12:20:22.562269 30581 net.cpp:100] Creating Layer relu4_3
I0608 12:20:22.562275 30581 net.cpp:434] relu4_3 <- conv4_3
I0608 12:20:22.562296 30581 net.cpp:395] relu4_3 -> conv4_3 (in-place)
I0608 12:20:22.562476 30581 net.cpp:150] Setting up relu4_3
I0608 12:20:22.562485 30581 net.cpp:157] Top shape: 32 512 38 38 (23658496)
I0608 12:20:22.562489 30581 net.cpp:165] Memory required for data: 6697680928
I0608 12:20:22.562492 30581 layer_factory.hpp:77] Creating layer conv4_3_relu4_3_0_split
I0608 12:20:22.562499 30581 net.cpp:100] Creating Layer conv4_3_relu4_3_0_split
I0608 12:20:22.562503 30581 net.cpp:434] conv4_3_relu4_3_0_split <- conv4_3
I0608 12:20:22.562525 30581 net.cpp:408] conv4_3_relu4_3_0_split -> conv4_3_relu4_3_0_split_0
I0608 12:20:22.562533 30581 net.cpp:408] conv4_3_relu4_3_0_split -> conv4_3_relu4_3_0_split_1
I0608 12:20:22.562579 30581 net.cpp:150] Setting up conv4_3_relu4_3_0_split
I0608 12:20:22.562587 30581 net.cpp:157] Top shape: 32 512 38 38 (23658496)
I0608 12:20:22.562592 30581 net.cpp:157] Top shape: 32 512 38 38 (23658496)
I0608 12:20:22.562595 30581 net.cpp:165] Memory required for data: 6886948896
I0608 12:20:22.562599 30581 layer_factory.hpp:77] Creating layer pool4
I0608 12:20:22.562623 30581 net.cpp:100] Creating Layer pool4
I0608 12:20:22.562626 30581 net.cpp:434] pool4 <- conv4_3_relu4_3_0_split_0
I0608 12:20:22.562633 30581 net.cpp:408] pool4 -> pool4
I0608 12:20:22.562676 30581 net.cpp:150] Setting up pool4
I0608 12:20:22.562683 30581 net.cpp:157] Top shape: 32 512 19 19 (5914624)
I0608 12:20:22.562686 30581 net.cpp:165] Memory required for data: 6910607392
I0608 12:20:22.562690 30581 layer_factory.hpp:77] Creating layer conv5_1
I0608 12:20:22.562700 30581 net.cpp:100] Creating Layer conv5_1
I0608 12:20:22.562705 30581 net.cpp:434] conv5_1 <- pool4
I0608 12:20:22.562711 30581 net.cpp:408] conv5_1 -> conv5_1
I0608 12:20:22.575742 30581 net.cpp:150] Setting up conv5_1
I0608 12:20:22.575762 30581 net.cpp:157] Top shape: 32 512 19 19 (5914624)
I0608 12:20:22.575767 30581 net.cpp:165] Memory required for data: 6934265888
I0608 12:20:22.575790 30581 layer_factory.hpp:77] Creating layer relu5_1
I0608 12:20:22.575799 30581 net.cpp:100] Creating Layer relu5_1
I0608 12:20:22.575805 30581 net.cpp:434] relu5_1 <- conv5_1
I0608 12:20:22.575827 30581 net.cpp:395] relu5_1 -> conv5_1 (in-place)
I0608 12:20:22.576025 30581 net.cpp:150] Setting up relu5_1
I0608 12:20:22.576031 30581 net.cpp:157] Top shape: 32 512 19 19 (5914624)
I0608 12:20:22.576035 30581 net.cpp:165] Memory required for data: 6957924384
I0608 12:20:22.576056 30581 layer_factory.hpp:77] Creating layer conv5_2
I0608 12:20:22.576066 30581 net.cpp:100] Creating Layer conv5_2
I0608 12:20:22.576071 30581 net.cpp:434] conv5_2 <- conv5_1
I0608 12:20:22.576089 30581 net.cpp:408] conv5_2 -> conv5_2
I0608 12:20:22.588614 30581 net.cpp:150] Setting up conv5_2
I0608 12:20:22.588634 30581 net.cpp:157] Top shape: 32 512 19 19 (5914624)
I0608 12:20:22.588637 30581 net.cpp:165] Memory required for data: 6981582880
I0608 12:20:22.588645 30581 layer_factory.hpp:77] Creating layer relu5_2
I0608 12:20:22.588654 30581 net.cpp:100] Creating Layer relu5_2
I0608 12:20:22.588675 30581 net.cpp:434] relu5_2 <- conv5_2
I0608 12:20:22.588696 30581 net.cpp:395] relu5_2 -> conv5_2 (in-place)
I0608 12:20:22.588853 30581 net.cpp:150] Setting up relu5_2
I0608 12:20:22.588862 30581 net.cpp:157] Top shape: 32 512 19 19 (5914624)
I0608 12:20:22.588866 30581 net.cpp:165] Memory required for data: 7005241376
I0608 12:20:22.588871 30581 layer_factory.hpp:77] Creating layer conv5_3
I0608 12:20:22.588897 30581 net.cpp:100] Creating Layer conv5_3
I0608 12:20:22.588903 30581 net.cpp:434] conv5_3 <- conv5_2
I0608 12:20:22.588923 30581 net.cpp:408] conv5_3 -> conv5_3
I0608 12:20:22.602154 30581 net.cpp:150] Setting up conv5_3
I0608 12:20:22.602171 30581 net.cpp:157] Top shape: 32 512 19 19 (5914624)
I0608 12:20:22.602175 30581 net.cpp:165] Memory required for data: 7028899872
I0608 12:20:22.602183 30581 layer_factory.hpp:77] Creating layer relu5_3
I0608 12:20:22.602211 30581 net.cpp:100] Creating Layer relu5_3
I0608 12:20:22.602231 30581 net.cpp:434] relu5_3 <- conv5_3
I0608 12:20:22.602252 30581 net.cpp:395] relu5_3 -> conv5_3 (in-place)
I0608 12:20:22.602427 30581 net.cpp:150] Setting up relu5_3
I0608 12:20:22.602434 30581 net.cpp:157] Top shape: 32 512 19 19 (5914624)
I0608 12:20:22.602437 30581 net.cpp:165] Memory required for data: 7052558368
I0608 12:20:22.602442 30581 layer_factory.hpp:77] Creating layer pool5
I0608 12:20:22.602465 30581 net.cpp:100] Creating Layer pool5
I0608 12:20:22.602470 30581 net.cpp:434] pool5 <- conv5_3
I0608 12:20:22.602476 30581 net.cpp:408] pool5 -> pool5
I0608 12:20:22.602514 30581 net.cpp:150] Setting up pool5
I0608 12:20:22.602520 30581 net.cpp:157] Top shape: 32 512 19 19 (5914624)
I0608 12:20:22.602524 30581 net.cpp:165] Memory required for data: 7076216864
I0608 12:20:22.602527 30581 layer_factory.hpp:77] Creating layer fc6
I0608 12:20:22.602550 30581 net.cpp:100] Creating Layer fc6
I0608 12:20:22.602555 30581 net.cpp:434] fc6 <- pool5
I0608 12:20:22.602561 30581 net.cpp:408] fc6 -> fc6
I0608 12:20:22.624781 30581 net.cpp:150] Setting up fc6
I0608 12:20:22.624800 30581 net.cpp:157] Top shape: 32 1024 19 19 (11829248)
I0608 12:20:22.624804 30581 net.cpp:165] Memory required for data: 7123533856
I0608 12:20:22.624811 30581 layer_factory.hpp:77] Creating layer relu6
I0608 12:20:22.624819 30581 net.cpp:100] Creating Layer relu6
I0608 12:20:22.624840 30581 net.cpp:434] relu6 <- fc6
I0608 12:20:22.624862 30581 net.cpp:395] relu6 -> fc6 (in-place)
I0608 12:20:22.625916 30581 net.cpp:150] Setting up relu6
I0608 12:20:22.625941 30581 net.cpp:157] Top shape: 32 1024 19 19 (11829248)
I0608 12:20:22.625946 30581 net.cpp:165] Memory required for data: 7170850848
I0608 12:20:22.625962 30581 layer_factory.hpp:77] Creating layer fc7
I0608 12:20:22.625988 30581 net.cpp:100] Creating Layer fc7
I0608 12:20:22.625993 30581 net.cpp:434] fc7 <- fc6
I0608 12:20:22.626013 30581 net.cpp:408] fc7 -> fc7
I0608 12:20:22.633251 30581 net.cpp:150] Setting up fc7
I0608 12:20:22.633267 30581 net.cpp:157] Top shape: 32 1024 19 19 (11829248)
I0608 12:20:22.633270 30581 net.cpp:165] Memory required for data: 7218167840
I0608 12:20:22.633293 30581 layer_factory.hpp:77] Creating layer relu7
I0608 12:20:22.633304 30581 net.cpp:100] Creating Layer relu7
I0608 12:20:22.633311 30581 net.cpp:434] relu7 <- fc7
I0608 12:20:22.633332 30581 net.cpp:395] relu7 -> fc7 (in-place)
I0608 12:20:22.633507 30581 net.cpp:150] Setting up relu7
I0608 12:20:22.633517 30581 net.cpp:157] Top shape: 32 1024 19 19 (11829248)
I0608 12:20:22.633522 30581 net.cpp:165] Memory required for data: 7265484832
I0608 12:20:22.633539 30581 layer_factory.hpp:77] Creating layer fc7_relu7_0_split
I0608 12:20:22.633548 30581 net.cpp:100] Creating Layer fc7_relu7_0_split
I0608 12:20:22.633550 30581 net.cpp:434] fc7_relu7_0_split <- fc7
I0608 12:20:22.633558 30581 net.cpp:408] fc7_relu7_0_split -> fc7_relu7_0_split_0
I0608 12:20:22.633582 30581 net.cpp:408] fc7_relu7_0_split -> fc7_relu7_0_split_1
I0608 12:20:22.633622 30581 net.cpp:408] fc7_relu7_0_split -> fc7_relu7_0_split_2
I0608 12:20:22.633643 30581 net.cpp:408] fc7_relu7_0_split -> fc7_relu7_0_split_3
I0608 12:20:22.633764 30581 net.cpp:150] Setting up fc7_relu7_0_split
I0608 12:20:22.633772 30581 net.cpp:157] Top shape: 32 1024 19 19 (11829248)
I0608 12:20:22.633793 30581 net.cpp:157] Top shape: 32 1024 19 19 (11829248)
I0608 12:20:22.633800 30581 net.cpp:157] Top shape: 32 1024 19 19 (11829248)
I0608 12:20:22.633805 30581 net.cpp:157] Top shape: 32 1024 19 19 (11829248)
I0608 12:20:22.633821 30581 net.cpp:165] Memory required for data: 7454752800
I0608 12:20:22.633826 30581 layer_factory.hpp:77] Creating layer conv6_1
I0608 12:20:22.633852 30581 net.cpp:100] Creating Layer conv6_1
I0608 12:20:22.633857 30581 net.cpp:434] conv6_1 <- fc7_relu7_0_split_0
I0608 12:20:22.633877 30581 net.cpp:408] conv6_1 -> conv6_1
I0608 12:20:22.637450 30581 net.cpp:150] Setting up conv6_1
I0608 12:20:22.637464 30581 net.cpp:157] Top shape: 32 256 19 19 (2957312)
I0608 12:20:22.637466 30581 net.cpp:165] Memory required for data: 7466582048
I0608 12:20:22.637471 30581 layer_factory.hpp:77] Creating layer conv6_1_relu
I0608 12:20:22.637477 30581 net.cpp:100] Creating Layer conv6_1_relu
I0608 12:20:22.637509 30581 net.cpp:434] conv6_1_relu <- conv6_1
I0608 12:20:22.637517 30581 net.cpp:395] conv6_1_relu -> conv6_1 (in-place)
I0608 12:20:22.637701 30581 net.cpp:150] Setting up conv6_1_relu
I0608 12:20:22.637712 30581 net.cpp:157] Top shape: 32 256 19 19 (2957312)
I0608 12:20:22.637717 30581 net.cpp:165] Memory required for data: 7478411296
I0608 12:20:22.637722 30581 layer_factory.hpp:77] Creating layer conv6_2
I0608 12:20:22.637747 30581 net.cpp:100] Creating Layer conv6_2
I0608 12:20:22.637753 30581 net.cpp:434] conv6_2 <- conv6_1
I0608 12:20:22.637761 30581 net.cpp:408] conv6_2 -> conv6_2
I0608 12:20:22.646607 30581 net.cpp:150] Setting up conv6_2
I0608 12:20:22.646625 30581 net.cpp:157] Top shape: 32 512 10 10 (1638400)
I0608 12:20:22.646627 30581 net.cpp:165] Memory required for data: 7484964896
I0608 12:20:22.646654 30581 layer_factory.hpp:77] Creating layer conv6_2_relu
I0608 12:20:22.646661 30581 net.cpp:100] Creating Layer conv6_2_relu
I0608 12:20:22.646666 30581 net.cpp:434] conv6_2_relu <- conv6_2
I0608 12:20:22.646669 30581 net.cpp:395] conv6_2_relu -> conv6_2 (in-place)
I0608 12:20:22.646868 30581 net.cpp:150] Setting up conv6_2_relu
I0608 12:20:22.646878 30581 net.cpp:157] Top shape: 32 512 10 10 (1638400)
I0608 12:20:22.646883 30581 net.cpp:165] Memory required for data: 7491518496
I0608 12:20:22.646885 30581 layer_factory.hpp:77] Creating layer conv6_2_conv6_2_relu_0_split
I0608 12:20:22.646906 30581 net.cpp:100] Creating Layer conv6_2_conv6_2_relu_0_split
I0608 12:20:22.646910 30581 net.cpp:434] conv6_2_conv6_2_relu_0_split <- conv6_2
I0608 12:20:22.646929 30581 net.cpp:408] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_0
I0608 12:20:22.646937 30581 net.cpp:408] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_1
I0608 12:20:22.646961 30581 net.cpp:408] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_2
I0608 12:20:22.646966 30581 net.cpp:408] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_3
I0608 12:20:22.647044 30581 net.cpp:150] Setting up conv6_2_conv6_2_relu_0_split
I0608 12:20:22.647053 30581 net.cpp:157] Top shape: 32 512 10 10 (1638400)
I0608 12:20:22.647058 30581 net.cpp:157] Top shape: 32 512 10 10 (1638400)
I0608 12:20:22.647061 30581 net.cpp:157] Top shape: 32 512 10 10 (1638400)
I0608 12:20:22.647078 30581 net.cpp:157] Top shape: 32 512 10 10 (1638400)
I0608 12:20:22.647080 30581 net.cpp:165] Memory required for data: 7517732896
I0608 12:20:22.647099 30581 layer_factory.hpp:77] Creating layer conv7_1
I0608 12:20:22.647109 30581 net.cpp:100] Creating Layer conv7_1
I0608 12:20:22.647114 30581 net.cpp:434] conv7_1 <- conv6_2_conv6_2_relu_0_split_0
I0608 12:20:22.647120 30581 net.cpp:408] conv7_1 -> conv7_1
I0608 12:20:22.649055 30581 net.cpp:150] Setting up conv7_1
I0608 12:20:22.649065 30581 net.cpp:157] Top shape: 32 128 10 10 (409600)
I0608 12:20:22.649067 30581 net.cpp:165] Memory required for data: 7519371296
I0608 12:20:22.649075 30581 layer_factory.hpp:77] Creating layer conv7_1_relu
I0608 12:20:22.649097 30581 net.cpp:100] Creating Layer conv7_1_relu
I0608 12:20:22.649103 30581 net.cpp:434] conv7_1_relu <- conv7_1
I0608 12:20:22.649111 30581 net.cpp:395] conv7_1_relu -> conv7_1 (in-place)
I0608 12:20:22.649278 30581 net.cpp:150] Setting up conv7_1_relu
I0608 12:20:22.649291 30581 net.cpp:157] Top shape: 32 128 10 10 (409600)
I0608 12:20:22.649296 30581 net.cpp:165] Memory required for data: 7521009696
I0608 12:20:22.649307 30581 layer_factory.hpp:77] Creating layer conv7_2
I0608 12:20:22.649317 30581 net.cpp:100] Creating Layer conv7_2
I0608 12:20:22.649338 30581 net.cpp:434] conv7_2 <- conv7_1
I0608 12:20:22.649346 30581 net.cpp:408] conv7_2 -> conv7_2
I0608 12:20:22.652519 30581 net.cpp:150] Setting up conv7_2
I0608 12:20:22.652534 30581 net.cpp:157] Top shape: 32 256 5 5 (204800)
I0608 12:20:22.652537 30581 net.cpp:165] Memory required for data: 7521828896
I0608 12:20:22.652559 30581 layer_factory.hpp:77] Creating layer conv7_2_relu
I0608 12:20:22.652565 30581 net.cpp:100] Creating Layer conv7_2_relu
I0608 12:20:22.652581 30581 net.cpp:434] conv7_2_relu <- conv7_2
I0608 12:20:22.652587 30581 net.cpp:395] conv7_2_relu -> conv7_2 (in-place)
I0608 12:20:22.652753 30581 net.cpp:150] Setting up conv7_2_relu
I0608 12:20:22.652762 30581 net.cpp:157] Top shape: 32 256 5 5 (204800)
I0608 12:20:22.652765 30581 net.cpp:165] Memory required for data: 7522648096
I0608 12:20:22.652768 30581 layer_factory.hpp:77] Creating layer conv7_2_conv7_2_relu_0_split
I0608 12:20:22.652776 30581 net.cpp:100] Creating Layer conv7_2_conv7_2_relu_0_split
I0608 12:20:22.652779 30581 net.cpp:434] conv7_2_conv7_2_relu_0_split <- conv7_2
I0608 12:20:22.652784 30581 net.cpp:408] conv7_2_conv7_2_relu_0_split -> conv7_2_conv7_2_relu_0_split_0
I0608 12:20:22.652791 30581 net.cpp:408] conv7_2_conv7_2_relu_0_split -> conv7_2_conv7_2_relu_0_split_1
I0608 12:20:22.652799 30581 net.cpp:408] conv7_2_conv7_2_relu_0_split -> conv7_2_conv7_2_relu_0_split_2
I0608 12:20:22.652806 30581 net.cpp:408] conv7_2_conv7_2_relu_0_split -> conv7_2_conv7_2_relu_0_split_3
I0608 12:20:22.652861 30581 net.cpp:150] Setting up conv7_2_conv7_2_relu_0_split
I0608 12:20:22.652866 30581 net.cpp:157] Top shape: 32 256 5 5 (204800)
I0608 12:20:22.652870 30581 net.cpp:157] Top shape: 32 256 5 5 (204800)
I0608 12:20:22.652873 30581 net.cpp:157] Top shape: 32 256 5 5 (204800)
I0608 12:20:22.652875 30581 net.cpp:157] Top shape: 32 256 5 5 (204800)
I0608 12:20:22.652878 30581 net.cpp:165] Memory required for data: 7525924896
I0608 12:20:22.652879 30581 layer_factory.hpp:77] Creating layer conv8_1
I0608 12:20:22.652886 30581 net.cpp:100] Creating Layer conv8_1
I0608 12:20:22.652889 30581 net.cpp:434] conv8_1 <- conv7_2_conv7_2_relu_0_split_0
I0608 12:20:22.652894 30581 net.cpp:408] conv8_1 -> conv8_1
I0608 12:20:22.654355 30581 net.cpp:150] Setting up conv8_1
I0608 12:20:22.654367 30581 net.cpp:157] Top shape: 32 128 5 5 (102400)
I0608 12:20:22.654371 30581 net.cpp:165] Memory required for data: 7526334496
I0608 12:20:22.654377 30581 layer_factory.hpp:77] Creating layer conv8_1_relu
I0608 12:20:22.654384 30581 net.cpp:100] Creating Layer conv8_1_relu
I0608 12:20:22.654389 30581 net.cpp:434] conv8_1_relu <- conv8_1
I0608 12:20:22.654395 30581 net.cpp:395] conv8_1_relu -> conv8_1 (in-place)
I0608 12:20:22.655169 30581 net.cpp:150] Setting up conv8_1_relu
I0608 12:20:22.655179 30581 net.cpp:157] Top shape: 32 128 5 5 (102400)
I0608 12:20:22.655182 30581 net.cpp:165] Memory required for data: 7526744096
I0608 12:20:22.655186 30581 layer_factory.hpp:77] Creating layer conv8_2
I0608 12:20:22.655194 30581 net.cpp:100] Creating Layer conv8_2
I0608 12:20:22.655200 30581 net.cpp:434] conv8_2 <- conv8_1
I0608 12:20:22.655205 30581 net.cpp:408] conv8_2 -> conv8_2
I0608 12:20:22.658242 30581 net.cpp:150] Setting up conv8_2
I0608 12:20:22.658253 30581 net.cpp:157] Top shape: 32 256 3 3 (73728)
I0608 12:20:22.658257 30581 net.cpp:165] Memory required for data: 7527039008
I0608 12:20:22.658262 30581 layer_factory.hpp:77] Creating layer conv8_2_relu
I0608 12:20:22.658267 30581 net.cpp:100] Creating Layer conv8_2_relu
I0608 12:20:22.658270 30581 net.cpp:434] conv8_2_relu <- conv8_2
I0608 12:20:22.658274 30581 net.cpp:395] conv8_2_relu -> conv8_2 (in-place)
I0608 12:20:22.658386 30581 net.cpp:150] Setting up conv8_2_relu
I0608 12:20:22.658393 30581 net.cpp:157] Top shape: 32 256 3 3 (73728)
I0608 12:20:22.658396 30581 net.cpp:165] Memory required for data: 7527333920
I0608 12:20:22.658398 30581 layer_factory.hpp:77] Creating layer conv8_2_conv8_2_relu_0_split
I0608 12:20:22.658401 30581 net.cpp:100] Creating Layer conv8_2_conv8_2_relu_0_split
I0608 12:20:22.658404 30581 net.cpp:434] conv8_2_conv8_2_relu_0_split <- conv8_2
I0608 12:20:22.658408 30581 net.cpp:408] conv8_2_conv8_2_relu_0_split -> conv8_2_conv8_2_relu_0_split_0
I0608 12:20:22.658416 30581 net.cpp:408] conv8_2_conv8_2_relu_0_split -> conv8_2_conv8_2_relu_0_split_1
I0608 12:20:22.658421 30581 net.cpp:408] conv8_2_conv8_2_relu_0_split -> conv8_2_conv8_2_relu_0_split_2
I0608 12:20:22.658426 30581 net.cpp:408] conv8_2_conv8_2_relu_0_split -> conv8_2_conv8_2_relu_0_split_3
I0608 12:20:22.658495 30581 net.cpp:150] Setting up conv8_2_conv8_2_relu_0_split
I0608 12:20:22.658501 30581 net.cpp:157] Top shape: 32 256 3 3 (73728)
I0608 12:20:22.658504 30581 net.cpp:157] Top shape: 32 256 3 3 (73728)
I0608 12:20:22.658507 30581 net.cpp:157] Top shape: 32 256 3 3 (73728)
I0608 12:20:22.658509 30581 net.cpp:157] Top shape: 32 256 3 3 (73728)
I0608 12:20:22.658512 30581 net.cpp:165] Memory required for data: 7528513568
I0608 12:20:22.658514 30581 layer_factory.hpp:77] Creating layer conv9_1
I0608 12:20:22.658520 30581 net.cpp:100] Creating Layer conv9_1
I0608 12:20:22.658524 30581 net.cpp:434] conv9_1 <- conv8_2_conv8_2_relu_0_split_0
I0608 12:20:22.658527 30581 net.cpp:408] conv9_1 -> conv9_1
I0608 12:20:22.659729 30581 net.cpp:150] Setting up conv9_1
I0608 12:20:22.659739 30581 net.cpp:157] Top shape: 32 128 3 3 (36864)
I0608 12:20:22.659740 30581 net.cpp:165] Memory required for data: 7528661024
I0608 12:20:22.659746 30581 layer_factory.hpp:77] Creating layer conv9_1_relu
I0608 12:20:22.659751 30581 net.cpp:100] Creating Layer conv9_1_relu
I0608 12:20:22.659754 30581 net.cpp:434] conv9_1_relu <- conv9_1
I0608 12:20:22.659757 30581 net.cpp:395] conv9_1_relu -> conv9_1 (in-place)
I0608 12:20:22.659870 30581 net.cpp:150] Setting up conv9_1_relu
I0608 12:20:22.659876 30581 net.cpp:157] Top shape: 32 128 3 3 (36864)
I0608 12:20:22.659878 30581 net.cpp:165] Memory required for data: 7528808480
I0608 12:20:22.659880 30581 layer_factory.hpp:77] Creating layer conv9_2
I0608 12:20:22.659888 30581 net.cpp:100] Creating Layer conv9_2
I0608 12:20:22.659890 30581 net.cpp:434] conv9_2 <- conv9_1
I0608 12:20:22.659894 30581 net.cpp:408] conv9_2 -> conv9_2
I0608 12:20:22.663317 30581 net.cpp:150] Setting up conv9_2
I0608 12:20:22.663337 30581 net.cpp:157] Top shape: 32 256 1 1 (8192)
I0608 12:20:22.663341 30581 net.cpp:165] Memory required for data: 7528841248
I0608 12:20:22.663348 30581 layer_factory.hpp:77] Creating layer conv9_2_relu
I0608 12:20:22.663355 30581 net.cpp:100] Creating Layer conv9_2_relu
I0608 12:20:22.663360 30581 net.cpp:434] conv9_2_relu <- conv9_2
I0608 12:20:22.663367 30581 net.cpp:395] conv9_2_relu -> conv9_2 (in-place)
I0608 12:20:22.663485 30581 net.cpp:150] Setting up conv9_2_relu
I0608 12:20:22.663491 30581 net.cpp:157] Top shape: 32 256 1 1 (8192)
I0608 12:20:22.663494 30581 net.cpp:165] Memory required for data: 7528874016
I0608 12:20:22.663496 30581 layer_factory.hpp:77] Creating layer conv9_2_conv9_2_relu_0_split
I0608 12:20:22.663501 30581 net.cpp:100] Creating Layer conv9_2_conv9_2_relu_0_split
I0608 12:20:22.663503 30581 net.cpp:434] conv9_2_conv9_2_relu_0_split <- conv9_2
I0608 12:20:22.663508 30581 net.cpp:408] conv9_2_conv9_2_relu_0_split -> conv9_2_conv9_2_relu_0_split_0
I0608 12:20:22.663514 30581 net.cpp:408] conv9_2_conv9_2_relu_0_split -> conv9_2_conv9_2_relu_0_split_1
I0608 12:20:22.663522 30581 net.cpp:408] conv9_2_conv9_2_relu_0_split -> conv9_2_conv9_2_relu_0_split_2
I0608 12:20:22.663571 30581 net.cpp:150] Setting up conv9_2_conv9_2_relu_0_split
I0608 12:20:22.663594 30581 net.cpp:157] Top shape: 32 256 1 1 (8192)
I0608 12:20:22.663609 30581 net.cpp:157] Top shape: 32 256 1 1 (8192)
I0608 12:20:22.663614 30581 net.cpp:157] Top shape: 32 256 1 1 (8192)
I0608 12:20:22.663617 30581 net.cpp:165] Memory required for data: 7528972320
I0608 12:20:22.663621 30581 layer_factory.hpp:77] Creating layer conv4_3_norm
I0608 12:20:22.663630 30581 net.cpp:100] Creating Layer conv4_3_norm
I0608 12:20:22.663635 30581 net.cpp:434] conv4_3_norm <- conv4_3_relu4_3_0_split_1
I0608 12:20:22.663641 30581 net.cpp:408] conv4_3_norm -> conv4_3_norm
I0608 12:20:22.663777 30581 net.cpp:150] Setting up conv4_3_norm
I0608 12:20:22.663784 30581 net.cpp:157] Top shape: 32 512 38 38 (23658496)
I0608 12:20:22.663787 30581 net.cpp:165] Memory required for data: 7623606304
I0608 12:20:22.663792 30581 layer_factory.hpp:77] Creating layer conv4_3_norm_conv4_3_norm_0_split
I0608 12:20:22.663800 30581 net.cpp:100] Creating Layer conv4_3_norm_conv4_3_norm_0_split
I0608 12:20:22.663818 30581 net.cpp:434] conv4_3_norm_conv4_3_norm_0_split <- conv4_3_norm
I0608 12:20:22.663835 30581 net.cpp:408] conv4_3_norm_conv4_3_norm_0_split -> conv4_3_norm_conv4_3_norm_0_split_0
I0608 12:20:22.663856 30581 net.cpp:408] conv4_3_norm_conv4_3_norm_0_split -> conv4_3_norm_conv4_3_norm_0_split_1
I0608 12:20:22.663878 30581 net.cpp:408] conv4_3_norm_conv4_3_norm_0_split -> conv4_3_norm_conv4_3_norm_0_split_2
I0608 12:20:22.663929 30581 net.cpp:150] Setting up conv4_3_norm_conv4_3_norm_0_split
I0608 12:20:22.663935 30581 net.cpp:157] Top shape: 32 512 38 38 (23658496)
I0608 12:20:22.663940 30581 net.cpp:157] Top shape: 32 512 38 38 (23658496)
I0608 12:20:22.663946 30581 net.cpp:157] Top shape: 32 512 38 38 (23658496)
I0608 12:20:22.663950 30581 net.cpp:165] Memory required for data: 7907508256
I0608 12:20:22.663954 30581 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_loc
I0608 12:20:22.663964 30581 net.cpp:100] Creating Layer conv4_3_norm_mbox_loc
I0608 12:20:22.663969 30581 net.cpp:434] conv4_3_norm_mbox_loc <- conv4_3_norm_conv4_3_norm_0_split_0
I0608 12:20:22.663975 30581 net.cpp:408] conv4_3_norm_mbox_loc -> conv4_3_norm_mbox_loc
I0608 12:20:22.665802 30581 net.cpp:150] Setting up conv4_3_norm_mbox_loc
I0608 12:20:22.665812 30581 net.cpp:157] Top shape: 32 16 38 38 (739328)
I0608 12:20:22.665817 30581 net.cpp:165] Memory required for data: 7910465568
I0608 12:20:22.665824 30581 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_loc_perm
I0608 12:20:22.665832 30581 net.cpp:100] Creating Layer conv4_3_norm_mbox_loc_perm
I0608 12:20:22.665838 30581 net.cpp:434] conv4_3_norm_mbox_loc_perm <- conv4_3_norm_mbox_loc
I0608 12:20:22.665845 30581 net.cpp:408] conv4_3_norm_mbox_loc_perm -> conv4_3_norm_mbox_loc_perm
I0608 12:20:22.665931 30581 net.cpp:150] Setting up conv4_3_norm_mbox_loc_perm
I0608 12:20:22.665938 30581 net.cpp:157] Top shape: 32 38 38 16 (739328)
I0608 12:20:22.665942 30581 net.cpp:165] Memory required for data: 7913422880
I0608 12:20:22.665946 30581 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_loc_flat
I0608 12:20:22.665952 30581 net.cpp:100] Creating Layer conv4_3_norm_mbox_loc_flat
I0608 12:20:22.665957 30581 net.cpp:434] conv4_3_norm_mbox_loc_flat <- conv4_3_norm_mbox_loc_perm
I0608 12:20:22.665963 30581 net.cpp:408] conv4_3_norm_mbox_loc_flat -> conv4_3_norm_mbox_loc_flat
I0608 12:20:22.665994 30581 net.cpp:150] Setting up conv4_3_norm_mbox_loc_flat
I0608 12:20:22.666002 30581 net.cpp:157] Top shape: 32 23104 (739328)
I0608 12:20:22.666004 30581 net.cpp:165] Memory required for data: 7916380192
I0608 12:20:22.666008 30581 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_conf
I0608 12:20:22.666023 30581 net.cpp:100] Creating Layer conv4_3_norm_mbox_conf
I0608 12:20:22.666028 30581 net.cpp:434] conv4_3_norm_mbox_conf <- conv4_3_norm_conv4_3_norm_0_split_1
I0608 12:20:22.666034 30581 net.cpp:408] conv4_3_norm_mbox_conf -> conv4_3_norm_mbox_conf
I0608 12:20:22.667577 30581 net.cpp:150] Setting up conv4_3_norm_mbox_conf
I0608 12:20:22.667587 30581 net.cpp:157] Top shape: 32 8 38 38 (369664)
I0608 12:20:22.667593 30581 net.cpp:165] Memory required for data: 7917858848
I0608 12:20:22.667601 30581 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_conf_perm
I0608 12:20:22.667608 30581 net.cpp:100] Creating Layer conv4_3_norm_mbox_conf_perm
I0608 12:20:22.667614 30581 net.cpp:434] conv4_3_norm_mbox_conf_perm <- conv4_3_norm_mbox_conf
I0608 12:20:22.667623 30581 net.cpp:408] conv4_3_norm_mbox_conf_perm -> conv4_3_norm_mbox_conf_perm
I0608 12:20:22.667701 30581 net.cpp:150] Setting up conv4_3_norm_mbox_conf_perm
I0608 12:20:22.667706 30581 net.cpp:157] Top shape: 32 38 38 8 (369664)
I0608 12:20:22.667711 30581 net.cpp:165] Memory required for data: 7919337504
I0608 12:20:22.667716 30581 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_conf_flat
I0608 12:20:22.667722 30581 net.cpp:100] Creating Layer conv4_3_norm_mbox_conf_flat
I0608 12:20:22.667727 30581 net.cpp:434] conv4_3_norm_mbox_conf_flat <- conv4_3_norm_mbox_conf_perm
I0608 12:20:22.667733 30581 net.cpp:408] conv4_3_norm_mbox_conf_flat -> conv4_3_norm_mbox_conf_flat
I0608 12:20:22.667764 30581 net.cpp:150] Setting up conv4_3_norm_mbox_conf_flat
I0608 12:20:22.667770 30581 net.cpp:157] Top shape: 32 11552 (369664)
I0608 12:20:22.667774 30581 net.cpp:165] Memory required for data: 7920816160
I0608 12:20:22.667778 30581 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_priorbox
I0608 12:20:22.667786 30581 net.cpp:100] Creating Layer conv4_3_norm_mbox_priorbox
I0608 12:20:22.667791 30581 net.cpp:434] conv4_3_norm_mbox_priorbox <- conv4_3_norm_conv4_3_norm_0_split_2
I0608 12:20:22.667798 30581 net.cpp:434] conv4_3_norm_mbox_priorbox <- data_data_0_split_1
I0608 12:20:22.667804 30581 net.cpp:408] conv4_3_norm_mbox_priorbox -> conv4_3_norm_mbox_priorbox
I0608 12:20:22.667831 30581 net.cpp:150] Setting up conv4_3_norm_mbox_priorbox
I0608 12:20:22.667839 30581 net.cpp:157] Top shape: 1 2 23104 (46208)
I0608 12:20:22.667842 30581 net.cpp:165] Memory required for data: 7921000992
I0608 12:20:22.667845 30581 layer_factory.hpp:77] Creating layer fc7_mbox_loc
I0608 12:20:22.667855 30581 net.cpp:100] Creating Layer fc7_mbox_loc
I0608 12:20:22.667860 30581 net.cpp:434] fc7_mbox_loc <- fc7_relu7_0_split_1
I0608 12:20:22.667866 30581 net.cpp:408] fc7_mbox_loc -> fc7_mbox_loc
I0608 12:20:22.670148 30581 net.cpp:150] Setting up fc7_mbox_loc
I0608 12:20:22.670161 30581 net.cpp:157] Top shape: 32 24 19 19 (277248)
I0608 12:20:22.670164 30581 net.cpp:165] Memory required for data: 7922109984
I0608 12:20:22.670172 30581 layer_factory.hpp:77] Creating layer fc7_mbox_loc_perm
I0608 12:20:22.670181 30581 net.cpp:100] Creating Layer fc7_mbox_loc_perm
I0608 12:20:22.670187 30581 net.cpp:434] fc7_mbox_loc_perm <- fc7_mbox_loc
I0608 12:20:22.670193 30581 net.cpp:408] fc7_mbox_loc_perm -> fc7_mbox_loc_perm
I0608 12:20:22.670272 30581 net.cpp:150] Setting up fc7_mbox_loc_perm
I0608 12:20:22.670279 30581 net.cpp:157] Top shape: 32 19 19 24 (277248)
I0608 12:20:22.670284 30581 net.cpp:165] Memory required for data: 7923218976
I0608 12:20:22.670287 30581 layer_factory.hpp:77] Creating layer fc7_mbox_loc_flat
I0608 12:20:22.670294 30581 net.cpp:100] Creating Layer fc7_mbox_loc_flat
I0608 12:20:22.670298 30581 net.cpp:434] fc7_mbox_loc_flat <- fc7_mbox_loc_perm
I0608 12:20:22.670306 30581 net.cpp:408] fc7_mbox_loc_flat -> fc7_mbox_loc_flat
I0608 12:20:22.670328 30581 net.cpp:150] Setting up fc7_mbox_loc_flat
I0608 12:20:22.670334 30581 net.cpp:157] Top shape: 32 8664 (277248)
I0608 12:20:22.670337 30581 net.cpp:165] Memory required for data: 7924327968
I0608 12:20:22.670342 30581 layer_factory.hpp:77] Creating layer fc7_mbox_conf
I0608 12:20:22.670351 30581 net.cpp:100] Creating Layer fc7_mbox_conf
I0608 12:20:22.670356 30581 net.cpp:434] fc7_mbox_conf <- fc7_relu7_0_split_2
I0608 12:20:22.670361 30581 net.cpp:408] fc7_mbox_conf -> fc7_mbox_conf
I0608 12:20:22.672266 30581 net.cpp:150] Setting up fc7_mbox_conf
I0608 12:20:22.672276 30581 net.cpp:157] Top shape: 32 12 19 19 (138624)
I0608 12:20:22.672281 30581 net.cpp:165] Memory required for data: 7924882464
I0608 12:20:22.672287 30581 layer_factory.hpp:77] Creating layer fc7_mbox_conf_perm
I0608 12:20:22.672296 30581 net.cpp:100] Creating Layer fc7_mbox_conf_perm
I0608 12:20:22.672302 30581 net.cpp:434] fc7_mbox_conf_perm <- fc7_mbox_conf
I0608 12:20:22.672308 30581 net.cpp:408] fc7_mbox_conf_perm -> fc7_mbox_conf_perm
I0608 12:20:22.672389 30581 net.cpp:150] Setting up fc7_mbox_conf_perm
I0608 12:20:22.672395 30581 net.cpp:157] Top shape: 32 19 19 12 (138624)
I0608 12:20:22.672400 30581 net.cpp:165] Memory required for data: 7925436960
I0608 12:20:22.672404 30581 layer_factory.hpp:77] Creating layer fc7_mbox_conf_flat
I0608 12:20:22.672410 30581 net.cpp:100] Creating Layer fc7_mbox_conf_flat
I0608 12:20:22.672415 30581 net.cpp:434] fc7_mbox_conf_flat <- fc7_mbox_conf_perm
I0608 12:20:22.672421 30581 net.cpp:408] fc7_mbox_conf_flat -> fc7_mbox_conf_flat
I0608 12:20:22.672443 30581 net.cpp:150] Setting up fc7_mbox_conf_flat
I0608 12:20:22.672449 30581 net.cpp:157] Top shape: 32 4332 (138624)
I0608 12:20:22.672453 30581 net.cpp:165] Memory required for data: 7925991456
I0608 12:20:22.672466 30581 layer_factory.hpp:77] Creating layer fc7_mbox_priorbox
I0608 12:20:22.672474 30581 net.cpp:100] Creating Layer fc7_mbox_priorbox
I0608 12:20:22.672478 30581 net.cpp:434] fc7_mbox_priorbox <- fc7_relu7_0_split_3
I0608 12:20:22.672484 30581 net.cpp:434] fc7_mbox_priorbox <- data_data_0_split_2
I0608 12:20:22.672492 30581 net.cpp:408] fc7_mbox_priorbox -> fc7_mbox_priorbox
I0608 12:20:22.672518 30581 net.cpp:150] Setting up fc7_mbox_priorbox
I0608 12:20:22.672524 30581 net.cpp:157] Top shape: 1 2 8664 (17328)
I0608 12:20:22.672528 30581 net.cpp:165] Memory required for data: 7926060768
I0608 12:20:22.672533 30581 layer_factory.hpp:77] Creating layer conv6_2_mbox_loc
I0608 12:20:22.672541 30581 net.cpp:100] Creating Layer conv6_2_mbox_loc
I0608 12:20:22.672546 30581 net.cpp:434] conv6_2_mbox_loc <- conv6_2_conv6_2_relu_0_split_1
I0608 12:20:22.672554 30581 net.cpp:408] conv6_2_mbox_loc -> conv6_2_mbox_loc
I0608 12:20:22.674383 30581 net.cpp:150] Setting up conv6_2_mbox_loc
I0608 12:20:22.674393 30581 net.cpp:157] Top shape: 32 24 10 10 (76800)
I0608 12:20:22.674397 30581 net.cpp:165] Memory required for data: 7926367968
I0608 12:20:22.674405 30581 layer_factory.hpp:77] Creating layer conv6_2_mbox_loc_perm
I0608 12:20:22.674413 30581 net.cpp:100] Creating Layer conv6_2_mbox_loc_perm
I0608 12:20:22.674418 30581 net.cpp:434] conv6_2_mbox_loc_perm <- conv6_2_mbox_loc
I0608 12:20:22.674425 30581 net.cpp:408] conv6_2_mbox_loc_perm -> conv6_2_mbox_loc_perm
I0608 12:20:22.674507 30581 net.cpp:150] Setting up conv6_2_mbox_loc_perm
I0608 12:20:22.674515 30581 net.cpp:157] Top shape: 32 10 10 24 (76800)
I0608 12:20:22.674518 30581 net.cpp:165] Memory required for data: 7926675168
I0608 12:20:22.674521 30581 layer_factory.hpp:77] Creating layer conv6_2_mbox_loc_flat
I0608 12:20:22.674527 30581 net.cpp:100] Creating Layer conv6_2_mbox_loc_flat
I0608 12:20:22.674532 30581 net.cpp:434] conv6_2_mbox_loc_flat <- conv6_2_mbox_loc_perm
I0608 12:20:22.674538 30581 net.cpp:408] conv6_2_mbox_loc_flat -> conv6_2_mbox_loc_flat
I0608 12:20:22.674559 30581 net.cpp:150] Setting up conv6_2_mbox_loc_flat
I0608 12:20:22.674566 30581 net.cpp:157] Top shape: 32 2400 (76800)
I0608 12:20:22.674569 30581 net.cpp:165] Memory required for data: 7926982368
I0608 12:20:22.674573 30581 layer_factory.hpp:77] Creating layer conv6_2_mbox_conf
I0608 12:20:22.674582 30581 net.cpp:100] Creating Layer conv6_2_mbox_conf
I0608 12:20:22.674587 30581 net.cpp:434] conv6_2_mbox_conf <- conv6_2_conv6_2_relu_0_split_2
I0608 12:20:22.674593 30581 net.cpp:408] conv6_2_mbox_conf -> conv6_2_mbox_conf
I0608 12:20:22.676219 30581 net.cpp:150] Setting up conv6_2_mbox_conf
I0608 12:20:22.676231 30581 net.cpp:157] Top shape: 32 12 10 10 (38400)
I0608 12:20:22.676235 30581 net.cpp:165] Memory required for data: 7927135968
I0608 12:20:22.676244 30581 layer_factory.hpp:77] Creating layer conv6_2_mbox_conf_perm
I0608 12:20:22.676251 30581 net.cpp:100] Creating Layer conv6_2_mbox_conf_perm
I0608 12:20:22.676257 30581 net.cpp:434] conv6_2_mbox_conf_perm <- conv6_2_mbox_conf
I0608 12:20:22.676265 30581 net.cpp:408] conv6_2_mbox_conf_perm -> conv6_2_mbox_conf_perm
I0608 12:20:22.676348 30581 net.cpp:150] Setting up conv6_2_mbox_conf_perm
I0608 12:20:22.676355 30581 net.cpp:157] Top shape: 32 10 10 12 (38400)
I0608 12:20:22.676359 30581 net.cpp:165] Memory required for data: 7927289568
I0608 12:20:22.676362 30581 layer_factory.hpp:77] Creating layer conv6_2_mbox_conf_flat
I0608 12:20:22.676368 30581 net.cpp:100] Creating Layer conv6_2_mbox_conf_flat
I0608 12:20:22.676373 30581 net.cpp:434] conv6_2_mbox_conf_flat <- conv6_2_mbox_conf_perm
I0608 12:20:22.676379 30581 net.cpp:408] conv6_2_mbox_conf_flat -> conv6_2_mbox_conf_flat
I0608 12:20:22.676400 30581 net.cpp:150] Setting up conv6_2_mbox_conf_flat
I0608 12:20:22.676407 30581 net.cpp:157] Top shape: 32 1200 (38400)
I0608 12:20:22.676410 30581 net.cpp:165] Memory required for data: 7927443168
I0608 12:20:22.676414 30581 layer_factory.hpp:77] Creating layer conv6_2_mbox_priorbox
I0608 12:20:22.676430 30581 net.cpp:100] Creating Layer conv6_2_mbox_priorbox
I0608 12:20:22.676437 30581 net.cpp:434] conv6_2_mbox_priorbox <- conv6_2_conv6_2_relu_0_split_3
I0608 12:20:22.676443 30581 net.cpp:434] conv6_2_mbox_priorbox <- data_data_0_split_3
I0608 12:20:22.676450 30581 net.cpp:408] conv6_2_mbox_priorbox -> conv6_2_mbox_priorbox
I0608 12:20:22.676476 30581 net.cpp:150] Setting up conv6_2_mbox_priorbox
I0608 12:20:22.676483 30581 net.cpp:157] Top shape: 1 2 2400 (4800)
I0608 12:20:22.676487 30581 net.cpp:165] Memory required for data: 7927462368
I0608 12:20:22.676491 30581 layer_factory.hpp:77] Creating layer conv7_2_mbox_loc
I0608 12:20:22.676499 30581 net.cpp:100] Creating Layer conv7_2_mbox_loc
I0608 12:20:22.676504 30581 net.cpp:434] conv7_2_mbox_loc <- conv7_2_conv7_2_relu_0_split_1
I0608 12:20:22.676512 30581 net.cpp:408] conv7_2_mbox_loc -> conv7_2_mbox_loc
I0608 12:20:22.677755 30581 net.cpp:150] Setting up conv7_2_mbox_loc
I0608 12:20:22.677767 30581 net.cpp:157] Top shape: 32 24 5 5 (19200)
I0608 12:20:22.677772 30581 net.cpp:165] Memory required for data: 7927539168
I0608 12:20:22.677778 30581 layer_factory.hpp:77] Creating layer conv7_2_mbox_loc_perm
I0608 12:20:22.677786 30581 net.cpp:100] Creating Layer conv7_2_mbox_loc_perm
I0608 12:20:22.677791 30581 net.cpp:434] conv7_2_mbox_loc_perm <- conv7_2_mbox_loc
I0608 12:20:22.677799 30581 net.cpp:408] conv7_2_mbox_loc_perm -> conv7_2_mbox_loc_perm
I0608 12:20:22.677880 30581 net.cpp:150] Setting up conv7_2_mbox_loc_perm
I0608 12:20:22.677886 30581 net.cpp:157] Top shape: 32 5 5 24 (19200)
I0608 12:20:22.677891 30581 net.cpp:165] Memory required for data: 7927615968
I0608 12:20:22.677896 30581 layer_factory.hpp:77] Creating layer conv7_2_mbox_loc_flat
I0608 12:20:22.677901 30581 net.cpp:100] Creating Layer conv7_2_mbox_loc_flat
I0608 12:20:22.677906 30581 net.cpp:434] conv7_2_mbox_loc_flat <- conv7_2_mbox_loc_perm
I0608 12:20:22.677911 30581 net.cpp:408] conv7_2_mbox_loc_flat -> conv7_2_mbox_loc_flat
I0608 12:20:22.677933 30581 net.cpp:150] Setting up conv7_2_mbox_loc_flat
I0608 12:20:22.677939 30581 net.cpp:157] Top shape: 32 600 (19200)
I0608 12:20:22.677943 30581 net.cpp:165] Memory required for data: 7927692768
I0608 12:20:22.677947 30581 layer_factory.hpp:77] Creating layer conv7_2_mbox_conf
I0608 12:20:22.677955 30581 net.cpp:100] Creating Layer conv7_2_mbox_conf
I0608 12:20:22.677959 30581 net.cpp:434] conv7_2_mbox_conf <- conv7_2_conv7_2_relu_0_split_2
I0608 12:20:22.677966 30581 net.cpp:408] conv7_2_mbox_conf -> conv7_2_mbox_conf
I0608 12:20:22.679457 30581 net.cpp:150] Setting up conv7_2_mbox_conf
I0608 12:20:22.679468 30581 net.cpp:157] Top shape: 32 12 5 5 (9600)
I0608 12:20:22.679472 30581 net.cpp:165] Memory required for data: 7927731168
I0608 12:20:22.679479 30581 layer_factory.hpp:77] Creating layer conv7_2_mbox_conf_perm
I0608 12:20:22.679487 30581 net.cpp:100] Creating Layer conv7_2_mbox_conf_perm
I0608 12:20:22.679492 30581 net.cpp:434] conv7_2_mbox_conf_perm <- conv7_2_mbox_conf
I0608 12:20:22.679499 30581 net.cpp:408] conv7_2_mbox_conf_perm -> conv7_2_mbox_conf_perm
I0608 12:20:22.679579 30581 net.cpp:150] Setting up conv7_2_mbox_conf_perm
I0608 12:20:22.679586 30581 net.cpp:157] Top shape: 32 5 5 12 (9600)
I0608 12:20:22.679591 30581 net.cpp:165] Memory required for data: 7927769568
I0608 12:20:22.679595 30581 layer_factory.hpp:77] Creating layer conv7_2_mbox_conf_flat
I0608 12:20:22.679600 30581 net.cpp:100] Creating Layer conv7_2_mbox_conf_flat
I0608 12:20:22.679605 30581 net.cpp:434] conv7_2_mbox_conf_flat <- conv7_2_mbox_conf_perm
I0608 12:20:22.679612 30581 net.cpp:408] conv7_2_mbox_conf_flat -> conv7_2_mbox_conf_flat
I0608 12:20:22.679636 30581 net.cpp:150] Setting up conv7_2_mbox_conf_flat
I0608 12:20:22.679641 30581 net.cpp:157] Top shape: 32 300 (9600)
I0608 12:20:22.679644 30581 net.cpp:165] Memory required for data: 7927807968
I0608 12:20:22.679649 30581 layer_factory.hpp:77] Creating layer conv7_2_mbox_priorbox
I0608 12:20:22.679656 30581 net.cpp:100] Creating Layer conv7_2_mbox_priorbox
I0608 12:20:22.679659 30581 net.cpp:434] conv7_2_mbox_priorbox <- conv7_2_conv7_2_relu_0_split_3
I0608 12:20:22.679674 30581 net.cpp:434] conv7_2_mbox_priorbox <- data_data_0_split_4
I0608 12:20:22.679682 30581 net.cpp:408] conv7_2_mbox_priorbox -> conv7_2_mbox_priorbox
I0608 12:20:22.679707 30581 net.cpp:150] Setting up conv7_2_mbox_priorbox
I0608 12:20:22.679713 30581 net.cpp:157] Top shape: 1 2 600 (1200)
I0608 12:20:22.679716 30581 net.cpp:165] Memory required for data: 7927812768
I0608 12:20:22.679720 30581 layer_factory.hpp:77] Creating layer conv8_2_mbox_loc
I0608 12:20:22.679729 30581 net.cpp:100] Creating Layer conv8_2_mbox_loc
I0608 12:20:22.679733 30581 net.cpp:434] conv8_2_mbox_loc <- conv8_2_conv8_2_relu_0_split_1
I0608 12:20:22.679740 30581 net.cpp:408] conv8_2_mbox_loc -> conv8_2_mbox_loc
I0608 12:20:22.681315 30581 net.cpp:150] Setting up conv8_2_mbox_loc
I0608 12:20:22.681326 30581 net.cpp:157] Top shape: 32 16 3 3 (4608)
I0608 12:20:22.681330 30581 net.cpp:165] Memory required for data: 7927831200
I0608 12:20:22.681344 30581 layer_factory.hpp:77] Creating layer conv8_2_mbox_loc_perm
I0608 12:20:22.681351 30581 net.cpp:100] Creating Layer conv8_2_mbox_loc_perm
I0608 12:20:22.681357 30581 net.cpp:434] conv8_2_mbox_loc_perm <- conv8_2_mbox_loc
I0608 12:20:22.681365 30581 net.cpp:408] conv8_2_mbox_loc_perm -> conv8_2_mbox_loc_perm
I0608 12:20:22.681445 30581 net.cpp:150] Setting up conv8_2_mbox_loc_perm
I0608 12:20:22.681453 30581 net.cpp:157] Top shape: 32 3 3 16 (4608)
I0608 12:20:22.681457 30581 net.cpp:165] Memory required for data: 7927849632
I0608 12:20:22.681460 30581 layer_factory.hpp:77] Creating layer conv8_2_mbox_loc_flat
I0608 12:20:22.681465 30581 net.cpp:100] Creating Layer conv8_2_mbox_loc_flat
I0608 12:20:22.681471 30581 net.cpp:434] conv8_2_mbox_loc_flat <- conv8_2_mbox_loc_perm
I0608 12:20:22.681476 30581 net.cpp:408] conv8_2_mbox_loc_flat -> conv8_2_mbox_loc_flat
I0608 12:20:22.681499 30581 net.cpp:150] Setting up conv8_2_mbox_loc_flat
I0608 12:20:22.681504 30581 net.cpp:157] Top shape: 32 144 (4608)
I0608 12:20:22.681507 30581 net.cpp:165] Memory required for data: 7927868064
I0608 12:20:22.681511 30581 layer_factory.hpp:77] Creating layer conv8_2_mbox_conf
I0608 12:20:22.681519 30581 net.cpp:100] Creating Layer conv8_2_mbox_conf
I0608 12:20:22.681524 30581 net.cpp:434] conv8_2_mbox_conf <- conv8_2_conv8_2_relu_0_split_2
I0608 12:20:22.681531 30581 net.cpp:408] conv8_2_mbox_conf -> conv8_2_mbox_conf
I0608 12:20:22.682987 30581 net.cpp:150] Setting up conv8_2_mbox_conf
I0608 12:20:22.682996 30581 net.cpp:157] Top shape: 32 8 3 3 (2304)
I0608 12:20:22.683001 30581 net.cpp:165] Memory required for data: 7927877280
I0608 12:20:22.683008 30581 layer_factory.hpp:77] Creating layer conv8_2_mbox_conf_perm
I0608 12:20:22.683017 30581 net.cpp:100] Creating Layer conv8_2_mbox_conf_perm
I0608 12:20:22.683022 30581 net.cpp:434] conv8_2_mbox_conf_perm <- conv8_2_mbox_conf
I0608 12:20:22.683028 30581 net.cpp:408] conv8_2_mbox_conf_perm -> conv8_2_mbox_conf_perm
I0608 12:20:22.683109 30581 net.cpp:150] Setting up conv8_2_mbox_conf_perm
I0608 12:20:22.683115 30581 net.cpp:157] Top shape: 32 3 3 8 (2304)
I0608 12:20:22.683120 30581 net.cpp:165] Memory required for data: 7927886496
I0608 12:20:22.683122 30581 layer_factory.hpp:77] Creating layer conv8_2_mbox_conf_flat
I0608 12:20:22.683128 30581 net.cpp:100] Creating Layer conv8_2_mbox_conf_flat
I0608 12:20:22.683133 30581 net.cpp:434] conv8_2_mbox_conf_flat <- conv8_2_mbox_conf_perm
I0608 12:20:22.683140 30581 net.cpp:408] conv8_2_mbox_conf_flat -> conv8_2_mbox_conf_flat
I0608 12:20:22.683161 30581 net.cpp:150] Setting up conv8_2_mbox_conf_flat
I0608 12:20:22.683167 30581 net.cpp:157] Top shape: 32 72 (2304)
I0608 12:20:22.683171 30581 net.cpp:165] Memory required for data: 7927895712
I0608 12:20:22.683174 30581 layer_factory.hpp:77] Creating layer conv8_2_mbox_priorbox
I0608 12:20:22.683179 30581 net.cpp:100] Creating Layer conv8_2_mbox_priorbox
I0608 12:20:22.683185 30581 net.cpp:434] conv8_2_mbox_priorbox <- conv8_2_conv8_2_relu_0_split_3
I0608 12:20:22.683190 30581 net.cpp:434] conv8_2_mbox_priorbox <- data_data_0_split_5
I0608 12:20:22.683207 30581 net.cpp:408] conv8_2_mbox_priorbox -> conv8_2_mbox_priorbox
I0608 12:20:22.683230 30581 net.cpp:150] Setting up conv8_2_mbox_priorbox
I0608 12:20:22.683238 30581 net.cpp:157] Top shape: 1 2 144 (288)
I0608 12:20:22.683240 30581 net.cpp:165] Memory required for data: 7927896864
I0608 12:20:22.683243 30581 layer_factory.hpp:77] Creating layer conv9_2_mbox_loc
I0608 12:20:22.683253 30581 net.cpp:100] Creating Layer conv9_2_mbox_loc
I0608 12:20:22.683257 30581 net.cpp:434] conv9_2_mbox_loc <- conv9_2_conv9_2_relu_0_split_0
I0608 12:20:22.683264 30581 net.cpp:408] conv9_2_mbox_loc -> conv9_2_mbox_loc
I0608 12:20:22.684803 30581 net.cpp:150] Setting up conv9_2_mbox_loc
I0608 12:20:22.684811 30581 net.cpp:157] Top shape: 32 16 1 1 (512)
I0608 12:20:22.684815 30581 net.cpp:165] Memory required for data: 7927898912
I0608 12:20:22.684824 30581 layer_factory.hpp:77] Creating layer conv9_2_mbox_loc_perm
I0608 12:20:22.684830 30581 net.cpp:100] Creating Layer conv9_2_mbox_loc_perm
I0608 12:20:22.684836 30581 net.cpp:434] conv9_2_mbox_loc_perm <- conv9_2_mbox_loc
I0608 12:20:22.684842 30581 net.cpp:408] conv9_2_mbox_loc_perm -> conv9_2_mbox_loc_perm
I0608 12:20:22.684923 30581 net.cpp:150] Setting up conv9_2_mbox_loc_perm
I0608 12:20:22.684929 30581 net.cpp:157] Top shape: 32 1 1 16 (512)
I0608 12:20:22.684933 30581 net.cpp:165] Memory required for data: 7927900960
I0608 12:20:22.684937 30581 layer_factory.hpp:77] Creating layer conv9_2_mbox_loc_flat
I0608 12:20:22.684942 30581 net.cpp:100] Creating Layer conv9_2_mbox_loc_flat
I0608 12:20:22.684947 30581 net.cpp:434] conv9_2_mbox_loc_flat <- conv9_2_mbox_loc_perm
I0608 12:20:22.684953 30581 net.cpp:408] conv9_2_mbox_loc_flat -> conv9_2_mbox_loc_flat
I0608 12:20:22.684974 30581 net.cpp:150] Setting up conv9_2_mbox_loc_flat
I0608 12:20:22.684981 30581 net.cpp:157] Top shape: 32 16 (512)
I0608 12:20:22.684984 30581 net.cpp:165] Memory required for data: 7927903008
I0608 12:20:22.684988 30581 layer_factory.hpp:77] Creating layer conv9_2_mbox_conf
I0608 12:20:22.684996 30581 net.cpp:100] Creating Layer conv9_2_mbox_conf
I0608 12:20:22.685001 30581 net.cpp:434] conv9_2_mbox_conf <- conv9_2_conv9_2_relu_0_split_1
I0608 12:20:22.685008 30581 net.cpp:408] conv9_2_mbox_conf -> conv9_2_mbox_conf
I0608 12:20:22.686892 30581 net.cpp:150] Setting up conv9_2_mbox_conf
I0608 12:20:22.686902 30581 net.cpp:157] Top shape: 32 8 1 1 (256)
I0608 12:20:22.686905 30581 net.cpp:165] Memory required for data: 7927904032
I0608 12:20:22.686913 30581 layer_factory.hpp:77] Creating layer conv9_2_mbox_conf_perm
I0608 12:20:22.686920 30581 net.cpp:100] Creating Layer conv9_2_mbox_conf_perm
I0608 12:20:22.686925 30581 net.cpp:434] conv9_2_mbox_conf_perm <- conv9_2_mbox_conf
I0608 12:20:22.686933 30581 net.cpp:408] conv9_2_mbox_conf_perm -> conv9_2_mbox_conf_perm
I0608 12:20:22.687013 30581 net.cpp:150] Setting up conv9_2_mbox_conf_perm
I0608 12:20:22.687021 30581 net.cpp:157] Top shape: 32 1 1 8 (256)
I0608 12:20:22.687023 30581 net.cpp:165] Memory required for data: 7927905056
I0608 12:20:22.687028 30581 layer_factory.hpp:77] Creating layer conv9_2_mbox_conf_flat
I0608 12:20:22.687033 30581 net.cpp:100] Creating Layer conv9_2_mbox_conf_flat
I0608 12:20:22.687038 30581 net.cpp:434] conv9_2_mbox_conf_flat <- conv9_2_mbox_conf_perm
I0608 12:20:22.687044 30581 net.cpp:408] conv9_2_mbox_conf_flat -> conv9_2_mbox_conf_flat
I0608 12:20:22.687067 30581 net.cpp:150] Setting up conv9_2_mbox_conf_flat
I0608 12:20:22.687072 30581 net.cpp:157] Top shape: 32 8 (256)
I0608 12:20:22.687075 30581 net.cpp:165] Memory required for data: 7927906080
I0608 12:20:22.687078 30581 layer_factory.hpp:77] Creating layer conv9_2_mbox_priorbox
I0608 12:20:22.687085 30581 net.cpp:100] Creating Layer conv9_2_mbox_priorbox
I0608 12:20:22.687089 30581 net.cpp:434] conv9_2_mbox_priorbox <- conv9_2_conv9_2_relu_0_split_2
I0608 12:20:22.687095 30581 net.cpp:434] conv9_2_mbox_priorbox <- data_data_0_split_6
I0608 12:20:22.687103 30581 net.cpp:408] conv9_2_mbox_priorbox -> conv9_2_mbox_priorbox
I0608 12:20:22.687135 30581 net.cpp:150] Setting up conv9_2_mbox_priorbox
I0608 12:20:22.687142 30581 net.cpp:157] Top shape: 1 2 16 (32)
I0608 12:20:22.687145 30581 net.cpp:165] Memory required for data: 7927906208
I0608 12:20:22.687149 30581 layer_factory.hpp:77] Creating layer mbox_loc
I0608 12:20:22.687155 30581 net.cpp:100] Creating Layer mbox_loc
I0608 12:20:22.687160 30581 net.cpp:434] mbox_loc <- conv4_3_norm_mbox_loc_flat
I0608 12:20:22.687166 30581 net.cpp:434] mbox_loc <- fc7_mbox_loc_flat
I0608 12:20:22.687172 30581 net.cpp:434] mbox_loc <- conv6_2_mbox_loc_flat
I0608 12:20:22.687178 30581 net.cpp:434] mbox_loc <- conv7_2_mbox_loc_flat
I0608 12:20:22.687185 30581 net.cpp:434] mbox_loc <- conv8_2_mbox_loc_flat
I0608 12:20:22.687189 30581 net.cpp:434] mbox_loc <- conv9_2_mbox_loc_flat
I0608 12:20:22.687196 30581 net.cpp:408] mbox_loc -> mbox_loc
I0608 12:20:22.687221 30581 net.cpp:150] Setting up mbox_loc
I0608 12:20:22.687227 30581 net.cpp:157] Top shape: 32 34928 (1117696)
I0608 12:20:22.687230 30581 net.cpp:165] Memory required for data: 7932376992
I0608 12:20:22.687234 30581 layer_factory.hpp:77] Creating layer mbox_conf
I0608 12:20:22.687240 30581 net.cpp:100] Creating Layer mbox_conf
I0608 12:20:22.687244 30581 net.cpp:434] mbox_conf <- conv4_3_norm_mbox_conf_flat
I0608 12:20:22.687250 30581 net.cpp:434] mbox_conf <- fc7_mbox_conf_flat
I0608 12:20:22.687257 30581 net.cpp:434] mbox_conf <- conv6_2_mbox_conf_flat
I0608 12:20:22.687263 30581 net.cpp:434] mbox_conf <- conv7_2_mbox_conf_flat
I0608 12:20:22.687266 30581 net.cpp:434] mbox_conf <- conv8_2_mbox_conf_flat
I0608 12:20:22.687271 30581 net.cpp:434] mbox_conf <- conv9_2_mbox_conf_flat
I0608 12:20:22.687278 30581 net.cpp:408] mbox_conf -> mbox_conf
I0608 12:20:22.687300 30581 net.cpp:150] Setting up mbox_conf
I0608 12:20:22.687306 30581 net.cpp:157] Top shape: 32 17464 (558848)
I0608 12:20:22.687310 30581 net.cpp:165] Memory required for data: 7934612384
I0608 12:20:22.687314 30581 layer_factory.hpp:77] Creating layer mbox_priorbox
I0608 12:20:22.687319 30581 net.cpp:100] Creating Layer mbox_priorbox
I0608 12:20:22.687325 30581 net.cpp:434] mbox_priorbox <- conv4_3_norm_mbox_priorbox
I0608 12:20:22.687330 30581 net.cpp:434] mbox_priorbox <- fc7_mbox_priorbox
I0608 12:20:22.687333 30581 net.cpp:434] mbox_priorbox <- conv6_2_mbox_priorbox
I0608 12:20:22.687340 30581 net.cpp:434] mbox_priorbox <- conv7_2_mbox_priorbox
I0608 12:20:22.687343 30581 net.cpp:434] mbox_priorbox <- conv8_2_mbox_priorbox
I0608 12:20:22.687347 30581 net.cpp:434] mbox_priorbox <- conv9_2_mbox_priorbox
I0608 12:20:22.687353 30581 net.cpp:408] mbox_priorbox -> mbox_priorbox
I0608 12:20:22.687376 30581 net.cpp:150] Setting up mbox_priorbox
I0608 12:20:22.687381 30581 net.cpp:157] Top shape: 1 2 34928 (69856)
I0608 12:20:22.687386 30581 net.cpp:165] Memory required for data: 7934891808
I0608 12:20:22.687388 30581 layer_factory.hpp:77] Creating layer mbox_loss
I0608 12:20:22.687398 30581 net.cpp:100] Creating Layer mbox_loss
I0608 12:20:22.687402 30581 net.cpp:434] mbox_loss <- mbox_loc
I0608 12:20:22.687407 30581 net.cpp:434] mbox_loss <- mbox_conf
I0608 12:20:22.687412 30581 net.cpp:434] mbox_loss <- mbox_priorbox
I0608 12:20:22.687417 30581 net.cpp:434] mbox_loss <- label
I0608 12:20:22.687424 30581 net.cpp:408] mbox_loss -> mbox_loss
I0608 12:20:22.687471 30581 layer_factory.hpp:77] Creating layer mbox_loss_smooth_L1_loc
I0608 12:20:22.687544 30581 layer_factory.hpp:77] Creating layer mbox_loss_softmax_conf
I0608 12:20:22.687553 30581 layer_factory.hpp:77] Creating layer mbox_loss_softmax_conf
I0608 12:20:22.687757 30581 net.cpp:150] Setting up mbox_loss
I0608 12:20:22.687764 30581 net.cpp:157] Top shape: (1)
I0608 12:20:22.687767 30581 net.cpp:160]     with loss weight 1
I0608 12:20:22.687789 30581 net.cpp:165] Memory required for data: 7934891812
I0608 12:20:22.687793 30581 net.cpp:226] mbox_loss needs backward computation.
I0608 12:20:22.687801 30581 net.cpp:228] mbox_priorbox does not need backward computation.
I0608 12:20:22.687810 30581 net.cpp:226] mbox_conf needs backward computation.
I0608 12:20:22.687822 30581 net.cpp:226] mbox_loc needs backward computation.
I0608 12:20:22.687829 30581 net.cpp:228] conv9_2_mbox_priorbox does not need backward computation.
I0608 12:20:22.687835 30581 net.cpp:226] conv9_2_mbox_conf_flat needs backward computation.
I0608 12:20:22.687840 30581 net.cpp:226] conv9_2_mbox_conf_perm needs backward computation.
I0608 12:20:22.687845 30581 net.cpp:226] conv9_2_mbox_conf needs backward computation.
I0608 12:20:22.687849 30581 net.cpp:226] conv9_2_mbox_loc_flat needs backward computation.
I0608 12:20:22.687853 30581 net.cpp:226] conv9_2_mbox_loc_perm needs backward computation.
I0608 12:20:22.687857 30581 net.cpp:226] conv9_2_mbox_loc needs backward computation.
I0608 12:20:22.687863 30581 net.cpp:228] conv8_2_mbox_priorbox does not need backward computation.
I0608 12:20:22.687868 30581 net.cpp:226] conv8_2_mbox_conf_flat needs backward computation.
I0608 12:20:22.687872 30581 net.cpp:226] conv8_2_mbox_conf_perm needs backward computation.
I0608 12:20:22.687877 30581 net.cpp:226] conv8_2_mbox_conf needs backward computation.
I0608 12:20:22.687882 30581 net.cpp:226] conv8_2_mbox_loc_flat needs backward computation.
I0608 12:20:22.687886 30581 net.cpp:226] conv8_2_mbox_loc_perm needs backward computation.
I0608 12:20:22.687891 30581 net.cpp:226] conv8_2_mbox_loc needs backward computation.
I0608 12:20:22.687894 30581 net.cpp:228] conv7_2_mbox_priorbox does not need backward computation.
I0608 12:20:22.687901 30581 net.cpp:226] conv7_2_mbox_conf_flat needs backward computation.
I0608 12:20:22.687906 30581 net.cpp:226] conv7_2_mbox_conf_perm needs backward computation.
I0608 12:20:22.687911 30581 net.cpp:226] conv7_2_mbox_conf needs backward computation.
I0608 12:20:22.687916 30581 net.cpp:226] conv7_2_mbox_loc_flat needs backward computation.
I0608 12:20:22.687921 30581 net.cpp:226] conv7_2_mbox_loc_perm needs backward computation.
I0608 12:20:22.687924 30581 net.cpp:226] conv7_2_mbox_loc needs backward computation.
I0608 12:20:22.687929 30581 net.cpp:228] conv6_2_mbox_priorbox does not need backward computation.
I0608 12:20:22.687934 30581 net.cpp:226] conv6_2_mbox_conf_flat needs backward computation.
I0608 12:20:22.687939 30581 net.cpp:226] conv6_2_mbox_conf_perm needs backward computation.
I0608 12:20:22.687943 30581 net.cpp:226] conv6_2_mbox_conf needs backward computation.
I0608 12:20:22.687948 30581 net.cpp:226] conv6_2_mbox_loc_flat needs backward computation.
I0608 12:20:22.687953 30581 net.cpp:226] conv6_2_mbox_loc_perm needs backward computation.
I0608 12:20:22.687958 30581 net.cpp:226] conv6_2_mbox_loc needs backward computation.
I0608 12:20:22.687963 30581 net.cpp:228] fc7_mbox_priorbox does not need backward computation.
I0608 12:20:22.687968 30581 net.cpp:226] fc7_mbox_conf_flat needs backward computation.
I0608 12:20:22.687973 30581 net.cpp:226] fc7_mbox_conf_perm needs backward computation.
I0608 12:20:22.687978 30581 net.cpp:226] fc7_mbox_conf needs backward computation.
I0608 12:20:22.687983 30581 net.cpp:226] fc7_mbox_loc_flat needs backward computation.
I0608 12:20:22.687988 30581 net.cpp:226] fc7_mbox_loc_perm needs backward computation.
I0608 12:20:22.687993 30581 net.cpp:226] fc7_mbox_loc needs backward computation.
I0608 12:20:22.687999 30581 net.cpp:228] conv4_3_norm_mbox_priorbox does not need backward computation.
I0608 12:20:22.688004 30581 net.cpp:226] conv4_3_norm_mbox_conf_flat needs backward computation.
I0608 12:20:22.688009 30581 net.cpp:226] conv4_3_norm_mbox_conf_perm needs backward computation.
I0608 12:20:22.688014 30581 net.cpp:226] conv4_3_norm_mbox_conf needs backward computation.
I0608 12:20:22.688019 30581 net.cpp:226] conv4_3_norm_mbox_loc_flat needs backward computation.
I0608 12:20:22.688024 30581 net.cpp:226] conv4_3_norm_mbox_loc_perm needs backward computation.
I0608 12:20:22.688029 30581 net.cpp:226] conv4_3_norm_mbox_loc needs backward computation.
I0608 12:20:22.688033 30581 net.cpp:226] conv4_3_norm_conv4_3_norm_0_split needs backward computation.
I0608 12:20:22.688038 30581 net.cpp:226] conv4_3_norm needs backward computation.
I0608 12:20:22.688047 30581 net.cpp:226] conv9_2_conv9_2_relu_0_split needs backward computation.
I0608 12:20:22.688053 30581 net.cpp:226] conv9_2_relu needs backward computation.
I0608 12:20:22.688056 30581 net.cpp:226] conv9_2 needs backward computation.
I0608 12:20:22.688062 30581 net.cpp:226] conv9_1_relu needs backward computation.
I0608 12:20:22.688067 30581 net.cpp:226] conv9_1 needs backward computation.
I0608 12:20:22.688071 30581 net.cpp:226] conv8_2_conv8_2_relu_0_split needs backward computation.
I0608 12:20:22.688076 30581 net.cpp:226] conv8_2_relu needs backward computation.
I0608 12:20:22.688081 30581 net.cpp:226] conv8_2 needs backward computation.
I0608 12:20:22.688084 30581 net.cpp:226] conv8_1_relu needs backward computation.
I0608 12:20:22.688088 30581 net.cpp:226] conv8_1 needs backward computation.
I0608 12:20:22.688092 30581 net.cpp:226] conv7_2_conv7_2_relu_0_split needs backward computation.
I0608 12:20:22.688097 30581 net.cpp:226] conv7_2_relu needs backward computation.
I0608 12:20:22.688102 30581 net.cpp:226] conv7_2 needs backward computation.
I0608 12:20:22.688105 30581 net.cpp:226] conv7_1_relu needs backward computation.
I0608 12:20:22.688109 30581 net.cpp:226] conv7_1 needs backward computation.
I0608 12:20:22.688115 30581 net.cpp:226] conv6_2_conv6_2_relu_0_split needs backward computation.
I0608 12:20:22.688119 30581 net.cpp:226] conv6_2_relu needs backward computation.
I0608 12:20:22.688123 30581 net.cpp:226] conv6_2 needs backward computation.
I0608 12:20:22.688127 30581 net.cpp:226] conv6_1_relu needs backward computation.
I0608 12:20:22.688133 30581 net.cpp:226] conv6_1 needs backward computation.
I0608 12:20:22.688138 30581 net.cpp:226] fc7_relu7_0_split needs backward computation.
I0608 12:20:22.688143 30581 net.cpp:226] relu7 needs backward computation.
I0608 12:20:22.688145 30581 net.cpp:226] fc7 needs backward computation.
I0608 12:20:22.688150 30581 net.cpp:226] relu6 needs backward computation.
I0608 12:20:22.688154 30581 net.cpp:226] fc6 needs backward computation.
I0608 12:20:22.688158 30581 net.cpp:226] pool5 needs backward computation.
I0608 12:20:22.688163 30581 net.cpp:226] relu5_3 needs backward computation.
I0608 12:20:22.688168 30581 net.cpp:226] conv5_3 needs backward computation.
I0608 12:20:22.688171 30581 net.cpp:226] relu5_2 needs backward computation.
I0608 12:20:22.688175 30581 net.cpp:226] conv5_2 needs backward computation.
I0608 12:20:22.688179 30581 net.cpp:226] relu5_1 needs backward computation.
I0608 12:20:22.688184 30581 net.cpp:226] conv5_1 needs backward computation.
I0608 12:20:22.688187 30581 net.cpp:226] pool4 needs backward computation.
I0608 12:20:22.688191 30581 net.cpp:226] conv4_3_relu4_3_0_split needs backward computation.
I0608 12:20:22.688195 30581 net.cpp:226] relu4_3 needs backward computation.
I0608 12:20:22.688200 30581 net.cpp:226] conv4_3 needs backward computation.
I0608 12:20:22.688205 30581 net.cpp:226] relu4_2 needs backward computation.
I0608 12:20:22.688208 30581 net.cpp:226] conv4_2 needs backward computation.
I0608 12:20:22.688212 30581 net.cpp:226] relu4_1 needs backward computation.
I0608 12:20:22.688216 30581 net.cpp:226] conv4_1 needs backward computation.
I0608 12:20:22.688220 30581 net.cpp:226] pool3 needs backward computation.
I0608 12:20:22.688225 30581 net.cpp:226] relu3_3 needs backward computation.
I0608 12:20:22.688228 30581 net.cpp:226] conv3_3 needs backward computation.
I0608 12:20:22.688232 30581 net.cpp:226] relu3_2 needs backward computation.
I0608 12:20:22.688236 30581 net.cpp:226] conv3_2 needs backward computation.
I0608 12:20:22.688241 30581 net.cpp:226] relu3_1 needs backward computation.
I0608 12:20:22.688244 30581 net.cpp:226] conv3_1 needs backward computation.
I0608 12:20:22.688249 30581 net.cpp:226] pool2 needs backward computation.
I0608 12:20:22.688254 30581 net.cpp:226] relu2_2 needs backward computation.
I0608 12:20:22.688258 30581 net.cpp:226] conv2_2 needs backward computation.
I0608 12:20:22.688262 30581 net.cpp:226] relu2_1 needs backward computation.
I0608 12:20:22.688271 30581 net.cpp:226] conv2_1 needs backward computation.
I0608 12:20:22.688275 30581 net.cpp:226] pool1 needs backward computation.
I0608 12:20:22.688279 30581 net.cpp:226] relu1_2 needs backward computation.
I0608 12:20:22.688282 30581 net.cpp:226] conv1_2 needs backward computation.
I0608 12:20:22.688287 30581 net.cpp:226] relu1_1 needs backward computation.
I0608 12:20:22.688290 30581 net.cpp:226] conv1_1 needs backward computation.
I0608 12:20:22.688297 30581 net.cpp:228] data_data_0_split does not need backward computation.
I0608 12:20:22.688302 30581 net.cpp:228] data does not need backward computation.
I0608 12:20:22.688305 30581 net.cpp:270] This network produces output mbox_loss
I0608 12:20:22.688364 30581 net.cpp:283] Network initialization done.
I0608 12:20:22.689067 30581 solver.cpp:196] Creating test net (#0) specified by test_net file: models/VGGNet/sharpen_tbs_v2.0/SSD_300x300/test.prototxt
I0608 12:20:22.689599 30581 net.cpp:58] Initializing net from parameters: 
name: "VGG_sharpen_tbs_v2.0_SSD_300x300_test"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "AnnotatedData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mean_value: 104
    mean_value: 117
    mean_value: 123
    resize_param {
      prob: 1
      resize_mode: WARP
      height: 300
      width: 300
      interp_mode: LINEAR
    }
  }
  data_param {
    source: "examples/sharpen_tbs_v2.0/sharpen_tbs_v2.0_test_lmdb"
    batch_size: 4
    backend: LMDB
  }
  annotated_data_param {
    batch_sampler {
    }
    label_map_file: "data/sharpen_tbs_v2.0/labelmap_voc.prototxt"
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "fc6"
  type: "Convolution"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    pad: 6
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 6
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "fc7"
  type: "Convolution"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "conv6_1"
  type: "Convolution"
  bottom: "fc7"
  top: "conv6_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6_1_relu"
  type: "ReLU"
  bottom: "conv6_1"
  top: "conv6_1"
}
layer {
  name: "conv6_2"
  type: "Convolution"
  bottom: "conv6_1"
  top: "conv6_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6_2_relu"
  type: "ReLU"
  bottom: "conv6_2"
  top: "conv6_2"
}
layer {
  name: "conv7_1"
  type: "Convolution"
  bottom: "conv6_2"
  top: "conv7_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv7_1_relu"
  type: "ReLU"
  bottom: "conv7_1"
  top: "conv7_1"
}
layer {
  name: "conv7_2"
  type: "Convolution"
  bottom: "conv7_1"
  top: "conv7_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv7_2_relu"
  type: "ReLU"
  bottom: "conv7_2"
  top: "conv7_2"
}
layer {
  name: "conv8_1"
  type: "Convolution"
  bottom: "conv7_2"
  top: "conv8_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv8_1_relu"
  type: "ReLU"
  bottom: "conv8_1"
  top: "conv8_1"
}
layer {
  name: "conv8_2"
  type: "Convolution"
  bottom: "conv8_1"
  top: "conv8_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv8_2_relu"
  type: "ReLU"
  bottom: "conv8_2"
  top: "conv8_2"
}
layer {
  name: "conv9_1"
  type: "Convolution"
  bottom: "conv8_2"
  top: "conv9_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv9_1_relu"
  type: "ReLU"
  bottom: "conv9_1"
  top: "conv9_1"
}
layer {
  name: "conv9_2"
  type: "Convolution"
  bottom: "conv9_1"
  top: "conv9_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv9_2_relu"
  type: "ReLU"
  bottom: "conv9_2"
  top: "conv9_2"
}
layer {
  name: "conv4_3_norm"
  type: "Normalize"
  bottom: "conv4_3"
  top: "conv4_3_norm"
  norm_param {
    across_spatial: false
    scale_filler {
      type: "constant"
      value: 20
    }
    channel_shared: false
  }
}
layer {
  name: "conv4_3_norm_mbox_loc"
  type: "Convolution"
  bottom: "conv4_3_norm"
  top: "conv4_3_norm_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_3_norm_mbox_loc_perm"
  type: "Permute"
  bottom: "conv4_3_norm_mbox_loc"
  top: "conv4_3_norm_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv4_3_norm_mbox_loc_perm"
  top: "conv4_3_norm_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_conf"
  type: "Convolution"
  bottom: "conv4_3_norm"
  top: "conv4_3_norm_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_3_norm_mbox_conf_perm"
  type: "Permute"
  bottom: "conv4_3_norm_mbox_conf"
  top: "conv4_3_norm_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv4_3_norm_mbox_conf_perm"
  top: "conv4_3_norm_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv4_3_norm"
  bottom: "data"
  top: "conv4_3_norm_mbox_priorbox"
  prior_box_param {
    min_size: 30
    max_size: 60
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 8
    offset: 0.5
  }
}
layer {
  name: "fc7_mbox_loc"
  type: "Convolution"
  bottom: "fc7"
  top: "fc7_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc7_mbox_loc_perm"
  type: "Permute"
  bottom: "fc7_mbox_loc"
  top: "fc7_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "fc7_mbox_loc_flat"
  type: "Flatten"
  bottom: "fc7_mbox_loc_perm"
  top: "fc7_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "fc7_mbox_conf"
  type: "Convolution"
  bottom: "fc7"
  top: "fc7_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 12
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc7_mbox_conf_perm"
  type: "Permute"
  bottom: "fc7_mbox_conf"
  top: "fc7_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "fc7_mbox_conf_flat"
  type: "Flatten"
  bottom: "fc7_mbox_conf_perm"
  top: "fc7_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "fc7_mbox_priorbox"
  type: "PriorBox"
  bottom: "fc7"
  bottom: "data"
  top: "fc7_mbox_priorbox"
  prior_box_param {
    min_size: 60
    max_size: 111
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 16
    offset: 0.5
  }
}
layer {
  name: "conv6_2_mbox_loc"
  type: "Convolution"
  bottom: "conv6_2"
  top: "conv6_2_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6_2_mbox_loc_perm"
  type: "Permute"
  bottom: "conv6_2_mbox_loc"
  top: "conv6_2_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv6_2_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv6_2_mbox_loc_perm"
  top: "conv6_2_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv6_2_mbox_conf"
  type: "Convolution"
  bottom: "conv6_2"
  top: "conv6_2_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 12
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6_2_mbox_conf_perm"
  type: "Permute"
  bottom: "conv6_2_mbox_conf"
  top: "conv6_2_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv6_2_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv6_2_mbox_conf_perm"
  top: "conv6_2_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv6_2_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv6_2"
  bottom: "data"
  top: "conv6_2_mbox_priorbox"
  prior_box_param {
    min_size: 111
    max_size: 162
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 32
    offset: 0.5
  }
}
layer {
  name: "conv7_2_mbox_loc"
  type: "Convolution"
  bottom: "conv7_2"
  top: "conv7_2_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv7_2_mbox_loc_perm"
  type: "Permute"
  bottom: "conv7_2_mbox_loc"
  top: "conv7_2_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv7_2_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv7_2_mbox_loc_perm"
  top: "conv7_2_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv7_2_mbox_conf"
  type: "Convolution"
  bottom: "conv7_2"
  top: "conv7_2_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 12
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv7_2_mbox_conf_perm"
  type: "Permute"
  bottom: "conv7_2_mbox_conf"
  top: "conv7_2_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv7_2_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv7_2_mbox_conf_perm"
  top: "conv7_2_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv7_2_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv7_2"
  bottom: "data"
  top: "conv7_2_mbox_priorbox"
  prior_box_param {
    min_size: 162
    max_size: 213
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 64
    offset: 0.5
  }
}
layer {
  name: "conv8_2_mbox_loc"
  type: "Convolution"
  bottom: "conv8_2"
  top: "conv8_2_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv8_2_mbox_loc_perm"
  type: "Permute"
  bottom: "conv8_2_mbox_loc"
  top: "conv8_2_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv8_2_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv8_2_mbox_loc_perm"
  top: "conv8_2_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv8_2_mbox_conf"
  type: "Convolution"
  bottom: "conv8_2"
  top: "conv8_2_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv8_2_mbox_conf_perm"
  type: "Permute"
  bottom: "conv8_2_mbox_conf"
  top: "conv8_2_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv8_2_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv8_2_mbox_conf_perm"
  top: "conv8_2_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv8_2_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv8_2"
  bottom: "data"
  top: "conv8_2_mbox_priorbox"
  prior_box_param {
    min_size: 213
    max_size: 264
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 100
    offset: 0.5
  }
}
layer {
  name: "conv9_2_mbox_loc"
  type: "Convolution"
  bottom: "conv9_2"
  top: "conv9_2_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv9_2_mbox_loc_perm"
  type: "Permute"
  bottom: "conv9_2_mbox_loc"
  top: "conv9_2_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv9_2_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv9_2_mbox_loc_perm"
  top: "conv9_2_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv9_2_mbox_conf"
  type: "Convolution"
  bottom: "conv9_2"
  top: "conv9_2_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv9_2_mbox_conf_perm"
  type: "Permute"
  bottom: "conv9_2_mbox_conf"
  top: "conv9_2_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv9_2_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv9_2_mbox_conf_perm"
  top: "conv9_2_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv9_2_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv9_2"
  bottom: "data"
  top: "conv9_2_mbox_priorbox"
  prior_box_param {
    min_size: 264
    max_size: 315
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 300
    offset: 0.5
  }
}
layer {
  name: "mbox_loc"
  type: "Concat"
  bottom: "conv4_3_norm_mbox_loc_flat"
  bottom: "fc7_mbox_loc_flat"
  bottom: "conv6_2_mbox_loc_flat"
  bottom: "conv7_2_mbox_loc_flat"
  bottom: "conv8_2_mbox_loc_flat"
  bottom: "conv9_2_mbox_loc_flat"
  top: "mbox_loc"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mbox_conf"
  type: "Concat"
  bottom: "conv4_3_norm_mbox_conf_flat"
  bottom: "fc7_mbox_conf_flat"
  bottom: "conv6_2_mbox_conf_flat"
  bottom: "conv7_2_mbox_conf_flat"
  bottom: "conv8_2_mbox_conf_flat"
  bottom: "conv9_2_mbox_conf_flat"
  top: "mbox_conf"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mbox_priorbox"
  type: "Concat"
  bottom: "conv4_3_norm_mbox_priorbox"
  bottom: "fc7_mbox_priorbox"
  bottom: "conv6_2_mbox_priorbox"
  bottom: "conv7_2_mbox_priorbox"
  bottom: "conv8_2_mbox_priorbox"
  bottom: "conv9_2_mbox_priorbox"
  top: "mbox_priorbox"
  concat_param {
    axis: 2
  }
}
layer {
  name: "mbox_conf_reshape"
  type: "Reshape"
  bottom: "mbox_conf"
  top: "mbox_conf_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: -1
      dim: 2
    }
  }
}
layer {
  name: "mbox_conf_softmax"
  type: "Softmax"
  bottom: "mbox_conf_reshape"
  top: "mbox_conf_softmax"
  softmax_param {
    axis: 2
  }
}
layer {
  name: "mbox_conf_flatten"
  type: "Flatten"
  bottom: "mbox_conf_softmax"
  top: "mbox_conf_flatten"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "detection_out"
  type: "DetectionOutput"
  bottom: "mbox_loc"
  bottom: "mbox_conf_flatten"
  bottom: "mbox_priorbox"
  top: "detection_out"
  include {
    phase: TEST
  }
  detection_output_param {
    num_classes: 2
    share_location: true
    background_label_id: 0
    nms_param {
      nms_threshold: 0.45
      top_k: 400
    }
    save_output_param {
      output_directory: "/home/shangzw/data/sharpen_tbs_v2.0/results/tbs/SSD_300x300/Main"
      output_name_prefix: "comp4_det_test_"
      output_format: "VOC"
      label_map_file: "data/sharpen_tbs_v2.0/labelmap_voc.prototxt"
      name_size_file: "data/sharpen_tbs_v2.0/test_name_size"
      num_test_image: 100
    }
    code_type: CENTER_SIZE
    keep_top_k: 200
    confidence_threshold: 0.01
  }
}
layer {
  name: "detection_eval"
  type: "DetectionEvaluate"
  bottom: "detection_out"
  bottom: "label"
  top: "detection_eval"
  include {
    phase: TEST
  }
  detection_evaluate_param {
    num_classes: 2
    background_label_id: 0
    overlap_threshold: 0.5
    evaluate_difficult_gt: false
    name_size_file: "data/sharpen_tbs_v2.0/test_name_size"
  }
}
I0608 12:20:22.689982 30581 layer_factory.hpp:77] Creating layer data
I0608 12:20:22.690035 30581 net.cpp:100] Creating Layer data
I0608 12:20:22.690044 30581 net.cpp:408] data -> data
I0608 12:20:22.690054 30581 net.cpp:408] data -> label
I0608 12:20:22.690513 30608 db_lmdb.cpp:35] Opened lmdb examples/sharpen_tbs_v2.0/sharpen_tbs_v2.0_test_lmdb
I0608 12:20:22.692020 30581 annotated_data_layer.cpp:62] output data size: 4,3,300,300
I0608 12:20:22.701752 30581 net.cpp:150] Setting up data
I0608 12:20:22.701786 30581 net.cpp:157] Top shape: 4 3 300 300 (1080000)
I0608 12:20:22.701792 30581 net.cpp:157] Top shape: 1 1 1 8 (8)
I0608 12:20:22.701795 30581 net.cpp:165] Memory required for data: 4320032
I0608 12:20:22.701802 30581 layer_factory.hpp:77] Creating layer data_data_0_split
I0608 12:20:22.701828 30581 net.cpp:100] Creating Layer data_data_0_split
I0608 12:20:22.701848 30581 net.cpp:434] data_data_0_split <- data
I0608 12:20:22.701856 30581 net.cpp:408] data_data_0_split -> data_data_0_split_0
I0608 12:20:22.701869 30581 net.cpp:408] data_data_0_split -> data_data_0_split_1
I0608 12:20:22.701876 30581 net.cpp:408] data_data_0_split -> data_data_0_split_2
I0608 12:20:22.701885 30581 net.cpp:408] data_data_0_split -> data_data_0_split_3
I0608 12:20:22.701906 30581 net.cpp:408] data_data_0_split -> data_data_0_split_4
I0608 12:20:22.701915 30581 net.cpp:408] data_data_0_split -> data_data_0_split_5
I0608 12:20:22.701921 30581 net.cpp:408] data_data_0_split -> data_data_0_split_6
I0608 12:20:22.702018 30581 net.cpp:150] Setting up data_data_0_split
I0608 12:20:22.702024 30581 net.cpp:157] Top shape: 4 3 300 300 (1080000)
I0608 12:20:22.702029 30581 net.cpp:157] Top shape: 4 3 300 300 (1080000)
I0608 12:20:22.702034 30581 net.cpp:157] Top shape: 4 3 300 300 (1080000)
I0608 12:20:22.702040 30581 net.cpp:157] Top shape: 4 3 300 300 (1080000)
I0608 12:20:22.702045 30581 net.cpp:157] Top shape: 4 3 300 300 (1080000)
I0608 12:20:22.702059 30581 net.cpp:157] Top shape: 4 3 300 300 (1080000)
I0608 12:20:22.702065 30581 net.cpp:157] Top shape: 4 3 300 300 (1080000)
I0608 12:20:22.702070 30581 net.cpp:165] Memory required for data: 34560032
I0608 12:20:22.702075 30581 layer_factory.hpp:77] Creating layer conv1_1
I0608 12:20:22.702086 30581 net.cpp:100] Creating Layer conv1_1
I0608 12:20:22.702091 30581 net.cpp:434] conv1_1 <- data_data_0_split_0
I0608 12:20:22.702100 30581 net.cpp:408] conv1_1 -> conv1_1
I0608 12:20:22.703332 30581 net.cpp:150] Setting up conv1_1
I0608 12:20:22.703343 30581 net.cpp:157] Top shape: 4 64 300 300 (23040000)
I0608 12:20:22.703347 30581 net.cpp:165] Memory required for data: 126720032
I0608 12:20:22.703359 30581 layer_factory.hpp:77] Creating layer relu1_1
I0608 12:20:22.703367 30581 net.cpp:100] Creating Layer relu1_1
I0608 12:20:22.703372 30581 net.cpp:434] relu1_1 <- conv1_1
I0608 12:20:22.703377 30581 net.cpp:395] relu1_1 -> conv1_1 (in-place)
I0608 12:20:22.703496 30581 net.cpp:150] Setting up relu1_1
I0608 12:20:22.703505 30581 net.cpp:157] Top shape: 4 64 300 300 (23040000)
I0608 12:20:22.703508 30581 net.cpp:165] Memory required for data: 218880032
I0608 12:20:22.703512 30581 layer_factory.hpp:77] Creating layer conv1_2
I0608 12:20:22.703523 30581 net.cpp:100] Creating Layer conv1_2
I0608 12:20:22.703527 30581 net.cpp:434] conv1_2 <- conv1_1
I0608 12:20:22.703533 30581 net.cpp:408] conv1_2 -> conv1_2
I0608 12:20:22.706645 30581 net.cpp:150] Setting up conv1_2
I0608 12:20:22.706658 30581 net.cpp:157] Top shape: 4 64 300 300 (23040000)
I0608 12:20:22.706662 30581 net.cpp:165] Memory required for data: 311040032
I0608 12:20:22.706672 30581 layer_factory.hpp:77] Creating layer relu1_2
I0608 12:20:22.706681 30581 net.cpp:100] Creating Layer relu1_2
I0608 12:20:22.706686 30581 net.cpp:434] relu1_2 <- conv1_2
I0608 12:20:22.706691 30581 net.cpp:395] relu1_2 -> conv1_2 (in-place)
I0608 12:20:22.707289 30581 net.cpp:150] Setting up relu1_2
I0608 12:20:22.707299 30581 net.cpp:157] Top shape: 4 64 300 300 (23040000)
I0608 12:20:22.707304 30581 net.cpp:165] Memory required for data: 403200032
I0608 12:20:22.707309 30581 layer_factory.hpp:77] Creating layer pool1
I0608 12:20:22.707315 30581 net.cpp:100] Creating Layer pool1
I0608 12:20:22.707320 30581 net.cpp:434] pool1 <- conv1_2
I0608 12:20:22.707327 30581 net.cpp:408] pool1 -> pool1
I0608 12:20:22.707367 30581 net.cpp:150] Setting up pool1
I0608 12:20:22.707375 30581 net.cpp:157] Top shape: 4 64 150 150 (5760000)
I0608 12:20:22.707378 30581 net.cpp:165] Memory required for data: 426240032
I0608 12:20:22.707382 30581 layer_factory.hpp:77] Creating layer conv2_1
I0608 12:20:22.707391 30581 net.cpp:100] Creating Layer conv2_1
I0608 12:20:22.707396 30581 net.cpp:434] conv2_1 <- pool1
I0608 12:20:22.707402 30581 net.cpp:408] conv2_1 -> conv2_1
I0608 12:20:22.708325 30581 net.cpp:150] Setting up conv2_1
I0608 12:20:22.708334 30581 net.cpp:157] Top shape: 4 128 150 150 (11520000)
I0608 12:20:22.708338 30581 net.cpp:165] Memory required for data: 472320032
I0608 12:20:22.708348 30581 layer_factory.hpp:77] Creating layer relu2_1
I0608 12:20:22.708355 30581 net.cpp:100] Creating Layer relu2_1
I0608 12:20:22.708360 30581 net.cpp:434] relu2_1 <- conv2_1
I0608 12:20:22.708366 30581 net.cpp:395] relu2_1 -> conv2_1 (in-place)
I0608 12:20:22.708933 30581 net.cpp:150] Setting up relu2_1
I0608 12:20:22.708942 30581 net.cpp:157] Top shape: 4 128 150 150 (11520000)
I0608 12:20:22.708947 30581 net.cpp:165] Memory required for data: 518400032
I0608 12:20:22.708951 30581 layer_factory.hpp:77] Creating layer conv2_2
I0608 12:20:22.708961 30581 net.cpp:100] Creating Layer conv2_2
I0608 12:20:22.708966 30581 net.cpp:434] conv2_2 <- conv2_1
I0608 12:20:22.708972 30581 net.cpp:408] conv2_2 -> conv2_2
I0608 12:20:22.711042 30581 net.cpp:150] Setting up conv2_2
I0608 12:20:22.711053 30581 net.cpp:157] Top shape: 4 128 150 150 (11520000)
I0608 12:20:22.711057 30581 net.cpp:165] Memory required for data: 564480032
I0608 12:20:22.711066 30581 layer_factory.hpp:77] Creating layer relu2_2
I0608 12:20:22.711082 30581 net.cpp:100] Creating Layer relu2_2
I0608 12:20:22.711087 30581 net.cpp:434] relu2_2 <- conv2_2
I0608 12:20:22.711092 30581 net.cpp:395] relu2_2 -> conv2_2 (in-place)
I0608 12:20:22.711225 30581 net.cpp:150] Setting up relu2_2
I0608 12:20:22.711233 30581 net.cpp:157] Top shape: 4 128 150 150 (11520000)
I0608 12:20:22.711236 30581 net.cpp:165] Memory required for data: 610560032
I0608 12:20:22.711241 30581 layer_factory.hpp:77] Creating layer pool2
I0608 12:20:22.711247 30581 net.cpp:100] Creating Layer pool2
I0608 12:20:22.711252 30581 net.cpp:434] pool2 <- conv2_2
I0608 12:20:22.711257 30581 net.cpp:408] pool2 -> pool2
I0608 12:20:22.711297 30581 net.cpp:150] Setting up pool2
I0608 12:20:22.711303 30581 net.cpp:157] Top shape: 4 128 75 75 (2880000)
I0608 12:20:22.711307 30581 net.cpp:165] Memory required for data: 622080032
I0608 12:20:22.711310 30581 layer_factory.hpp:77] Creating layer conv3_1
I0608 12:20:22.711318 30581 net.cpp:100] Creating Layer conv3_1
I0608 12:20:22.711323 30581 net.cpp:434] conv3_1 <- pool2
I0608 12:20:22.711329 30581 net.cpp:408] conv3_1 -> conv3_1
I0608 12:20:22.714640 30581 net.cpp:150] Setting up conv3_1
I0608 12:20:22.714653 30581 net.cpp:157] Top shape: 4 256 75 75 (5760000)
I0608 12:20:22.714658 30581 net.cpp:165] Memory required for data: 645120032
I0608 12:20:22.714670 30581 layer_factory.hpp:77] Creating layer relu3_1
I0608 12:20:22.714679 30581 net.cpp:100] Creating Layer relu3_1
I0608 12:20:22.714684 30581 net.cpp:434] relu3_1 <- conv3_1
I0608 12:20:22.714690 30581 net.cpp:395] relu3_1 -> conv3_1 (in-place)
I0608 12:20:22.714833 30581 net.cpp:150] Setting up relu3_1
I0608 12:20:22.714841 30581 net.cpp:157] Top shape: 4 256 75 75 (5760000)
I0608 12:20:22.714844 30581 net.cpp:165] Memory required for data: 668160032
I0608 12:20:22.714861 30581 layer_factory.hpp:77] Creating layer conv3_2
I0608 12:20:22.714885 30581 net.cpp:100] Creating Layer conv3_2
I0608 12:20:22.714890 30581 net.cpp:434] conv3_2 <- conv3_1
I0608 12:20:22.714896 30581 net.cpp:408] conv3_2 -> conv3_2
I0608 12:20:22.719507 30581 net.cpp:150] Setting up conv3_2
I0608 12:20:22.719521 30581 net.cpp:157] Top shape: 4 256 75 75 (5760000)
I0608 12:20:22.719525 30581 net.cpp:165] Memory required for data: 691200032
I0608 12:20:22.719532 30581 layer_factory.hpp:77] Creating layer relu3_2
I0608 12:20:22.719542 30581 net.cpp:100] Creating Layer relu3_2
I0608 12:20:22.719547 30581 net.cpp:434] relu3_2 <- conv3_2
I0608 12:20:22.719553 30581 net.cpp:395] relu3_2 -> conv3_2 (in-place)
I0608 12:20:22.719692 30581 net.cpp:150] Setting up relu3_2
I0608 12:20:22.719700 30581 net.cpp:157] Top shape: 4 256 75 75 (5760000)
I0608 12:20:22.719703 30581 net.cpp:165] Memory required for data: 714240032
I0608 12:20:22.719707 30581 layer_factory.hpp:77] Creating layer conv3_3
I0608 12:20:22.719720 30581 net.cpp:100] Creating Layer conv3_3
I0608 12:20:22.719725 30581 net.cpp:434] conv3_3 <- conv3_2
I0608 12:20:22.719732 30581 net.cpp:408] conv3_3 -> conv3_3
I0608 12:20:22.724323 30581 net.cpp:150] Setting up conv3_3
I0608 12:20:22.724337 30581 net.cpp:157] Top shape: 4 256 75 75 (5760000)
I0608 12:20:22.724341 30581 net.cpp:165] Memory required for data: 737280032
I0608 12:20:22.724349 30581 layer_factory.hpp:77] Creating layer relu3_3
I0608 12:20:22.724356 30581 net.cpp:100] Creating Layer relu3_3
I0608 12:20:22.724360 30581 net.cpp:434] relu3_3 <- conv3_3
I0608 12:20:22.724371 30581 net.cpp:395] relu3_3 -> conv3_3 (in-place)
I0608 12:20:22.724526 30581 net.cpp:150] Setting up relu3_3
I0608 12:20:22.724534 30581 net.cpp:157] Top shape: 4 256 75 75 (5760000)
I0608 12:20:22.724537 30581 net.cpp:165] Memory required for data: 760320032
I0608 12:20:22.724541 30581 layer_factory.hpp:77] Creating layer pool3
I0608 12:20:22.724551 30581 net.cpp:100] Creating Layer pool3
I0608 12:20:22.724555 30581 net.cpp:434] pool3 <- conv3_3
I0608 12:20:22.724560 30581 net.cpp:408] pool3 -> pool3
I0608 12:20:22.724617 30581 net.cpp:150] Setting up pool3
I0608 12:20:22.724623 30581 net.cpp:157] Top shape: 4 256 38 38 (1478656)
I0608 12:20:22.724638 30581 net.cpp:165] Memory required for data: 766234656
I0608 12:20:22.724642 30581 layer_factory.hpp:77] Creating layer conv4_1
I0608 12:20:22.724654 30581 net.cpp:100] Creating Layer conv4_1
I0608 12:20:22.724658 30581 net.cpp:434] conv4_1 <- pool3
I0608 12:20:22.724666 30581 net.cpp:408] conv4_1 -> conv4_1
I0608 12:20:22.733902 30581 net.cpp:150] Setting up conv4_1
I0608 12:20:22.733921 30581 net.cpp:157] Top shape: 4 512 38 38 (2957312)
I0608 12:20:22.733924 30581 net.cpp:165] Memory required for data: 778063904
I0608 12:20:22.733932 30581 layer_factory.hpp:77] Creating layer relu4_1
I0608 12:20:22.733956 30581 net.cpp:100] Creating Layer relu4_1
I0608 12:20:22.733979 30581 net.cpp:434] relu4_1 <- conv4_1
I0608 12:20:22.733988 30581 net.cpp:395] relu4_1 -> conv4_1 (in-place)
I0608 12:20:22.734808 30581 net.cpp:150] Setting up relu4_1
I0608 12:20:22.734819 30581 net.cpp:157] Top shape: 4 512 38 38 (2957312)
I0608 12:20:22.734823 30581 net.cpp:165] Memory required for data: 789893152
I0608 12:20:22.734839 30581 layer_factory.hpp:77] Creating layer conv4_2
I0608 12:20:22.734848 30581 net.cpp:100] Creating Layer conv4_2
I0608 12:20:22.734853 30581 net.cpp:434] conv4_2 <- conv4_1
I0608 12:20:22.734875 30581 net.cpp:408] conv4_2 -> conv4_2
I0608 12:20:22.748001 30581 net.cpp:150] Setting up conv4_2
I0608 12:20:22.748019 30581 net.cpp:157] Top shape: 4 512 38 38 (2957312)
I0608 12:20:22.748023 30581 net.cpp:165] Memory required for data: 801722400
I0608 12:20:22.748031 30581 layer_factory.hpp:77] Creating layer relu4_2
I0608 12:20:22.748054 30581 net.cpp:100] Creating Layer relu4_2
I0608 12:20:22.748057 30581 net.cpp:434] relu4_2 <- conv4_2
I0608 12:20:22.748061 30581 net.cpp:395] relu4_2 -> conv4_2 (in-place)
I0608 12:20:22.748903 30581 net.cpp:150] Setting up relu4_2
I0608 12:20:22.748911 30581 net.cpp:157] Top shape: 4 512 38 38 (2957312)
I0608 12:20:22.748914 30581 net.cpp:165] Memory required for data: 813551648
I0608 12:20:22.748917 30581 layer_factory.hpp:77] Creating layer conv4_3
I0608 12:20:22.748942 30581 net.cpp:100] Creating Layer conv4_3
I0608 12:20:22.748950 30581 net.cpp:434] conv4_3 <- conv4_2
I0608 12:20:22.748961 30581 net.cpp:408] conv4_3 -> conv4_3
I0608 12:20:22.761762 30581 net.cpp:150] Setting up conv4_3
I0608 12:20:22.761778 30581 net.cpp:157] Top shape: 4 512 38 38 (2957312)
I0608 12:20:22.761781 30581 net.cpp:165] Memory required for data: 825380896
I0608 12:20:22.761802 30581 layer_factory.hpp:77] Creating layer relu4_3
I0608 12:20:22.761809 30581 net.cpp:100] Creating Layer relu4_3
I0608 12:20:22.761814 30581 net.cpp:434] relu4_3 <- conv4_3
I0608 12:20:22.761818 30581 net.cpp:395] relu4_3 -> conv4_3 (in-place)
I0608 12:20:22.762009 30581 net.cpp:150] Setting up relu4_3
I0608 12:20:22.762020 30581 net.cpp:157] Top shape: 4 512 38 38 (2957312)
I0608 12:20:22.762024 30581 net.cpp:165] Memory required for data: 837210144
I0608 12:20:22.762042 30581 layer_factory.hpp:77] Creating layer conv4_3_relu4_3_0_split
I0608 12:20:22.762063 30581 net.cpp:100] Creating Layer conv4_3_relu4_3_0_split
I0608 12:20:22.762066 30581 net.cpp:434] conv4_3_relu4_3_0_split <- conv4_3
I0608 12:20:22.762073 30581 net.cpp:408] conv4_3_relu4_3_0_split -> conv4_3_relu4_3_0_split_0
I0608 12:20:22.762081 30581 net.cpp:408] conv4_3_relu4_3_0_split -> conv4_3_relu4_3_0_split_1
I0608 12:20:22.762140 30581 net.cpp:150] Setting up conv4_3_relu4_3_0_split
I0608 12:20:22.762147 30581 net.cpp:157] Top shape: 4 512 38 38 (2957312)
I0608 12:20:22.762152 30581 net.cpp:157] Top shape: 4 512 38 38 (2957312)
I0608 12:20:22.762171 30581 net.cpp:165] Memory required for data: 860868640
I0608 12:20:22.762173 30581 layer_factory.hpp:77] Creating layer pool4
I0608 12:20:22.762194 30581 net.cpp:100] Creating Layer pool4
I0608 12:20:22.762199 30581 net.cpp:434] pool4 <- conv4_3_relu4_3_0_split_0
I0608 12:20:22.762205 30581 net.cpp:408] pool4 -> pool4
I0608 12:20:22.762250 30581 net.cpp:150] Setting up pool4
I0608 12:20:22.762257 30581 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0608 12:20:22.762262 30581 net.cpp:165] Memory required for data: 863825952
I0608 12:20:22.762277 30581 layer_factory.hpp:77] Creating layer conv5_1
I0608 12:20:22.762290 30581 net.cpp:100] Creating Layer conv5_1
I0608 12:20:22.762293 30581 net.cpp:434] conv5_1 <- pool4
I0608 12:20:22.762301 30581 net.cpp:408] conv5_1 -> conv5_1
I0608 12:20:22.776082 30581 net.cpp:150] Setting up conv5_1
I0608 12:20:22.776098 30581 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0608 12:20:22.776101 30581 net.cpp:165] Memory required for data: 866783264
I0608 12:20:22.776123 30581 layer_factory.hpp:77] Creating layer relu5_1
I0608 12:20:22.776127 30581 net.cpp:100] Creating Layer relu5_1
I0608 12:20:22.776131 30581 net.cpp:434] relu5_1 <- conv5_1
I0608 12:20:22.776136 30581 net.cpp:395] relu5_1 -> conv5_1 (in-place)
I0608 12:20:22.776291 30581 net.cpp:150] Setting up relu5_1
I0608 12:20:22.776299 30581 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0608 12:20:22.776301 30581 net.cpp:165] Memory required for data: 869740576
I0608 12:20:22.776304 30581 layer_factory.hpp:77] Creating layer conv5_2
I0608 12:20:22.776327 30581 net.cpp:100] Creating Layer conv5_2
I0608 12:20:22.776329 30581 net.cpp:434] conv5_2 <- conv5_1
I0608 12:20:22.776335 30581 net.cpp:408] conv5_2 -> conv5_2
I0608 12:20:22.789361 30581 net.cpp:150] Setting up conv5_2
I0608 12:20:22.789377 30581 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0608 12:20:22.789381 30581 net.cpp:165] Memory required for data: 872697888
I0608 12:20:22.789386 30581 layer_factory.hpp:77] Creating layer relu5_2
I0608 12:20:22.789394 30581 net.cpp:100] Creating Layer relu5_2
I0608 12:20:22.789398 30581 net.cpp:434] relu5_2 <- conv5_2
I0608 12:20:22.789402 30581 net.cpp:395] relu5_2 -> conv5_2 (in-place)
I0608 12:20:22.789561 30581 net.cpp:150] Setting up relu5_2
I0608 12:20:22.789569 30581 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0608 12:20:22.789572 30581 net.cpp:165] Memory required for data: 875655200
I0608 12:20:22.789574 30581 layer_factory.hpp:77] Creating layer conv5_3
I0608 12:20:22.789598 30581 net.cpp:100] Creating Layer conv5_3
I0608 12:20:22.789600 30581 net.cpp:434] conv5_3 <- conv5_2
I0608 12:20:22.789619 30581 net.cpp:408] conv5_3 -> conv5_3
I0608 12:20:22.804875 30581 net.cpp:150] Setting up conv5_3
I0608 12:20:22.804893 30581 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0608 12:20:22.804896 30581 net.cpp:165] Memory required for data: 878612512
I0608 12:20:22.804918 30581 layer_factory.hpp:77] Creating layer relu5_3
I0608 12:20:22.804929 30581 net.cpp:100] Creating Layer relu5_3
I0608 12:20:22.804932 30581 net.cpp:434] relu5_3 <- conv5_3
I0608 12:20:22.804939 30581 net.cpp:395] relu5_3 -> conv5_3 (in-place)
I0608 12:20:22.805090 30581 net.cpp:150] Setting up relu5_3
I0608 12:20:22.805097 30581 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0608 12:20:22.805100 30581 net.cpp:165] Memory required for data: 881569824
I0608 12:20:22.805104 30581 layer_factory.hpp:77] Creating layer pool5
I0608 12:20:22.805111 30581 net.cpp:100] Creating Layer pool5
I0608 12:20:22.805116 30581 net.cpp:434] pool5 <- conv5_3
I0608 12:20:22.805124 30581 net.cpp:408] pool5 -> pool5
I0608 12:20:22.805186 30581 net.cpp:150] Setting up pool5
I0608 12:20:22.805192 30581 net.cpp:157] Top shape: 4 512 19 19 (739328)
I0608 12:20:22.805196 30581 net.cpp:165] Memory required for data: 884527136
I0608 12:20:22.805198 30581 layer_factory.hpp:77] Creating layer fc6
I0608 12:20:22.805209 30581 net.cpp:100] Creating Layer fc6
I0608 12:20:22.805217 30581 net.cpp:434] fc6 <- pool5
I0608 12:20:22.805223 30581 net.cpp:408] fc6 -> fc6
I0608 12:20:22.828673 30581 net.cpp:150] Setting up fc6
I0608 12:20:22.828692 30581 net.cpp:157] Top shape: 4 1024 19 19 (1478656)
I0608 12:20:22.828696 30581 net.cpp:165] Memory required for data: 890441760
I0608 12:20:22.828716 30581 layer_factory.hpp:77] Creating layer relu6
I0608 12:20:22.828724 30581 net.cpp:100] Creating Layer relu6
I0608 12:20:22.828727 30581 net.cpp:434] relu6 <- fc6
I0608 12:20:22.828734 30581 net.cpp:395] relu6 -> fc6 (in-place)
I0608 12:20:22.829540 30581 net.cpp:150] Setting up relu6
I0608 12:20:22.829552 30581 net.cpp:157] Top shape: 4 1024 19 19 (1478656)
I0608 12:20:22.829567 30581 net.cpp:165] Memory required for data: 896356384
I0608 12:20:22.829573 30581 layer_factory.hpp:77] Creating layer fc7
I0608 12:20:22.829586 30581 net.cpp:100] Creating Layer fc7
I0608 12:20:22.829591 30581 net.cpp:434] fc7 <- fc6
I0608 12:20:22.829601 30581 net.cpp:408] fc7 -> fc7
I0608 12:20:22.836083 30581 net.cpp:150] Setting up fc7
I0608 12:20:22.836102 30581 net.cpp:157] Top shape: 4 1024 19 19 (1478656)
I0608 12:20:22.836104 30581 net.cpp:165] Memory required for data: 902271008
I0608 12:20:22.836113 30581 layer_factory.hpp:77] Creating layer relu7
I0608 12:20:22.836122 30581 net.cpp:100] Creating Layer relu7
I0608 12:20:22.836127 30581 net.cpp:434] relu7 <- fc7
I0608 12:20:22.836134 30581 net.cpp:395] relu7 -> fc7 (in-place)
I0608 12:20:22.836269 30581 net.cpp:150] Setting up relu7
I0608 12:20:22.836278 30581 net.cpp:157] Top shape: 4 1024 19 19 (1478656)
I0608 12:20:22.836280 30581 net.cpp:165] Memory required for data: 908185632
I0608 12:20:22.836282 30581 layer_factory.hpp:77] Creating layer fc7_relu7_0_split
I0608 12:20:22.836289 30581 net.cpp:100] Creating Layer fc7_relu7_0_split
I0608 12:20:22.836294 30581 net.cpp:434] fc7_relu7_0_split <- fc7
I0608 12:20:22.836302 30581 net.cpp:408] fc7_relu7_0_split -> fc7_relu7_0_split_0
I0608 12:20:22.836308 30581 net.cpp:408] fc7_relu7_0_split -> fc7_relu7_0_split_1
I0608 12:20:22.836320 30581 net.cpp:408] fc7_relu7_0_split -> fc7_relu7_0_split_2
I0608 12:20:22.836328 30581 net.cpp:408] fc7_relu7_0_split -> fc7_relu7_0_split_3
I0608 12:20:22.836390 30581 net.cpp:150] Setting up fc7_relu7_0_split
I0608 12:20:22.836395 30581 net.cpp:157] Top shape: 4 1024 19 19 (1478656)
I0608 12:20:22.836400 30581 net.cpp:157] Top shape: 4 1024 19 19 (1478656)
I0608 12:20:22.836405 30581 net.cpp:157] Top shape: 4 1024 19 19 (1478656)
I0608 12:20:22.836421 30581 net.cpp:157] Top shape: 4 1024 19 19 (1478656)
I0608 12:20:22.836423 30581 net.cpp:165] Memory required for data: 931844128
I0608 12:20:22.836426 30581 layer_factory.hpp:77] Creating layer conv6_1
I0608 12:20:22.836450 30581 net.cpp:100] Creating Layer conv6_1
I0608 12:20:22.836453 30581 net.cpp:434] conv6_1 <- fc7_relu7_0_split_0
I0608 12:20:22.836460 30581 net.cpp:408] conv6_1 -> conv6_1
I0608 12:20:22.839754 30581 net.cpp:150] Setting up conv6_1
I0608 12:20:22.839766 30581 net.cpp:157] Top shape: 4 256 19 19 (369664)
I0608 12:20:22.839769 30581 net.cpp:165] Memory required for data: 933322784
I0608 12:20:22.839776 30581 layer_factory.hpp:77] Creating layer conv6_1_relu
I0608 12:20:22.839799 30581 net.cpp:100] Creating Layer conv6_1_relu
I0608 12:20:22.839804 30581 net.cpp:434] conv6_1_relu <- conv6_1
I0608 12:20:22.839808 30581 net.cpp:395] conv6_1_relu -> conv6_1 (in-place)
I0608 12:20:22.839967 30581 net.cpp:150] Setting up conv6_1_relu
I0608 12:20:22.839973 30581 net.cpp:157] Top shape: 4 256 19 19 (369664)
I0608 12:20:22.839977 30581 net.cpp:165] Memory required for data: 934801440
I0608 12:20:22.839979 30581 layer_factory.hpp:77] Creating layer conv6_2
I0608 12:20:22.840004 30581 net.cpp:100] Creating Layer conv6_2
I0608 12:20:22.840008 30581 net.cpp:434] conv6_2 <- conv6_1
I0608 12:20:22.840013 30581 net.cpp:408] conv6_2 -> conv6_2
I0608 12:20:22.847237 30581 net.cpp:150] Setting up conv6_2
I0608 12:20:22.847255 30581 net.cpp:157] Top shape: 4 512 10 10 (204800)
I0608 12:20:22.847259 30581 net.cpp:165] Memory required for data: 935620640
I0608 12:20:22.847285 30581 layer_factory.hpp:77] Creating layer conv6_2_relu
I0608 12:20:22.847295 30581 net.cpp:100] Creating Layer conv6_2_relu
I0608 12:20:22.847299 30581 net.cpp:434] conv6_2_relu <- conv6_2
I0608 12:20:22.847304 30581 net.cpp:395] conv6_2_relu -> conv6_2 (in-place)
I0608 12:20:22.847467 30581 net.cpp:150] Setting up conv6_2_relu
I0608 12:20:22.847474 30581 net.cpp:157] Top shape: 4 512 10 10 (204800)
I0608 12:20:22.847476 30581 net.cpp:165] Memory required for data: 936439840
I0608 12:20:22.847479 30581 layer_factory.hpp:77] Creating layer conv6_2_conv6_2_relu_0_split
I0608 12:20:22.847486 30581 net.cpp:100] Creating Layer conv6_2_conv6_2_relu_0_split
I0608 12:20:22.847498 30581 net.cpp:434] conv6_2_conv6_2_relu_0_split <- conv6_2
I0608 12:20:22.847504 30581 net.cpp:408] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_0
I0608 12:20:22.847510 30581 net.cpp:408] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_1
I0608 12:20:22.847530 30581 net.cpp:408] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_2
I0608 12:20:22.847550 30581 net.cpp:408] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_3
I0608 12:20:22.847615 30581 net.cpp:150] Setting up conv6_2_conv6_2_relu_0_split
I0608 12:20:22.847620 30581 net.cpp:157] Top shape: 4 512 10 10 (204800)
I0608 12:20:22.847623 30581 net.cpp:157] Top shape: 4 512 10 10 (204800)
I0608 12:20:22.847627 30581 net.cpp:157] Top shape: 4 512 10 10 (204800)
I0608 12:20:22.847631 30581 net.cpp:157] Top shape: 4 512 10 10 (204800)
I0608 12:20:22.847635 30581 net.cpp:165] Memory required for data: 939716640
I0608 12:20:22.847638 30581 layer_factory.hpp:77] Creating layer conv7_1
I0608 12:20:22.847648 30581 net.cpp:100] Creating Layer conv7_1
I0608 12:20:22.847666 30581 net.cpp:434] conv7_1 <- conv6_2_conv6_2_relu_0_split_0
I0608 12:20:22.847672 30581 net.cpp:408] conv7_1 -> conv7_1
I0608 12:20:22.849119 30581 net.cpp:150] Setting up conv7_1
I0608 12:20:22.849128 30581 net.cpp:157] Top shape: 4 128 10 10 (51200)
I0608 12:20:22.849131 30581 net.cpp:165] Memory required for data: 939921440
I0608 12:20:22.849138 30581 layer_factory.hpp:77] Creating layer conv7_1_relu
I0608 12:20:22.849146 30581 net.cpp:100] Creating Layer conv7_1_relu
I0608 12:20:22.849150 30581 net.cpp:434] conv7_1_relu <- conv7_1
I0608 12:20:22.849155 30581 net.cpp:395] conv7_1_relu -> conv7_1 (in-place)
I0608 12:20:22.849318 30581 net.cpp:150] Setting up conv7_1_relu
I0608 12:20:22.849328 30581 net.cpp:157] Top shape: 4 128 10 10 (51200)
I0608 12:20:22.849330 30581 net.cpp:165] Memory required for data: 940126240
I0608 12:20:22.849333 30581 layer_factory.hpp:77] Creating layer conv7_2
I0608 12:20:22.849339 30581 net.cpp:100] Creating Layer conv7_2
I0608 12:20:22.849344 30581 net.cpp:434] conv7_2 <- conv7_1
I0608 12:20:22.849364 30581 net.cpp:408] conv7_2 -> conv7_2
I0608 12:20:22.852290 30581 net.cpp:150] Setting up conv7_2
I0608 12:20:22.852301 30581 net.cpp:157] Top shape: 4 256 5 5 (25600)
I0608 12:20:22.852304 30581 net.cpp:165] Memory required for data: 940228640
I0608 12:20:22.852308 30581 layer_factory.hpp:77] Creating layer conv7_2_relu
I0608 12:20:22.852313 30581 net.cpp:100] Creating Layer conv7_2_relu
I0608 12:20:22.852316 30581 net.cpp:434] conv7_2_relu <- conv7_2
I0608 12:20:22.852321 30581 net.cpp:395] conv7_2_relu -> conv7_2 (in-place)
I0608 12:20:22.852453 30581 net.cpp:150] Setting up conv7_2_relu
I0608 12:20:22.852460 30581 net.cpp:157] Top shape: 4 256 5 5 (25600)
I0608 12:20:22.852463 30581 net.cpp:165] Memory required for data: 940331040
I0608 12:20:22.852466 30581 layer_factory.hpp:77] Creating layer conv7_2_conv7_2_relu_0_split
I0608 12:20:22.852473 30581 net.cpp:100] Creating Layer conv7_2_conv7_2_relu_0_split
I0608 12:20:22.852478 30581 net.cpp:434] conv7_2_conv7_2_relu_0_split <- conv7_2
I0608 12:20:22.852481 30581 net.cpp:408] conv7_2_conv7_2_relu_0_split -> conv7_2_conv7_2_relu_0_split_0
I0608 12:20:22.852490 30581 net.cpp:408] conv7_2_conv7_2_relu_0_split -> conv7_2_conv7_2_relu_0_split_1
I0608 12:20:22.852497 30581 net.cpp:408] conv7_2_conv7_2_relu_0_split -> conv7_2_conv7_2_relu_0_split_2
I0608 12:20:22.852501 30581 net.cpp:408] conv7_2_conv7_2_relu_0_split -> conv7_2_conv7_2_relu_0_split_3
I0608 12:20:22.852563 30581 net.cpp:150] Setting up conv7_2_conv7_2_relu_0_split
I0608 12:20:22.852568 30581 net.cpp:157] Top shape: 4 256 5 5 (25600)
I0608 12:20:22.852571 30581 net.cpp:157] Top shape: 4 256 5 5 (25600)
I0608 12:20:22.852574 30581 net.cpp:157] Top shape: 4 256 5 5 (25600)
I0608 12:20:22.852576 30581 net.cpp:157] Top shape: 4 256 5 5 (25600)
I0608 12:20:22.852578 30581 net.cpp:165] Memory required for data: 940740640
I0608 12:20:22.852581 30581 layer_factory.hpp:77] Creating layer conv8_1
I0608 12:20:22.852597 30581 net.cpp:100] Creating Layer conv8_1
I0608 12:20:22.852602 30581 net.cpp:434] conv8_1 <- conv7_2_conv7_2_relu_0_split_0
I0608 12:20:22.852607 30581 net.cpp:408] conv8_1 -> conv8_1
I0608 12:20:22.853827 30581 net.cpp:150] Setting up conv8_1
I0608 12:20:22.853837 30581 net.cpp:157] Top shape: 4 128 5 5 (12800)
I0608 12:20:22.853839 30581 net.cpp:165] Memory required for data: 940791840
I0608 12:20:22.853844 30581 layer_factory.hpp:77] Creating layer conv8_1_relu
I0608 12:20:22.853849 30581 net.cpp:100] Creating Layer conv8_1_relu
I0608 12:20:22.853852 30581 net.cpp:434] conv8_1_relu <- conv8_1
I0608 12:20:22.853857 30581 net.cpp:395] conv8_1_relu -> conv8_1 (in-place)
I0608 12:20:22.854434 30581 net.cpp:150] Setting up conv8_1_relu
I0608 12:20:22.854442 30581 net.cpp:157] Top shape: 4 128 5 5 (12800)
I0608 12:20:22.854444 30581 net.cpp:165] Memory required for data: 940843040
I0608 12:20:22.854446 30581 layer_factory.hpp:77] Creating layer conv8_2
I0608 12:20:22.854454 30581 net.cpp:100] Creating Layer conv8_2
I0608 12:20:22.854456 30581 net.cpp:434] conv8_2 <- conv8_1
I0608 12:20:22.854462 30581 net.cpp:408] conv8_2 -> conv8_2
I0608 12:20:22.857385 30581 net.cpp:150] Setting up conv8_2
I0608 12:20:22.857398 30581 net.cpp:157] Top shape: 4 256 3 3 (9216)
I0608 12:20:22.857400 30581 net.cpp:165] Memory required for data: 940879904
I0608 12:20:22.857404 30581 layer_factory.hpp:77] Creating layer conv8_2_relu
I0608 12:20:22.857409 30581 net.cpp:100] Creating Layer conv8_2_relu
I0608 12:20:22.857414 30581 net.cpp:434] conv8_2_relu <- conv8_2
I0608 12:20:22.857417 30581 net.cpp:395] conv8_2_relu -> conv8_2 (in-place)
I0608 12:20:22.857548 30581 net.cpp:150] Setting up conv8_2_relu
I0608 12:20:22.857554 30581 net.cpp:157] Top shape: 4 256 3 3 (9216)
I0608 12:20:22.857558 30581 net.cpp:165] Memory required for data: 940916768
I0608 12:20:22.857559 30581 layer_factory.hpp:77] Creating layer conv8_2_conv8_2_relu_0_split
I0608 12:20:22.857563 30581 net.cpp:100] Creating Layer conv8_2_conv8_2_relu_0_split
I0608 12:20:22.857566 30581 net.cpp:434] conv8_2_conv8_2_relu_0_split <- conv8_2
I0608 12:20:22.857570 30581 net.cpp:408] conv8_2_conv8_2_relu_0_split -> conv8_2_conv8_2_relu_0_split_0
I0608 12:20:22.857576 30581 net.cpp:408] conv8_2_conv8_2_relu_0_split -> conv8_2_conv8_2_relu_0_split_1
I0608 12:20:22.857583 30581 net.cpp:408] conv8_2_conv8_2_relu_0_split -> conv8_2_conv8_2_relu_0_split_2
I0608 12:20:22.857586 30581 net.cpp:408] conv8_2_conv8_2_relu_0_split -> conv8_2_conv8_2_relu_0_split_3
I0608 12:20:22.857646 30581 net.cpp:150] Setting up conv8_2_conv8_2_relu_0_split
I0608 12:20:22.857651 30581 net.cpp:157] Top shape: 4 256 3 3 (9216)
I0608 12:20:22.857655 30581 net.cpp:157] Top shape: 4 256 3 3 (9216)
I0608 12:20:22.857656 30581 net.cpp:157] Top shape: 4 256 3 3 (9216)
I0608 12:20:22.857659 30581 net.cpp:157] Top shape: 4 256 3 3 (9216)
I0608 12:20:22.857661 30581 net.cpp:165] Memory required for data: 941064224
I0608 12:20:22.857663 30581 layer_factory.hpp:77] Creating layer conv9_1
I0608 12:20:22.857673 30581 net.cpp:100] Creating Layer conv9_1
I0608 12:20:22.857679 30581 net.cpp:434] conv9_1 <- conv8_2_conv8_2_relu_0_split_0
I0608 12:20:22.857686 30581 net.cpp:408] conv9_1 -> conv9_1
I0608 12:20:22.858904 30581 net.cpp:150] Setting up conv9_1
I0608 12:20:22.858913 30581 net.cpp:157] Top shape: 4 128 3 3 (4608)
I0608 12:20:22.858916 30581 net.cpp:165] Memory required for data: 941082656
I0608 12:20:22.858923 30581 layer_factory.hpp:77] Creating layer conv9_1_relu
I0608 12:20:22.858928 30581 net.cpp:100] Creating Layer conv9_1_relu
I0608 12:20:22.858932 30581 net.cpp:434] conv9_1_relu <- conv9_1
I0608 12:20:22.858938 30581 net.cpp:395] conv9_1_relu -> conv9_1 (in-place)
I0608 12:20:22.859071 30581 net.cpp:150] Setting up conv9_1_relu
I0608 12:20:22.859077 30581 net.cpp:157] Top shape: 4 128 3 3 (4608)
I0608 12:20:22.859079 30581 net.cpp:165] Memory required for data: 941101088
I0608 12:20:22.859082 30581 layer_factory.hpp:77] Creating layer conv9_2
I0608 12:20:22.859100 30581 net.cpp:100] Creating Layer conv9_2
I0608 12:20:22.859104 30581 net.cpp:434] conv9_2 <- conv9_1
I0608 12:20:22.859110 30581 net.cpp:408] conv9_2 -> conv9_2
I0608 12:20:22.862525 30581 net.cpp:150] Setting up conv9_2
I0608 12:20:22.862571 30581 net.cpp:157] Top shape: 4 256 1 1 (1024)
I0608 12:20:22.862574 30581 net.cpp:165] Memory required for data: 941105184
I0608 12:20:22.862584 30581 layer_factory.hpp:77] Creating layer conv9_2_relu
I0608 12:20:22.862609 30581 net.cpp:100] Creating Layer conv9_2_relu
I0608 12:20:22.862617 30581 net.cpp:434] conv9_2_relu <- conv9_2
I0608 12:20:22.862624 30581 net.cpp:395] conv9_2_relu -> conv9_2 (in-place)
I0608 12:20:22.862784 30581 net.cpp:150] Setting up conv9_2_relu
I0608 12:20:22.862792 30581 net.cpp:157] Top shape: 4 256 1 1 (1024)
I0608 12:20:22.862797 30581 net.cpp:165] Memory required for data: 941109280
I0608 12:20:22.862800 30581 layer_factory.hpp:77] Creating layer conv9_2_conv9_2_relu_0_split
I0608 12:20:22.862808 30581 net.cpp:100] Creating Layer conv9_2_conv9_2_relu_0_split
I0608 12:20:22.862813 30581 net.cpp:434] conv9_2_conv9_2_relu_0_split <- conv9_2
I0608 12:20:22.862820 30581 net.cpp:408] conv9_2_conv9_2_relu_0_split -> conv9_2_conv9_2_relu_0_split_0
I0608 12:20:22.862828 30581 net.cpp:408] conv9_2_conv9_2_relu_0_split -> conv9_2_conv9_2_relu_0_split_1
I0608 12:20:22.862833 30581 net.cpp:408] conv9_2_conv9_2_relu_0_split -> conv9_2_conv9_2_relu_0_split_2
I0608 12:20:22.862900 30581 net.cpp:150] Setting up conv9_2_conv9_2_relu_0_split
I0608 12:20:22.862905 30581 net.cpp:157] Top shape: 4 256 1 1 (1024)
I0608 12:20:22.862907 30581 net.cpp:157] Top shape: 4 256 1 1 (1024)
I0608 12:20:22.862910 30581 net.cpp:157] Top shape: 4 256 1 1 (1024)
I0608 12:20:22.862911 30581 net.cpp:165] Memory required for data: 941121568
I0608 12:20:22.862915 30581 layer_factory.hpp:77] Creating layer conv4_3_norm
I0608 12:20:22.862922 30581 net.cpp:100] Creating Layer conv4_3_norm
I0608 12:20:22.862926 30581 net.cpp:434] conv4_3_norm <- conv4_3_relu4_3_0_split_1
I0608 12:20:22.862931 30581 net.cpp:408] conv4_3_norm -> conv4_3_norm
I0608 12:20:22.863082 30581 net.cpp:150] Setting up conv4_3_norm
I0608 12:20:22.863088 30581 net.cpp:157] Top shape: 4 512 38 38 (2957312)
I0608 12:20:22.863091 30581 net.cpp:165] Memory required for data: 952950816
I0608 12:20:22.863096 30581 layer_factory.hpp:77] Creating layer conv4_3_norm_conv4_3_norm_0_split
I0608 12:20:22.863102 30581 net.cpp:100] Creating Layer conv4_3_norm_conv4_3_norm_0_split
I0608 12:20:22.863106 30581 net.cpp:434] conv4_3_norm_conv4_3_norm_0_split <- conv4_3_norm
I0608 12:20:22.863112 30581 net.cpp:408] conv4_3_norm_conv4_3_norm_0_split -> conv4_3_norm_conv4_3_norm_0_split_0
I0608 12:20:22.863119 30581 net.cpp:408] conv4_3_norm_conv4_3_norm_0_split -> conv4_3_norm_conv4_3_norm_0_split_1
I0608 12:20:22.863126 30581 net.cpp:408] conv4_3_norm_conv4_3_norm_0_split -> conv4_3_norm_conv4_3_norm_0_split_2
I0608 12:20:22.863170 30581 net.cpp:150] Setting up conv4_3_norm_conv4_3_norm_0_split
I0608 12:20:22.863176 30581 net.cpp:157] Top shape: 4 512 38 38 (2957312)
I0608 12:20:22.863180 30581 net.cpp:157] Top shape: 4 512 38 38 (2957312)
I0608 12:20:22.863185 30581 net.cpp:157] Top shape: 4 512 38 38 (2957312)
I0608 12:20:22.863189 30581 net.cpp:165] Memory required for data: 988438560
I0608 12:20:22.863193 30581 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_loc
I0608 12:20:22.863204 30581 net.cpp:100] Creating Layer conv4_3_norm_mbox_loc
I0608 12:20:22.863210 30581 net.cpp:434] conv4_3_norm_mbox_loc <- conv4_3_norm_conv4_3_norm_0_split_0
I0608 12:20:22.863219 30581 net.cpp:408] conv4_3_norm_mbox_loc -> conv4_3_norm_mbox_loc
I0608 12:20:22.865151 30581 net.cpp:150] Setting up conv4_3_norm_mbox_loc
I0608 12:20:22.865160 30581 net.cpp:157] Top shape: 4 16 38 38 (92416)
I0608 12:20:22.865165 30581 net.cpp:165] Memory required for data: 988808224
I0608 12:20:22.865173 30581 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_loc_perm
I0608 12:20:22.865185 30581 net.cpp:100] Creating Layer conv4_3_norm_mbox_loc_perm
I0608 12:20:22.865201 30581 net.cpp:434] conv4_3_norm_mbox_loc_perm <- conv4_3_norm_mbox_loc
I0608 12:20:22.865211 30581 net.cpp:408] conv4_3_norm_mbox_loc_perm -> conv4_3_norm_mbox_loc_perm
I0608 12:20:22.865329 30581 net.cpp:150] Setting up conv4_3_norm_mbox_loc_perm
I0608 12:20:22.865336 30581 net.cpp:157] Top shape: 4 38 38 16 (92416)
I0608 12:20:22.865339 30581 net.cpp:165] Memory required for data: 989177888
I0608 12:20:22.865345 30581 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_loc_flat
I0608 12:20:22.865352 30581 net.cpp:100] Creating Layer conv4_3_norm_mbox_loc_flat
I0608 12:20:22.865357 30581 net.cpp:434] conv4_3_norm_mbox_loc_flat <- conv4_3_norm_mbox_loc_perm
I0608 12:20:22.865363 30581 net.cpp:408] conv4_3_norm_mbox_loc_flat -> conv4_3_norm_mbox_loc_flat
I0608 12:20:22.865401 30581 net.cpp:150] Setting up conv4_3_norm_mbox_loc_flat
I0608 12:20:22.865407 30581 net.cpp:157] Top shape: 4 23104 (92416)
I0608 12:20:22.865411 30581 net.cpp:165] Memory required for data: 989547552
I0608 12:20:22.865413 30581 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_conf
I0608 12:20:22.865432 30581 net.cpp:100] Creating Layer conv4_3_norm_mbox_conf
I0608 12:20:22.865437 30581 net.cpp:434] conv4_3_norm_mbox_conf <- conv4_3_norm_conv4_3_norm_0_split_1
I0608 12:20:22.865442 30581 net.cpp:408] conv4_3_norm_mbox_conf -> conv4_3_norm_mbox_conf
I0608 12:20:22.867163 30581 net.cpp:150] Setting up conv4_3_norm_mbox_conf
I0608 12:20:22.867173 30581 net.cpp:157] Top shape: 4 8 38 38 (46208)
I0608 12:20:22.867177 30581 net.cpp:165] Memory required for data: 989732384
I0608 12:20:22.867183 30581 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_conf_perm
I0608 12:20:22.867190 30581 net.cpp:100] Creating Layer conv4_3_norm_mbox_conf_perm
I0608 12:20:22.867197 30581 net.cpp:434] conv4_3_norm_mbox_conf_perm <- conv4_3_norm_mbox_conf
I0608 12:20:22.867205 30581 net.cpp:408] conv4_3_norm_mbox_conf_perm -> conv4_3_norm_mbox_conf_perm
I0608 12:20:22.867311 30581 net.cpp:150] Setting up conv4_3_norm_mbox_conf_perm
I0608 12:20:22.867317 30581 net.cpp:157] Top shape: 4 38 38 8 (46208)
I0608 12:20:22.867321 30581 net.cpp:165] Memory required for data: 989917216
I0608 12:20:22.867323 30581 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_conf_flat
I0608 12:20:22.867328 30581 net.cpp:100] Creating Layer conv4_3_norm_mbox_conf_flat
I0608 12:20:22.867332 30581 net.cpp:434] conv4_3_norm_mbox_conf_flat <- conv4_3_norm_mbox_conf_perm
I0608 12:20:22.867341 30581 net.cpp:408] conv4_3_norm_mbox_conf_flat -> conv4_3_norm_mbox_conf_flat
I0608 12:20:22.867370 30581 net.cpp:150] Setting up conv4_3_norm_mbox_conf_flat
I0608 12:20:22.867375 30581 net.cpp:157] Top shape: 4 11552 (46208)
I0608 12:20:22.867378 30581 net.cpp:165] Memory required for data: 990102048
I0608 12:20:22.867383 30581 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_priorbox
I0608 12:20:22.867390 30581 net.cpp:100] Creating Layer conv4_3_norm_mbox_priorbox
I0608 12:20:22.867396 30581 net.cpp:434] conv4_3_norm_mbox_priorbox <- conv4_3_norm_conv4_3_norm_0_split_2
I0608 12:20:22.867403 30581 net.cpp:434] conv4_3_norm_mbox_priorbox <- data_data_0_split_1
I0608 12:20:22.867411 30581 net.cpp:408] conv4_3_norm_mbox_priorbox -> conv4_3_norm_mbox_priorbox
I0608 12:20:22.867442 30581 net.cpp:150] Setting up conv4_3_norm_mbox_priorbox
I0608 12:20:22.867449 30581 net.cpp:157] Top shape: 1 2 23104 (46208)
I0608 12:20:22.867452 30581 net.cpp:165] Memory required for data: 990286880
I0608 12:20:22.867456 30581 layer_factory.hpp:77] Creating layer fc7_mbox_loc
I0608 12:20:22.867465 30581 net.cpp:100] Creating Layer fc7_mbox_loc
I0608 12:20:22.867470 30581 net.cpp:434] fc7_mbox_loc <- fc7_relu7_0_split_1
I0608 12:20:22.867477 30581 net.cpp:408] fc7_mbox_loc -> fc7_mbox_loc
I0608 12:20:22.869997 30581 net.cpp:150] Setting up fc7_mbox_loc
I0608 12:20:22.870009 30581 net.cpp:157] Top shape: 4 24 19 19 (34656)
I0608 12:20:22.870012 30581 net.cpp:165] Memory required for data: 990425504
I0608 12:20:22.870020 30581 layer_factory.hpp:77] Creating layer fc7_mbox_loc_perm
I0608 12:20:22.870052 30581 net.cpp:100] Creating Layer fc7_mbox_loc_perm
I0608 12:20:22.870057 30581 net.cpp:434] fc7_mbox_loc_perm <- fc7_mbox_loc
I0608 12:20:22.870064 30581 net.cpp:408] fc7_mbox_loc_perm -> fc7_mbox_loc_perm
I0608 12:20:22.870183 30581 net.cpp:150] Setting up fc7_mbox_loc_perm
I0608 12:20:22.870189 30581 net.cpp:157] Top shape: 4 19 19 24 (34656)
I0608 12:20:22.870192 30581 net.cpp:165] Memory required for data: 990564128
I0608 12:20:22.870193 30581 layer_factory.hpp:77] Creating layer fc7_mbox_loc_flat
I0608 12:20:22.870198 30581 net.cpp:100] Creating Layer fc7_mbox_loc_flat
I0608 12:20:22.870203 30581 net.cpp:434] fc7_mbox_loc_flat <- fc7_mbox_loc_perm
I0608 12:20:22.870206 30581 net.cpp:408] fc7_mbox_loc_flat -> fc7_mbox_loc_flat
I0608 12:20:22.870226 30581 net.cpp:150] Setting up fc7_mbox_loc_flat
I0608 12:20:22.870230 30581 net.cpp:157] Top shape: 4 8664 (34656)
I0608 12:20:22.870232 30581 net.cpp:165] Memory required for data: 990702752
I0608 12:20:22.870234 30581 layer_factory.hpp:77] Creating layer fc7_mbox_conf
I0608 12:20:22.870244 30581 net.cpp:100] Creating Layer fc7_mbox_conf
I0608 12:20:22.870247 30581 net.cpp:434] fc7_mbox_conf <- fc7_relu7_0_split_2
I0608 12:20:22.870251 30581 net.cpp:408] fc7_mbox_conf -> fc7_mbox_conf
I0608 12:20:22.872331 30581 net.cpp:150] Setting up fc7_mbox_conf
I0608 12:20:22.872341 30581 net.cpp:157] Top shape: 4 12 19 19 (17328)
I0608 12:20:22.872344 30581 net.cpp:165] Memory required for data: 990772064
I0608 12:20:22.872349 30581 layer_factory.hpp:77] Creating layer fc7_mbox_conf_perm
I0608 12:20:22.872354 30581 net.cpp:100] Creating Layer fc7_mbox_conf_perm
I0608 12:20:22.872356 30581 net.cpp:434] fc7_mbox_conf_perm <- fc7_mbox_conf
I0608 12:20:22.872361 30581 net.cpp:408] fc7_mbox_conf_perm -> fc7_mbox_conf_perm
I0608 12:20:22.872462 30581 net.cpp:150] Setting up fc7_mbox_conf_perm
I0608 12:20:22.872467 30581 net.cpp:157] Top shape: 4 19 19 12 (17328)
I0608 12:20:22.872469 30581 net.cpp:165] Memory required for data: 990841376
I0608 12:20:22.872472 30581 layer_factory.hpp:77] Creating layer fc7_mbox_conf_flat
I0608 12:20:22.872476 30581 net.cpp:100] Creating Layer fc7_mbox_conf_flat
I0608 12:20:22.872478 30581 net.cpp:434] fc7_mbox_conf_flat <- fc7_mbox_conf_perm
I0608 12:20:22.872483 30581 net.cpp:408] fc7_mbox_conf_flat -> fc7_mbox_conf_flat
I0608 12:20:22.872503 30581 net.cpp:150] Setting up fc7_mbox_conf_flat
I0608 12:20:22.872508 30581 net.cpp:157] Top shape: 4 4332 (17328)
I0608 12:20:22.872509 30581 net.cpp:165] Memory required for data: 990910688
I0608 12:20:22.872511 30581 layer_factory.hpp:77] Creating layer fc7_mbox_priorbox
I0608 12:20:22.872517 30581 net.cpp:100] Creating Layer fc7_mbox_priorbox
I0608 12:20:22.872520 30581 net.cpp:434] fc7_mbox_priorbox <- fc7_relu7_0_split_3
I0608 12:20:22.872524 30581 net.cpp:434] fc7_mbox_priorbox <- data_data_0_split_2
I0608 12:20:22.872529 30581 net.cpp:408] fc7_mbox_priorbox -> fc7_mbox_priorbox
I0608 12:20:22.872553 30581 net.cpp:150] Setting up fc7_mbox_priorbox
I0608 12:20:22.872558 30581 net.cpp:157] Top shape: 1 2 8664 (17328)
I0608 12:20:22.872560 30581 net.cpp:165] Memory required for data: 990980000
I0608 12:20:22.872562 30581 layer_factory.hpp:77] Creating layer conv6_2_mbox_loc
I0608 12:20:22.872570 30581 net.cpp:100] Creating Layer conv6_2_mbox_loc
I0608 12:20:22.872576 30581 net.cpp:434] conv6_2_mbox_loc <- conv6_2_conv6_2_relu_0_split_1
I0608 12:20:22.872583 30581 net.cpp:408] conv6_2_mbox_loc -> conv6_2_mbox_loc
I0608 12:20:22.874603 30581 net.cpp:150] Setting up conv6_2_mbox_loc
I0608 12:20:22.874611 30581 net.cpp:157] Top shape: 4 24 10 10 (9600)
I0608 12:20:22.874615 30581 net.cpp:165] Memory required for data: 991018400
I0608 12:20:22.874622 30581 layer_factory.hpp:77] Creating layer conv6_2_mbox_loc_perm
I0608 12:20:22.874629 30581 net.cpp:100] Creating Layer conv6_2_mbox_loc_perm
I0608 12:20:22.874634 30581 net.cpp:434] conv6_2_mbox_loc_perm <- conv6_2_mbox_loc
I0608 12:20:22.874641 30581 net.cpp:408] conv6_2_mbox_loc_perm -> conv6_2_mbox_loc_perm
I0608 12:20:22.874744 30581 net.cpp:150] Setting up conv6_2_mbox_loc_perm
I0608 12:20:22.874759 30581 net.cpp:157] Top shape: 4 10 10 24 (9600)
I0608 12:20:22.874763 30581 net.cpp:165] Memory required for data: 991056800
I0608 12:20:22.874766 30581 layer_factory.hpp:77] Creating layer conv6_2_mbox_loc_flat
I0608 12:20:22.874773 30581 net.cpp:100] Creating Layer conv6_2_mbox_loc_flat
I0608 12:20:22.874776 30581 net.cpp:434] conv6_2_mbox_loc_flat <- conv6_2_mbox_loc_perm
I0608 12:20:22.874784 30581 net.cpp:408] conv6_2_mbox_loc_flat -> conv6_2_mbox_loc_flat
I0608 12:20:22.874809 30581 net.cpp:150] Setting up conv6_2_mbox_loc_flat
I0608 12:20:22.874814 30581 net.cpp:157] Top shape: 4 2400 (9600)
I0608 12:20:22.874817 30581 net.cpp:165] Memory required for data: 991095200
I0608 12:20:22.874820 30581 layer_factory.hpp:77] Creating layer conv6_2_mbox_conf
I0608 12:20:22.874831 30581 net.cpp:100] Creating Layer conv6_2_mbox_conf
I0608 12:20:22.874835 30581 net.cpp:434] conv6_2_mbox_conf <- conv6_2_conv6_2_relu_0_split_2
I0608 12:20:22.874841 30581 net.cpp:408] conv6_2_mbox_conf -> conv6_2_mbox_conf
I0608 12:20:22.876652 30581 net.cpp:150] Setting up conv6_2_mbox_conf
I0608 12:20:22.876660 30581 net.cpp:157] Top shape: 4 12 10 10 (4800)
I0608 12:20:22.876663 30581 net.cpp:165] Memory required for data: 991114400
I0608 12:20:22.876667 30581 layer_factory.hpp:77] Creating layer conv6_2_mbox_conf_perm
I0608 12:20:22.876672 30581 net.cpp:100] Creating Layer conv6_2_mbox_conf_perm
I0608 12:20:22.876677 30581 net.cpp:434] conv6_2_mbox_conf_perm <- conv6_2_mbox_conf
I0608 12:20:22.876680 30581 net.cpp:408] conv6_2_mbox_conf_perm -> conv6_2_mbox_conf_perm
I0608 12:20:22.876783 30581 net.cpp:150] Setting up conv6_2_mbox_conf_perm
I0608 12:20:22.876790 30581 net.cpp:157] Top shape: 4 10 10 12 (4800)
I0608 12:20:22.876792 30581 net.cpp:165] Memory required for data: 991133600
I0608 12:20:22.876794 30581 layer_factory.hpp:77] Creating layer conv6_2_mbox_conf_flat
I0608 12:20:22.876798 30581 net.cpp:100] Creating Layer conv6_2_mbox_conf_flat
I0608 12:20:22.876801 30581 net.cpp:434] conv6_2_mbox_conf_flat <- conv6_2_mbox_conf_perm
I0608 12:20:22.876806 30581 net.cpp:408] conv6_2_mbox_conf_flat -> conv6_2_mbox_conf_flat
I0608 12:20:22.876824 30581 net.cpp:150] Setting up conv6_2_mbox_conf_flat
I0608 12:20:22.876829 30581 net.cpp:157] Top shape: 4 1200 (4800)
I0608 12:20:22.876830 30581 net.cpp:165] Memory required for data: 991152800
I0608 12:20:22.876833 30581 layer_factory.hpp:77] Creating layer conv6_2_mbox_priorbox
I0608 12:20:22.876838 30581 net.cpp:100] Creating Layer conv6_2_mbox_priorbox
I0608 12:20:22.876843 30581 net.cpp:434] conv6_2_mbox_priorbox <- conv6_2_conv6_2_relu_0_split_3
I0608 12:20:22.876848 30581 net.cpp:434] conv6_2_mbox_priorbox <- data_data_0_split_3
I0608 12:20:22.876857 30581 net.cpp:408] conv6_2_mbox_priorbox -> conv6_2_mbox_priorbox
I0608 12:20:22.876881 30581 net.cpp:150] Setting up conv6_2_mbox_priorbox
I0608 12:20:22.876886 30581 net.cpp:157] Top shape: 1 2 2400 (4800)
I0608 12:20:22.876890 30581 net.cpp:165] Memory required for data: 991172000
I0608 12:20:22.876894 30581 layer_factory.hpp:77] Creating layer conv7_2_mbox_loc
I0608 12:20:22.876904 30581 net.cpp:100] Creating Layer conv7_2_mbox_loc
I0608 12:20:22.876907 30581 net.cpp:434] conv7_2_mbox_loc <- conv7_2_conv7_2_relu_0_split_1
I0608 12:20:22.876914 30581 net.cpp:408] conv7_2_mbox_loc -> conv7_2_mbox_loc
I0608 12:20:22.878247 30581 net.cpp:150] Setting up conv7_2_mbox_loc
I0608 12:20:22.878254 30581 net.cpp:157] Top shape: 4 24 5 5 (2400)
I0608 12:20:22.878257 30581 net.cpp:165] Memory required for data: 991181600
I0608 12:20:22.878262 30581 layer_factory.hpp:77] Creating layer conv7_2_mbox_loc_perm
I0608 12:20:22.878268 30581 net.cpp:100] Creating Layer conv7_2_mbox_loc_perm
I0608 12:20:22.878270 30581 net.cpp:434] conv7_2_mbox_loc_perm <- conv7_2_mbox_loc
I0608 12:20:22.878274 30581 net.cpp:408] conv7_2_mbox_loc_perm -> conv7_2_mbox_loc_perm
I0608 12:20:22.878374 30581 net.cpp:150] Setting up conv7_2_mbox_loc_perm
I0608 12:20:22.878379 30581 net.cpp:157] Top shape: 4 5 5 24 (2400)
I0608 12:20:22.878391 30581 net.cpp:165] Memory required for data: 991191200
I0608 12:20:22.878394 30581 layer_factory.hpp:77] Creating layer conv7_2_mbox_loc_flat
I0608 12:20:22.878399 30581 net.cpp:100] Creating Layer conv7_2_mbox_loc_flat
I0608 12:20:22.878403 30581 net.cpp:434] conv7_2_mbox_loc_flat <- conv7_2_mbox_loc_perm
I0608 12:20:22.878410 30581 net.cpp:408] conv7_2_mbox_loc_flat -> conv7_2_mbox_loc_flat
I0608 12:20:22.878434 30581 net.cpp:150] Setting up conv7_2_mbox_loc_flat
I0608 12:20:22.878439 30581 net.cpp:157] Top shape: 4 600 (2400)
I0608 12:20:22.878443 30581 net.cpp:165] Memory required for data: 991200800
I0608 12:20:22.878448 30581 layer_factory.hpp:77] Creating layer conv7_2_mbox_conf
I0608 12:20:22.878455 30581 net.cpp:100] Creating Layer conv7_2_mbox_conf
I0608 12:20:22.878459 30581 net.cpp:434] conv7_2_mbox_conf <- conv7_2_conv7_2_relu_0_split_2
I0608 12:20:22.878465 30581 net.cpp:408] conv7_2_mbox_conf -> conv7_2_mbox_conf
I0608 12:20:22.880129 30581 net.cpp:150] Setting up conv7_2_mbox_conf
I0608 12:20:22.880138 30581 net.cpp:157] Top shape: 4 12 5 5 (1200)
I0608 12:20:22.880141 30581 net.cpp:165] Memory required for data: 991205600
I0608 12:20:22.880146 30581 layer_factory.hpp:77] Creating layer conv7_2_mbox_conf_perm
I0608 12:20:22.880151 30581 net.cpp:100] Creating Layer conv7_2_mbox_conf_perm
I0608 12:20:22.880154 30581 net.cpp:434] conv7_2_mbox_conf_perm <- conv7_2_mbox_conf
I0608 12:20:22.880159 30581 net.cpp:408] conv7_2_mbox_conf_perm -> conv7_2_mbox_conf_perm
I0608 12:20:22.880259 30581 net.cpp:150] Setting up conv7_2_mbox_conf_perm
I0608 12:20:22.880264 30581 net.cpp:157] Top shape: 4 5 5 12 (1200)
I0608 12:20:22.880266 30581 net.cpp:165] Memory required for data: 991210400
I0608 12:20:22.880269 30581 layer_factory.hpp:77] Creating layer conv7_2_mbox_conf_flat
I0608 12:20:22.880272 30581 net.cpp:100] Creating Layer conv7_2_mbox_conf_flat
I0608 12:20:22.880275 30581 net.cpp:434] conv7_2_mbox_conf_flat <- conv7_2_mbox_conf_perm
I0608 12:20:22.880278 30581 net.cpp:408] conv7_2_mbox_conf_flat -> conv7_2_mbox_conf_flat
I0608 12:20:22.880298 30581 net.cpp:150] Setting up conv7_2_mbox_conf_flat
I0608 12:20:22.880303 30581 net.cpp:157] Top shape: 4 300 (1200)
I0608 12:20:22.880306 30581 net.cpp:165] Memory required for data: 991215200
I0608 12:20:22.880307 30581 layer_factory.hpp:77] Creating layer conv7_2_mbox_priorbox
I0608 12:20:22.880312 30581 net.cpp:100] Creating Layer conv7_2_mbox_priorbox
I0608 12:20:22.880316 30581 net.cpp:434] conv7_2_mbox_priorbox <- conv7_2_conv7_2_relu_0_split_3
I0608 12:20:22.880319 30581 net.cpp:434] conv7_2_mbox_priorbox <- data_data_0_split_4
I0608 12:20:22.880324 30581 net.cpp:408] conv7_2_mbox_priorbox -> conv7_2_mbox_priorbox
I0608 12:20:22.880347 30581 net.cpp:150] Setting up conv7_2_mbox_priorbox
I0608 12:20:22.880352 30581 net.cpp:157] Top shape: 1 2 600 (1200)
I0608 12:20:22.880353 30581 net.cpp:165] Memory required for data: 991220000
I0608 12:20:22.880355 30581 layer_factory.hpp:77] Creating layer conv8_2_mbox_loc
I0608 12:20:22.880363 30581 net.cpp:100] Creating Layer conv8_2_mbox_loc
I0608 12:20:22.880367 30581 net.cpp:434] conv8_2_mbox_loc <- conv8_2_conv8_2_relu_0_split_1
I0608 12:20:22.880373 30581 net.cpp:408] conv8_2_mbox_loc -> conv8_2_mbox_loc
I0608 12:20:22.882086 30581 net.cpp:150] Setting up conv8_2_mbox_loc
I0608 12:20:22.882095 30581 net.cpp:157] Top shape: 4 16 3 3 (576)
I0608 12:20:22.882099 30581 net.cpp:165] Memory required for data: 991222304
I0608 12:20:22.882113 30581 layer_factory.hpp:77] Creating layer conv8_2_mbox_loc_perm
I0608 12:20:22.882120 30581 net.cpp:100] Creating Layer conv8_2_mbox_loc_perm
I0608 12:20:22.882123 30581 net.cpp:434] conv8_2_mbox_loc_perm <- conv8_2_mbox_loc
I0608 12:20:22.882128 30581 net.cpp:408] conv8_2_mbox_loc_perm -> conv8_2_mbox_loc_perm
I0608 12:20:22.882231 30581 net.cpp:150] Setting up conv8_2_mbox_loc_perm
I0608 12:20:22.882236 30581 net.cpp:157] Top shape: 4 3 3 16 (576)
I0608 12:20:22.882238 30581 net.cpp:165] Memory required for data: 991224608
I0608 12:20:22.882241 30581 layer_factory.hpp:77] Creating layer conv8_2_mbox_loc_flat
I0608 12:20:22.882251 30581 net.cpp:100] Creating Layer conv8_2_mbox_loc_flat
I0608 12:20:22.882254 30581 net.cpp:434] conv8_2_mbox_loc_flat <- conv8_2_mbox_loc_perm
I0608 12:20:22.882259 30581 net.cpp:408] conv8_2_mbox_loc_flat -> conv8_2_mbox_loc_flat
I0608 12:20:22.882287 30581 net.cpp:150] Setting up conv8_2_mbox_loc_flat
I0608 12:20:22.882292 30581 net.cpp:157] Top shape: 4 144 (576)
I0608 12:20:22.882294 30581 net.cpp:165] Memory required for data: 991226912
I0608 12:20:22.882298 30581 layer_factory.hpp:77] Creating layer conv8_2_mbox_conf
I0608 12:20:22.882308 30581 net.cpp:100] Creating Layer conv8_2_mbox_conf
I0608 12:20:22.882313 30581 net.cpp:434] conv8_2_mbox_conf <- conv8_2_conv8_2_relu_0_split_2
I0608 12:20:22.882319 30581 net.cpp:408] conv8_2_mbox_conf -> conv8_2_mbox_conf
I0608 12:20:22.883960 30581 net.cpp:150] Setting up conv8_2_mbox_conf
I0608 12:20:22.883970 30581 net.cpp:157] Top shape: 4 8 3 3 (288)
I0608 12:20:22.883972 30581 net.cpp:165] Memory required for data: 991228064
I0608 12:20:22.883976 30581 layer_factory.hpp:77] Creating layer conv8_2_mbox_conf_perm
I0608 12:20:22.883982 30581 net.cpp:100] Creating Layer conv8_2_mbox_conf_perm
I0608 12:20:22.883986 30581 net.cpp:434] conv8_2_mbox_conf_perm <- conv8_2_mbox_conf
I0608 12:20:22.883991 30581 net.cpp:408] conv8_2_mbox_conf_perm -> conv8_2_mbox_conf_perm
I0608 12:20:22.884093 30581 net.cpp:150] Setting up conv8_2_mbox_conf_perm
I0608 12:20:22.884096 30581 net.cpp:157] Top shape: 4 3 3 8 (288)
I0608 12:20:22.884099 30581 net.cpp:165] Memory required for data: 991229216
I0608 12:20:22.884101 30581 layer_factory.hpp:77] Creating layer conv8_2_mbox_conf_flat
I0608 12:20:22.884105 30581 net.cpp:100] Creating Layer conv8_2_mbox_conf_flat
I0608 12:20:22.884109 30581 net.cpp:434] conv8_2_mbox_conf_flat <- conv8_2_mbox_conf_perm
I0608 12:20:22.884112 30581 net.cpp:408] conv8_2_mbox_conf_flat -> conv8_2_mbox_conf_flat
I0608 12:20:22.884133 30581 net.cpp:150] Setting up conv8_2_mbox_conf_flat
I0608 12:20:22.884137 30581 net.cpp:157] Top shape: 4 72 (288)
I0608 12:20:22.884140 30581 net.cpp:165] Memory required for data: 991230368
I0608 12:20:22.884141 30581 layer_factory.hpp:77] Creating layer conv8_2_mbox_priorbox
I0608 12:20:22.884146 30581 net.cpp:100] Creating Layer conv8_2_mbox_priorbox
I0608 12:20:22.884150 30581 net.cpp:434] conv8_2_mbox_priorbox <- conv8_2_conv8_2_relu_0_split_3
I0608 12:20:22.884152 30581 net.cpp:434] conv8_2_mbox_priorbox <- data_data_0_split_5
I0608 12:20:22.884156 30581 net.cpp:408] conv8_2_mbox_priorbox -> conv8_2_mbox_priorbox
I0608 12:20:22.884182 30581 net.cpp:150] Setting up conv8_2_mbox_priorbox
I0608 12:20:22.884187 30581 net.cpp:157] Top shape: 1 2 144 (288)
I0608 12:20:22.884191 30581 net.cpp:165] Memory required for data: 991231520
I0608 12:20:22.884196 30581 layer_factory.hpp:77] Creating layer conv9_2_mbox_loc
I0608 12:20:22.884205 30581 net.cpp:100] Creating Layer conv9_2_mbox_loc
I0608 12:20:22.884209 30581 net.cpp:434] conv9_2_mbox_loc <- conv9_2_conv9_2_relu_0_split_0
I0608 12:20:22.884217 30581 net.cpp:408] conv9_2_mbox_loc -> conv9_2_mbox_loc
I0608 12:20:22.886366 30581 net.cpp:150] Setting up conv9_2_mbox_loc
I0608 12:20:22.886374 30581 net.cpp:157] Top shape: 4 16 1 1 (64)
I0608 12:20:22.886378 30581 net.cpp:165] Memory required for data: 991231776
I0608 12:20:22.886381 30581 layer_factory.hpp:77] Creating layer conv9_2_mbox_loc_perm
I0608 12:20:22.886389 30581 net.cpp:100] Creating Layer conv9_2_mbox_loc_perm
I0608 12:20:22.886392 30581 net.cpp:434] conv9_2_mbox_loc_perm <- conv9_2_mbox_loc
I0608 12:20:22.886396 30581 net.cpp:408] conv9_2_mbox_loc_perm -> conv9_2_mbox_loc_perm
I0608 12:20:22.886494 30581 net.cpp:150] Setting up conv9_2_mbox_loc_perm
I0608 12:20:22.886500 30581 net.cpp:157] Top shape: 4 1 1 16 (64)
I0608 12:20:22.886502 30581 net.cpp:165] Memory required for data: 991232032
I0608 12:20:22.886504 30581 layer_factory.hpp:77] Creating layer conv9_2_mbox_loc_flat
I0608 12:20:22.886508 30581 net.cpp:100] Creating Layer conv9_2_mbox_loc_flat
I0608 12:20:22.886512 30581 net.cpp:434] conv9_2_mbox_loc_flat <- conv9_2_mbox_loc_perm
I0608 12:20:22.886523 30581 net.cpp:408] conv9_2_mbox_loc_flat -> conv9_2_mbox_loc_flat
I0608 12:20:22.886545 30581 net.cpp:150] Setting up conv9_2_mbox_loc_flat
I0608 12:20:22.886549 30581 net.cpp:157] Top shape: 4 16 (64)
I0608 12:20:22.886553 30581 net.cpp:165] Memory required for data: 991232288
I0608 12:20:22.886554 30581 layer_factory.hpp:77] Creating layer conv9_2_mbox_conf
I0608 12:20:22.886560 30581 net.cpp:100] Creating Layer conv9_2_mbox_conf
I0608 12:20:22.886564 30581 net.cpp:434] conv9_2_mbox_conf <- conv9_2_conv9_2_relu_0_split_1
I0608 12:20:22.886569 30581 net.cpp:408] conv9_2_mbox_conf -> conv9_2_mbox_conf
I0608 12:20:22.888208 30581 net.cpp:150] Setting up conv9_2_mbox_conf
I0608 12:20:22.888218 30581 net.cpp:157] Top shape: 4 8 1 1 (32)
I0608 12:20:22.888221 30581 net.cpp:165] Memory required for data: 991232416
I0608 12:20:22.888226 30581 layer_factory.hpp:77] Creating layer conv9_2_mbox_conf_perm
I0608 12:20:22.888229 30581 net.cpp:100] Creating Layer conv9_2_mbox_conf_perm
I0608 12:20:22.888234 30581 net.cpp:434] conv9_2_mbox_conf_perm <- conv9_2_mbox_conf
I0608 12:20:22.888242 30581 net.cpp:408] conv9_2_mbox_conf_perm -> conv9_2_mbox_conf_perm
I0608 12:20:22.888348 30581 net.cpp:150] Setting up conv9_2_mbox_conf_perm
I0608 12:20:22.888353 30581 net.cpp:157] Top shape: 4 1 1 8 (32)
I0608 12:20:22.888357 30581 net.cpp:165] Memory required for data: 991232544
I0608 12:20:22.888360 30581 layer_factory.hpp:77] Creating layer conv9_2_mbox_conf_flat
I0608 12:20:22.888368 30581 net.cpp:100] Creating Layer conv9_2_mbox_conf_flat
I0608 12:20:22.888372 30581 net.cpp:434] conv9_2_mbox_conf_flat <- conv9_2_mbox_conf_perm
I0608 12:20:22.888380 30581 net.cpp:408] conv9_2_mbox_conf_flat -> conv9_2_mbox_conf_flat
I0608 12:20:22.888402 30581 net.cpp:150] Setting up conv9_2_mbox_conf_flat
I0608 12:20:22.888407 30581 net.cpp:157] Top shape: 4 8 (32)
I0608 12:20:22.888411 30581 net.cpp:165] Memory required for data: 991232672
I0608 12:20:22.888414 30581 layer_factory.hpp:77] Creating layer conv9_2_mbox_priorbox
I0608 12:20:22.888423 30581 net.cpp:100] Creating Layer conv9_2_mbox_priorbox
I0608 12:20:22.888428 30581 net.cpp:434] conv9_2_mbox_priorbox <- conv9_2_conv9_2_relu_0_split_2
I0608 12:20:22.888432 30581 net.cpp:434] conv9_2_mbox_priorbox <- data_data_0_split_6
I0608 12:20:22.888439 30581 net.cpp:408] conv9_2_mbox_priorbox -> conv9_2_mbox_priorbox
I0608 12:20:22.888464 30581 net.cpp:150] Setting up conv9_2_mbox_priorbox
I0608 12:20:22.888469 30581 net.cpp:157] Top shape: 1 2 16 (32)
I0608 12:20:22.888473 30581 net.cpp:165] Memory required for data: 991232800
I0608 12:20:22.888476 30581 layer_factory.hpp:77] Creating layer mbox_loc
I0608 12:20:22.888484 30581 net.cpp:100] Creating Layer mbox_loc
I0608 12:20:22.888489 30581 net.cpp:434] mbox_loc <- conv4_3_norm_mbox_loc_flat
I0608 12:20:22.888495 30581 net.cpp:434] mbox_loc <- fc7_mbox_loc_flat
I0608 12:20:22.888501 30581 net.cpp:434] mbox_loc <- conv6_2_mbox_loc_flat
I0608 12:20:22.888506 30581 net.cpp:434] mbox_loc <- conv7_2_mbox_loc_flat
I0608 12:20:22.888512 30581 net.cpp:434] mbox_loc <- conv8_2_mbox_loc_flat
I0608 12:20:22.888516 30581 net.cpp:434] mbox_loc <- conv9_2_mbox_loc_flat
I0608 12:20:22.888525 30581 net.cpp:408] mbox_loc -> mbox_loc
I0608 12:20:22.888550 30581 net.cpp:150] Setting up mbox_loc
I0608 12:20:22.888555 30581 net.cpp:157] Top shape: 4 34928 (139712)
I0608 12:20:22.888558 30581 net.cpp:165] Memory required for data: 991791648
I0608 12:20:22.888561 30581 layer_factory.hpp:77] Creating layer mbox_conf
I0608 12:20:22.888568 30581 net.cpp:100] Creating Layer mbox_conf
I0608 12:20:22.888572 30581 net.cpp:434] mbox_conf <- conv4_3_norm_mbox_conf_flat
I0608 12:20:22.888576 30581 net.cpp:434] mbox_conf <- fc7_mbox_conf_flat
I0608 12:20:22.888579 30581 net.cpp:434] mbox_conf <- conv6_2_mbox_conf_flat
I0608 12:20:22.888581 30581 net.cpp:434] mbox_conf <- conv7_2_mbox_conf_flat
I0608 12:20:22.888584 30581 net.cpp:434] mbox_conf <- conv8_2_mbox_conf_flat
I0608 12:20:22.888587 30581 net.cpp:434] mbox_conf <- conv9_2_mbox_conf_flat
I0608 12:20:22.888599 30581 net.cpp:408] mbox_conf -> mbox_conf
I0608 12:20:22.888623 30581 net.cpp:150] Setting up mbox_conf
I0608 12:20:22.888628 30581 net.cpp:157] Top shape: 4 17464 (69856)
I0608 12:20:22.888631 30581 net.cpp:165] Memory required for data: 992071072
I0608 12:20:22.888635 30581 layer_factory.hpp:77] Creating layer mbox_priorbox
I0608 12:20:22.888640 30581 net.cpp:100] Creating Layer mbox_priorbox
I0608 12:20:22.888645 30581 net.cpp:434] mbox_priorbox <- conv4_3_norm_mbox_priorbox
I0608 12:20:22.888649 30581 net.cpp:434] mbox_priorbox <- fc7_mbox_priorbox
I0608 12:20:22.888653 30581 net.cpp:434] mbox_priorbox <- conv6_2_mbox_priorbox
I0608 12:20:22.888656 30581 net.cpp:434] mbox_priorbox <- conv7_2_mbox_priorbox
I0608 12:20:22.888659 30581 net.cpp:434] mbox_priorbox <- conv8_2_mbox_priorbox
I0608 12:20:22.888661 30581 net.cpp:434] mbox_priorbox <- conv9_2_mbox_priorbox
I0608 12:20:22.888665 30581 net.cpp:408] mbox_priorbox -> mbox_priorbox
I0608 12:20:22.888687 30581 net.cpp:150] Setting up mbox_priorbox
I0608 12:20:22.888692 30581 net.cpp:157] Top shape: 1 2 34928 (69856)
I0608 12:20:22.888695 30581 net.cpp:165] Memory required for data: 992350496
I0608 12:20:22.888696 30581 layer_factory.hpp:77] Creating layer mbox_conf_reshape
I0608 12:20:22.888701 30581 net.cpp:100] Creating Layer mbox_conf_reshape
I0608 12:20:22.888706 30581 net.cpp:434] mbox_conf_reshape <- mbox_conf
I0608 12:20:22.888712 30581 net.cpp:408] mbox_conf_reshape -> mbox_conf_reshape
I0608 12:20:22.888743 30581 net.cpp:150] Setting up mbox_conf_reshape
I0608 12:20:22.888749 30581 net.cpp:157] Top shape: 4 8732 2 (69856)
I0608 12:20:22.888754 30581 net.cpp:165] Memory required for data: 992629920
I0608 12:20:22.888757 30581 layer_factory.hpp:77] Creating layer mbox_conf_softmax
I0608 12:20:22.888762 30581 net.cpp:100] Creating Layer mbox_conf_softmax
I0608 12:20:22.888766 30581 net.cpp:434] mbox_conf_softmax <- mbox_conf_reshape
I0608 12:20:22.888769 30581 net.cpp:408] mbox_conf_softmax -> mbox_conf_softmax
I0608 12:20:22.888970 30581 net.cpp:150] Setting up mbox_conf_softmax
I0608 12:20:22.888977 30581 net.cpp:157] Top shape: 4 8732 2 (69856)
I0608 12:20:22.888979 30581 net.cpp:165] Memory required for data: 992909344
I0608 12:20:22.888981 30581 layer_factory.hpp:77] Creating layer mbox_conf_flatten
I0608 12:20:22.888986 30581 net.cpp:100] Creating Layer mbox_conf_flatten
I0608 12:20:22.888988 30581 net.cpp:434] mbox_conf_flatten <- mbox_conf_softmax
I0608 12:20:22.888993 30581 net.cpp:408] mbox_conf_flatten -> mbox_conf_flatten
I0608 12:20:22.889016 30581 net.cpp:150] Setting up mbox_conf_flatten
I0608 12:20:22.889021 30581 net.cpp:157] Top shape: 4 17464 (69856)
I0608 12:20:22.889024 30581 net.cpp:165] Memory required for data: 993188768
I0608 12:20:22.889027 30581 layer_factory.hpp:77] Creating layer detection_out
I0608 12:20:22.889041 30581 net.cpp:100] Creating Layer detection_out
I0608 12:20:22.889045 30581 net.cpp:434] detection_out <- mbox_loc
I0608 12:20:22.889050 30581 net.cpp:434] detection_out <- mbox_conf_flatten
I0608 12:20:22.889053 30581 net.cpp:434] detection_out <- mbox_priorbox
I0608 12:20:22.889060 30581 net.cpp:408] detection_out -> detection_out
I0608 12:20:22.889329 30581 net.cpp:150] Setting up detection_out
I0608 12:20:22.889338 30581 net.cpp:157] Top shape: 1 1 1 7 (7)
I0608 12:20:22.889340 30581 net.cpp:165] Memory required for data: 993188796
I0608 12:20:22.889343 30581 layer_factory.hpp:77] Creating layer detection_eval
I0608 12:20:22.889348 30581 net.cpp:100] Creating Layer detection_eval
I0608 12:20:22.889353 30581 net.cpp:434] detection_eval <- detection_out
I0608 12:20:22.889355 30581 net.cpp:434] detection_eval <- label
I0608 12:20:22.889359 30581 net.cpp:408] detection_eval -> detection_eval
I0608 12:20:22.889446 30581 net.cpp:150] Setting up detection_eval
I0608 12:20:22.889451 30581 net.cpp:157] Top shape: 1 1 2 5 (10)
I0608 12:20:22.889453 30581 net.cpp:165] Memory required for data: 993188836
I0608 12:20:22.889456 30581 net.cpp:228] detection_eval does not need backward computation.
I0608 12:20:22.889467 30581 net.cpp:228] detection_out does not need backward computation.
I0608 12:20:22.889469 30581 net.cpp:228] mbox_conf_flatten does not need backward computation.
I0608 12:20:22.889472 30581 net.cpp:228] mbox_conf_softmax does not need backward computation.
I0608 12:20:22.889474 30581 net.cpp:228] mbox_conf_reshape does not need backward computation.
I0608 12:20:22.889477 30581 net.cpp:228] mbox_priorbox does not need backward computation.
I0608 12:20:22.889480 30581 net.cpp:228] mbox_conf does not need backward computation.
I0608 12:20:22.889484 30581 net.cpp:228] mbox_loc does not need backward computation.
I0608 12:20:22.889488 30581 net.cpp:228] conv9_2_mbox_priorbox does not need backward computation.
I0608 12:20:22.889492 30581 net.cpp:228] conv9_2_mbox_conf_flat does not need backward computation.
I0608 12:20:22.889493 30581 net.cpp:228] conv9_2_mbox_conf_perm does not need backward computation.
I0608 12:20:22.889495 30581 net.cpp:228] conv9_2_mbox_conf does not need backward computation.
I0608 12:20:22.889498 30581 net.cpp:228] conv9_2_mbox_loc_flat does not need backward computation.
I0608 12:20:22.889500 30581 net.cpp:228] conv9_2_mbox_loc_perm does not need backward computation.
I0608 12:20:22.889503 30581 net.cpp:228] conv9_2_mbox_loc does not need backward computation.
I0608 12:20:22.889505 30581 net.cpp:228] conv8_2_mbox_priorbox does not need backward computation.
I0608 12:20:22.889509 30581 net.cpp:228] conv8_2_mbox_conf_flat does not need backward computation.
I0608 12:20:22.889513 30581 net.cpp:228] conv8_2_mbox_conf_perm does not need backward computation.
I0608 12:20:22.889514 30581 net.cpp:228] conv8_2_mbox_conf does not need backward computation.
I0608 12:20:22.889518 30581 net.cpp:228] conv8_2_mbox_loc_flat does not need backward computation.
I0608 12:20:22.889520 30581 net.cpp:228] conv8_2_mbox_loc_perm does not need backward computation.
I0608 12:20:22.889523 30581 net.cpp:228] conv8_2_mbox_loc does not need backward computation.
I0608 12:20:22.889524 30581 net.cpp:228] conv7_2_mbox_priorbox does not need backward computation.
I0608 12:20:22.889528 30581 net.cpp:228] conv7_2_mbox_conf_flat does not need backward computation.
I0608 12:20:22.889530 30581 net.cpp:228] conv7_2_mbox_conf_perm does not need backward computation.
I0608 12:20:22.889533 30581 net.cpp:228] conv7_2_mbox_conf does not need backward computation.
I0608 12:20:22.889535 30581 net.cpp:228] conv7_2_mbox_loc_flat does not need backward computation.
I0608 12:20:22.889539 30581 net.cpp:228] conv7_2_mbox_loc_perm does not need backward computation.
I0608 12:20:22.889544 30581 net.cpp:228] conv7_2_mbox_loc does not need backward computation.
I0608 12:20:22.889549 30581 net.cpp:228] conv6_2_mbox_priorbox does not need backward computation.
I0608 12:20:22.889554 30581 net.cpp:228] conv6_2_mbox_conf_flat does not need backward computation.
I0608 12:20:22.889557 30581 net.cpp:228] conv6_2_mbox_conf_perm does not need backward computation.
I0608 12:20:22.889562 30581 net.cpp:228] conv6_2_mbox_conf does not need backward computation.
I0608 12:20:22.889566 30581 net.cpp:228] conv6_2_mbox_loc_flat does not need backward computation.
I0608 12:20:22.889570 30581 net.cpp:228] conv6_2_mbox_loc_perm does not need backward computation.
I0608 12:20:22.889575 30581 net.cpp:228] conv6_2_mbox_loc does not need backward computation.
I0608 12:20:22.889580 30581 net.cpp:228] fc7_mbox_priorbox does not need backward computation.
I0608 12:20:22.889585 30581 net.cpp:228] fc7_mbox_conf_flat does not need backward computation.
I0608 12:20:22.889588 30581 net.cpp:228] fc7_mbox_conf_perm does not need backward computation.
I0608 12:20:22.889593 30581 net.cpp:228] fc7_mbox_conf does not need backward computation.
I0608 12:20:22.889597 30581 net.cpp:228] fc7_mbox_loc_flat does not need backward computation.
I0608 12:20:22.889602 30581 net.cpp:228] fc7_mbox_loc_perm does not need backward computation.
I0608 12:20:22.889606 30581 net.cpp:228] fc7_mbox_loc does not need backward computation.
I0608 12:20:22.889611 30581 net.cpp:228] conv4_3_norm_mbox_priorbox does not need backward computation.
I0608 12:20:22.889619 30581 net.cpp:228] conv4_3_norm_mbox_conf_flat does not need backward computation.
I0608 12:20:22.889622 30581 net.cpp:228] conv4_3_norm_mbox_conf_perm does not need backward computation.
I0608 12:20:22.889627 30581 net.cpp:228] conv4_3_norm_mbox_conf does not need backward computation.
I0608 12:20:22.889631 30581 net.cpp:228] conv4_3_norm_mbox_loc_flat does not need backward computation.
I0608 12:20:22.889632 30581 net.cpp:228] conv4_3_norm_mbox_loc_perm does not need backward computation.
I0608 12:20:22.889636 30581 net.cpp:228] conv4_3_norm_mbox_loc does not need backward computation.
I0608 12:20:22.889638 30581 net.cpp:228] conv4_3_norm_conv4_3_norm_0_split does not need backward computation.
I0608 12:20:22.889641 30581 net.cpp:228] conv4_3_norm does not need backward computation.
I0608 12:20:22.889644 30581 net.cpp:228] conv9_2_conv9_2_relu_0_split does not need backward computation.
I0608 12:20:22.889647 30581 net.cpp:228] conv9_2_relu does not need backward computation.
I0608 12:20:22.889648 30581 net.cpp:228] conv9_2 does not need backward computation.
I0608 12:20:22.889650 30581 net.cpp:228] conv9_1_relu does not need backward computation.
I0608 12:20:22.889653 30581 net.cpp:228] conv9_1 does not need backward computation.
I0608 12:20:22.889657 30581 net.cpp:228] conv8_2_conv8_2_relu_0_split does not need backward computation.
I0608 12:20:22.889658 30581 net.cpp:228] conv8_2_relu does not need backward computation.
I0608 12:20:22.889660 30581 net.cpp:228] conv8_2 does not need backward computation.
I0608 12:20:22.889663 30581 net.cpp:228] conv8_1_relu does not need backward computation.
I0608 12:20:22.889665 30581 net.cpp:228] conv8_1 does not need backward computation.
I0608 12:20:22.889668 30581 net.cpp:228] conv7_2_conv7_2_relu_0_split does not need backward computation.
I0608 12:20:22.889670 30581 net.cpp:228] conv7_2_relu does not need backward computation.
I0608 12:20:22.889672 30581 net.cpp:228] conv7_2 does not need backward computation.
I0608 12:20:22.889675 30581 net.cpp:228] conv7_1_relu does not need backward computation.
I0608 12:20:22.889678 30581 net.cpp:228] conv7_1 does not need backward computation.
I0608 12:20:22.889679 30581 net.cpp:228] conv6_2_conv6_2_relu_0_split does not need backward computation.
I0608 12:20:22.889683 30581 net.cpp:228] conv6_2_relu does not need backward computation.
I0608 12:20:22.889685 30581 net.cpp:228] conv6_2 does not need backward computation.
I0608 12:20:22.889688 30581 net.cpp:228] conv6_1_relu does not need backward computation.
I0608 12:20:22.889690 30581 net.cpp:228] conv6_1 does not need backward computation.
I0608 12:20:22.889694 30581 net.cpp:228] fc7_relu7_0_split does not need backward computation.
I0608 12:20:22.889698 30581 net.cpp:228] relu7 does not need backward computation.
I0608 12:20:22.889701 30581 net.cpp:228] fc7 does not need backward computation.
I0608 12:20:22.889706 30581 net.cpp:228] relu6 does not need backward computation.
I0608 12:20:22.889710 30581 net.cpp:228] fc6 does not need backward computation.
I0608 12:20:22.889714 30581 net.cpp:228] pool5 does not need backward computation.
I0608 12:20:22.889719 30581 net.cpp:228] relu5_3 does not need backward computation.
I0608 12:20:22.889721 30581 net.cpp:228] conv5_3 does not need backward computation.
I0608 12:20:22.889725 30581 net.cpp:228] relu5_2 does not need backward computation.
I0608 12:20:22.889729 30581 net.cpp:228] conv5_2 does not need backward computation.
I0608 12:20:22.889731 30581 net.cpp:228] relu5_1 does not need backward computation.
I0608 12:20:22.889734 30581 net.cpp:228] conv5_1 does not need backward computation.
I0608 12:20:22.889737 30581 net.cpp:228] pool4 does not need backward computation.
I0608 12:20:22.889741 30581 net.cpp:228] conv4_3_relu4_3_0_split does not need backward computation.
I0608 12:20:22.889744 30581 net.cpp:228] relu4_3 does not need backward computation.
I0608 12:20:22.889746 30581 net.cpp:228] conv4_3 does not need backward computation.
I0608 12:20:22.889755 30581 net.cpp:228] relu4_2 does not need backward computation.
I0608 12:20:22.889756 30581 net.cpp:228] conv4_2 does not need backward computation.
I0608 12:20:22.889758 30581 net.cpp:228] relu4_1 does not need backward computation.
I0608 12:20:22.889760 30581 net.cpp:228] conv4_1 does not need backward computation.
I0608 12:20:22.889763 30581 net.cpp:228] pool3 does not need backward computation.
I0608 12:20:22.889766 30581 net.cpp:228] relu3_3 does not need backward computation.
I0608 12:20:22.889768 30581 net.cpp:228] conv3_3 does not need backward computation.
I0608 12:20:22.889770 30581 net.cpp:228] relu3_2 does not need backward computation.
I0608 12:20:22.889772 30581 net.cpp:228] conv3_2 does not need backward computation.
I0608 12:20:22.889775 30581 net.cpp:228] relu3_1 does not need backward computation.
I0608 12:20:22.889776 30581 net.cpp:228] conv3_1 does not need backward computation.
I0608 12:20:22.889780 30581 net.cpp:228] pool2 does not need backward computation.
I0608 12:20:22.889782 30581 net.cpp:228] relu2_2 does not need backward computation.
I0608 12:20:22.889785 30581 net.cpp:228] conv2_2 does not need backward computation.
I0608 12:20:22.889786 30581 net.cpp:228] relu2_1 does not need backward computation.
I0608 12:20:22.889788 30581 net.cpp:228] conv2_1 does not need backward computation.
I0608 12:20:22.889791 30581 net.cpp:228] pool1 does not need backward computation.
I0608 12:20:22.889792 30581 net.cpp:228] relu1_2 does not need backward computation.
I0608 12:20:22.889796 30581 net.cpp:228] conv1_2 does not need backward computation.
I0608 12:20:22.889797 30581 net.cpp:228] relu1_1 does not need backward computation.
I0608 12:20:22.889801 30581 net.cpp:228] conv1_1 does not need backward computation.
I0608 12:20:22.889804 30581 net.cpp:228] data_data_0_split does not need backward computation.
I0608 12:20:22.889806 30581 net.cpp:228] data does not need backward computation.
I0608 12:20:22.889808 30581 net.cpp:270] This network produces output detection_eval
I0608 12:20:22.889875 30581 net.cpp:283] Network initialization done.
I0608 12:20:22.890102 30581 solver.cpp:75] Solver scaffolding done.
I0608 12:20:22.892524 30581 caffe.cpp:155] Finetuning from models/VGGNet/VGG_ILSVRC_16_layers_fc_reduced.caffemodel
I0608 12:20:23.066862 30581 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: models/VGGNet/VGG_ILSVRC_16_layers_fc_reduced.caffemodel
I0608 12:20:23.066881 30581 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.
W0608 12:20:23.066884 30581 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.
I0608 12:20:23.078263 30581 net.cpp:761] Ignoring source layer drop6
I0608 12:20:23.079349 30581 net.cpp:761] Ignoring source layer drop7
I0608 12:20:23.079361 30581 net.cpp:761] Ignoring source layer fc8
I0608 12:20:23.079366 30581 net.cpp:761] Ignoring source layer prob
I0608 12:20:23.109469 30581 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: models/VGGNet/VGG_ILSVRC_16_layers_fc_reduced.caffemodel
I0608 12:20:23.109488 30581 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.
W0608 12:20:23.109489 30581 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.
I0608 12:20:23.121156 30581 net.cpp:761] Ignoring source layer drop6
I0608 12:20:23.122054 30581 net.cpp:761] Ignoring source layer drop7
I0608 12:20:23.122081 30581 net.cpp:761] Ignoring source layer fc8
I0608 12:20:23.122086 30581 net.cpp:761] Ignoring source layer prob
I0608 12:20:23.123342 30581 caffe.cpp:251] Starting Optimization
I0608 12:20:23.123358 30581 solver.cpp:294] Solving VGG_sharpen_tbs_v2.0_SSD_300x300_train
I0608 12:20:23.123361 30581 solver.cpp:295] Learning Rate Policy: multistep
I0608 12:20:23.131054 30581 blocking_queue.cpp:50] Data layer prefetch queue empty
I0608 12:20:23.806668 30581 solver.cpp:243] Iteration 0, loss = 13.6112
I0608 12:20:23.806737 30581 solver.cpp:259]     Train net output #0: mbox_loss = 13.6112 (* 1 = 13.6112 loss)
I0608 12:20:23.806764 30581 sgd_solver.cpp:138] Iteration 0, lr = 0.0005
I0608 12:20:35.024052 30581 solver.cpp:243] Iteration 10, loss = 8.94704
I0608 12:20:35.024081 30581 solver.cpp:259]     Train net output #0: mbox_loss = 8.17895 (* 1 = 8.17895 loss)
I0608 12:20:35.024087 30581 sgd_solver.cpp:138] Iteration 10, lr = 0.0005
I0608 12:20:45.179116 30581 solver.cpp:243] Iteration 20, loss = 6.52321
I0608 12:20:45.179147 30581 solver.cpp:259]     Train net output #0: mbox_loss = 5.67111 (* 1 = 5.67111 loss)
I0608 12:20:45.179152 30581 sgd_solver.cpp:138] Iteration 20, lr = 0.0005
I0608 12:20:55.705379 30581 solver.cpp:243] Iteration 30, loss = 6.05719
I0608 12:20:55.705451 30581 solver.cpp:259]     Train net output #0: mbox_loss = 5.8114 (* 1 = 5.8114 loss)
I0608 12:20:55.705457 30581 sgd_solver.cpp:138] Iteration 30, lr = 0.0005
I0608 12:21:06.762706 30581 solver.cpp:243] Iteration 40, loss = 5.64125
I0608 12:21:06.762738 30581 solver.cpp:259]     Train net output #0: mbox_loss = 5.76018 (* 1 = 5.76018 loss)
I0608 12:21:06.762744 30581 sgd_solver.cpp:138] Iteration 40, lr = 0.0005
I0608 12:21:17.445621 30581 solver.cpp:243] Iteration 50, loss = 5.51359
I0608 12:21:17.445648 30581 solver.cpp:259]     Train net output #0: mbox_loss = 5.30155 (* 1 = 5.30155 loss)
I0608 12:21:17.445654 30581 sgd_solver.cpp:138] Iteration 50, lr = 0.0005
I0608 12:21:27.655117 30581 solver.cpp:243] Iteration 60, loss = 5.43504
I0608 12:21:27.655274 30581 solver.cpp:259]     Train net output #0: mbox_loss = 5.22933 (* 1 = 5.22933 loss)
I0608 12:21:27.655298 30581 sgd_solver.cpp:138] Iteration 60, lr = 0.0005
I0608 12:21:38.021347 30581 solver.cpp:243] Iteration 70, loss = 5.57299
I0608 12:21:38.021375 30581 solver.cpp:259]     Train net output #0: mbox_loss = 5.68104 (* 1 = 5.68104 loss)
I0608 12:21:38.021380 30581 sgd_solver.cpp:138] Iteration 70, lr = 0.0005
I0608 12:21:48.291170 30581 solver.cpp:243] Iteration 80, loss = 5.84786
I0608 12:21:48.291198 30581 solver.cpp:259]     Train net output #0: mbox_loss = 6.07583 (* 1 = 6.07583 loss)
I0608 12:21:48.291203 30581 sgd_solver.cpp:138] Iteration 80, lr = 0.0005
I0608 12:21:58.293682 30581 solver.cpp:243] Iteration 90, loss = 5.67421
I0608 12:21:58.293838 30581 solver.cpp:259]     Train net output #0: mbox_loss = 5.86891 (* 1 = 5.86891 loss)
I0608 12:21:58.293848 30581 sgd_solver.cpp:138] Iteration 90, lr = 0.0005
I0608 12:22:07.931813 30581 solver.cpp:243] Iteration 100, loss = 5.3079
I0608 12:22:07.931839 30581 solver.cpp:259]     Train net output #0: mbox_loss = 5.15429 (* 1 = 5.15429 loss)
I0608 12:22:07.931845 30581 sgd_solver.cpp:138] Iteration 100, lr = 0.0005
I0608 12:22:19.288956 30581 solver.cpp:243] Iteration 110, loss = 5.14689
I0608 12:22:19.288985 30581 solver.cpp:259]     Train net output #0: mbox_loss = 5.26097 (* 1 = 5.26097 loss)
I0608 12:22:19.288990 30581 sgd_solver.cpp:138] Iteration 110, lr = 0.0005
I0608 12:22:30.187544 30581 solver.cpp:243] Iteration 120, loss = 5.0573
I0608 12:22:30.187609 30581 solver.cpp:259]     Train net output #0: mbox_loss = 4.84734 (* 1 = 4.84734 loss)
I0608 12:22:30.187615 30581 sgd_solver.cpp:138] Iteration 120, lr = 0.0005
I0608 12:22:39.901793 30581 solver.cpp:243] Iteration 130, loss = 5.24067
I0608 12:22:39.901816 30581 solver.cpp:259]     Train net output #0: mbox_loss = 5.31658 (* 1 = 5.31658 loss)
I0608 12:22:39.901839 30581 sgd_solver.cpp:138] Iteration 130, lr = 0.0005
I0608 12:22:49.887006 30581 solver.cpp:243] Iteration 140, loss = 5.11402
I0608 12:22:49.887038 30581 solver.cpp:259]     Train net output #0: mbox_loss = 5.28117 (* 1 = 5.28117 loss)
I0608 12:22:49.887044 30581 sgd_solver.cpp:138] Iteration 140, lr = 0.0005
I0608 12:22:59.757674 30581 solver.cpp:243] Iteration 150, loss = 5.25916
I0608 12:22:59.757699 30581 solver.cpp:259]     Train net output #0: mbox_loss = 5.60171 (* 1 = 5.60171 loss)
I0608 12:22:59.757720 30581 sgd_solver.cpp:138] Iteration 150, lr = 0.0005
I0608 12:23:09.876267 30581 solver.cpp:243] Iteration 160, loss = 5.06115
I0608 12:23:09.876451 30581 solver.cpp:259]     Train net output #0: mbox_loss = 5.15349 (* 1 = 5.15349 loss)
I0608 12:23:09.876473 30581 sgd_solver.cpp:138] Iteration 160, lr = 0.0005
I0608 12:23:20.005789 30581 solver.cpp:243] Iteration 170, loss = 4.94842
I0608 12:23:20.005815 30581 solver.cpp:259]     Train net output #0: mbox_loss = 5.08803 (* 1 = 5.08803 loss)
I0608 12:23:20.005821 30581 sgd_solver.cpp:138] Iteration 170, lr = 0.0005
I0608 12:23:30.689455 30581 solver.cpp:243] Iteration 180, loss = 4.9052
I0608 12:23:30.689483 30581 solver.cpp:259]     Train net output #0: mbox_loss = 4.9735 (* 1 = 4.9735 loss)
I0608 12:23:30.689503 30581 sgd_solver.cpp:138] Iteration 180, lr = 0.0005
I0608 12:23:40.662884 30581 solver.cpp:243] Iteration 190, loss = 4.84344
I0608 12:23:40.663013 30581 solver.cpp:259]     Train net output #0: mbox_loss = 4.83333 (* 1 = 4.83333 loss)
I0608 12:23:40.663035 30581 sgd_solver.cpp:138] Iteration 190, lr = 0.0005
I0608 12:23:49.936116 30581 solver.cpp:433] Iteration 200, Testing net (#0)
I0608 12:23:50.461155 30581 net.cpp:693] Ignoring source layer mbox_loss
I0608 12:23:51.714252 30581 solver.cpp:546]     Test net output #0: detection_eval = 0.242669
I0608 12:23:52.010978 30581 solver.cpp:243] Iteration 200, loss = 4.72625
I0608 12:23:52.011008 30581 solver.cpp:259]     Train net output #0: mbox_loss = 4.62065 (* 1 = 4.62065 loss)
I0608 12:23:52.011029 30581 sgd_solver.cpp:138] Iteration 200, lr = 0.0005
I0608 12:24:01.210707 30581 solver.cpp:243] Iteration 210, loss = 4.76838
I0608 12:24:01.210736 30581 solver.cpp:259]     Train net output #0: mbox_loss = 4.58166 (* 1 = 4.58166 loss)
I0608 12:24:01.210742 30581 sgd_solver.cpp:138] Iteration 210, lr = 0.0005
I0608 12:24:12.542208 30581 solver.cpp:243] Iteration 220, loss = 4.88817
I0608 12:24:12.542351 30581 solver.cpp:259]     Train net output #0: mbox_loss = 5.0328 (* 1 = 5.0328 loss)
I0608 12:24:12.542358 30581 sgd_solver.cpp:138] Iteration 220, lr = 0.0005
I0608 12:24:22.830831 30581 solver.cpp:243] Iteration 230, loss = 4.7619
I0608 12:24:22.830858 30581 solver.cpp:259]     Train net output #0: mbox_loss = 4.57965 (* 1 = 4.57965 loss)
I0608 12:24:22.830864 30581 sgd_solver.cpp:138] Iteration 230, lr = 0.0005
I0608 12:24:33.011226 30581 solver.cpp:243] Iteration 240, loss = 5.00981
I0608 12:24:33.011252 30581 solver.cpp:259]     Train net output #0: mbox_loss = 4.98612 (* 1 = 4.98612 loss)
I0608 12:24:33.011258 30581 sgd_solver.cpp:138] Iteration 240, lr = 0.0005
I0608 12:24:43.245342 30581 solver.cpp:243] Iteration 250, loss = 4.64064
I0608 12:24:43.245491 30581 solver.cpp:259]     Train net output #0: mbox_loss = 4.78226 (* 1 = 4.78226 loss)
I0608 12:24:43.245513 30581 sgd_solver.cpp:138] Iteration 250, lr = 0.0005
I0608 12:24:53.838279 30581 solver.cpp:243] Iteration 260, loss = 4.63205
I0608 12:24:53.838309 30581 solver.cpp:259]     Train net output #0: mbox_loss = 4.97229 (* 1 = 4.97229 loss)
I0608 12:24:53.838315 30581 sgd_solver.cpp:138] Iteration 260, lr = 0.0005
I0608 12:25:04.405545 30581 solver.cpp:243] Iteration 270, loss = 4.49482
I0608 12:25:04.405576 30581 solver.cpp:259]     Train net output #0: mbox_loss = 4.41427 (* 1 = 4.41427 loss)
I0608 12:25:04.405582 30581 sgd_solver.cpp:138] Iteration 270, lr = 0.0005
I0608 12:25:14.904436 30581 solver.cpp:243] Iteration 280, loss = 4.49019
I0608 12:25:14.904498 30581 solver.cpp:259]     Train net output #0: mbox_loss = 4.37065 (* 1 = 4.37065 loss)
I0608 12:25:14.904506 30581 sgd_solver.cpp:138] Iteration 280, lr = 0.0005
I0608 12:25:25.584604 30581 solver.cpp:243] Iteration 290, loss = 4.41055
I0608 12:25:25.584635 30581 solver.cpp:259]     Train net output #0: mbox_loss = 4.66985 (* 1 = 4.66985 loss)
I0608 12:25:25.584656 30581 sgd_solver.cpp:138] Iteration 290, lr = 0.0005
I0608 12:25:35.814751 30581 solver.cpp:243] Iteration 300, loss = 4.37487
I0608 12:25:35.814779 30581 solver.cpp:259]     Train net output #0: mbox_loss = 4.30519 (* 1 = 4.30519 loss)
I0608 12:25:35.814785 30581 sgd_solver.cpp:138] Iteration 300, lr = 0.0005
I0608 12:25:46.494776 30581 solver.cpp:243] Iteration 310, loss = 4.38844
I0608 12:25:46.494946 30581 solver.cpp:259]     Train net output #0: mbox_loss = 4.07869 (* 1 = 4.07869 loss)
I0608 12:25:46.494967 30581 sgd_solver.cpp:138] Iteration 310, lr = 0.0005
I0608 12:25:56.940140 30581 solver.cpp:243] Iteration 320, loss = 4.27645
I0608 12:25:56.940165 30581 solver.cpp:259]     Train net output #0: mbox_loss = 4.19163 (* 1 = 4.19163 loss)
I0608 12:25:56.940171 30581 sgd_solver.cpp:138] Iteration 320, lr = 0.0005
I0608 12:26:06.542754 30581 solver.cpp:243] Iteration 330, loss = 4.28512
I0608 12:26:06.542783 30581 solver.cpp:259]     Train net output #0: mbox_loss = 4.42677 (* 1 = 4.42677 loss)
I0608 12:26:06.542789 30581 sgd_solver.cpp:138] Iteration 330, lr = 0.0005
I0608 12:26:16.958647 30581 solver.cpp:243] Iteration 340, loss = 4.11192
I0608 12:26:16.958788 30581 solver.cpp:259]     Train net output #0: mbox_loss = 4.35039 (* 1 = 4.35039 loss)
I0608 12:26:16.958811 30581 sgd_solver.cpp:138] Iteration 340, lr = 0.0005
I0608 12:26:26.840363 30581 solver.cpp:243] Iteration 350, loss = 4.07209
I0608 12:26:26.840391 30581 solver.cpp:259]     Train net output #0: mbox_loss = 4.32013 (* 1 = 4.32013 loss)
I0608 12:26:26.840397 30581 sgd_solver.cpp:138] Iteration 350, lr = 0.0005
I0608 12:26:37.740689 30581 solver.cpp:243] Iteration 360, loss = 4.06172
I0608 12:26:37.740721 30581 solver.cpp:259]     Train net output #0: mbox_loss = 4.08307 (* 1 = 4.08307 loss)
I0608 12:26:37.740727 30581 sgd_solver.cpp:138] Iteration 360, lr = 0.0005
I0608 12:26:47.653040 30581 solver.cpp:243] Iteration 370, loss = 3.97157
I0608 12:26:47.653224 30581 solver.cpp:259]     Train net output #0: mbox_loss = 4.13894 (* 1 = 4.13894 loss)
I0608 12:26:47.653235 30581 sgd_solver.cpp:138] Iteration 370, lr = 0.0005
I0608 12:26:57.172883 30581 solver.cpp:243] Iteration 380, loss = 3.91251
I0608 12:26:57.172910 30581 solver.cpp:259]     Train net output #0: mbox_loss = 4.04395 (* 1 = 4.04395 loss)
I0608 12:26:57.172915 30581 sgd_solver.cpp:138] Iteration 380, lr = 0.0005
I0608 12:27:07.531256 30581 solver.cpp:243] Iteration 390, loss = 3.88353
I0608 12:27:07.531286 30581 solver.cpp:259]     Train net output #0: mbox_loss = 3.88604 (* 1 = 3.88604 loss)
I0608 12:27:07.531291 30581 sgd_solver.cpp:138] Iteration 390, lr = 0.0005
I0608 12:27:16.314703 30581 solver.cpp:433] Iteration 400, Testing net (#0)
I0608 12:27:16.314780 30581 net.cpp:693] Ignoring source layer mbox_loss
I0608 12:27:18.008244 30581 solver.cpp:546]     Test net output #0: detection_eval = 0.599588
I0608 12:27:18.306432 30581 solver.cpp:243] Iteration 400, loss = 3.91586
I0608 12:27:18.306460 30581 solver.cpp:259]     Train net output #0: mbox_loss = 4.14648 (* 1 = 4.14648 loss)
I0608 12:27:18.306465 30581 sgd_solver.cpp:138] Iteration 400, lr = 0.0005
I0608 12:27:27.053033 30581 solver.cpp:243] Iteration 410, loss = 3.85289
I0608 12:27:27.053059 30581 solver.cpp:259]     Train net output #0: mbox_loss = 3.68901 (* 1 = 3.68901 loss)
I0608 12:27:27.053064 30581 sgd_solver.cpp:138] Iteration 410, lr = 0.0005
I0608 12:27:37.700033 30581 solver.cpp:243] Iteration 420, loss = 3.76253
I0608 12:27:37.700062 30581 solver.cpp:259]     Train net output #0: mbox_loss = 3.62883 (* 1 = 3.62883 loss)
I0608 12:27:37.700067 30581 sgd_solver.cpp:138] Iteration 420, lr = 0.0005
I0608 12:27:47.964223 30581 solver.cpp:243] Iteration 430, loss = 3.77558
I0608 12:27:47.964252 30581 solver.cpp:259]     Train net output #0: mbox_loss = 3.6837 (* 1 = 3.6837 loss)
I0608 12:27:47.964259 30581 sgd_solver.cpp:138] Iteration 430, lr = 0.0005
I0608 12:27:58.698503 30581 solver.cpp:243] Iteration 440, loss = 3.68096
I0608 12:27:58.698659 30581 solver.cpp:259]     Train net output #0: mbox_loss = 3.67885 (* 1 = 3.67885 loss)
I0608 12:27:58.698681 30581 sgd_solver.cpp:138] Iteration 440, lr = 0.0005
I0608 12:28:09.652997 30581 solver.cpp:243] Iteration 450, loss = 3.66405
I0608 12:28:09.653025 30581 solver.cpp:259]     Train net output #0: mbox_loss = 3.42838 (* 1 = 3.42838 loss)
I0608 12:28:09.653030 30581 sgd_solver.cpp:138] Iteration 450, lr = 0.0005
I0608 12:28:19.596493 30581 solver.cpp:243] Iteration 460, loss = 3.59511
I0608 12:28:19.596523 30581 solver.cpp:259]     Train net output #0: mbox_loss = 3.67787 (* 1 = 3.67787 loss)
I0608 12:28:19.596544 30581 sgd_solver.cpp:138] Iteration 460, lr = 0.0005
I0608 12:28:29.959533 30581 solver.cpp:243] Iteration 470, loss = 3.68856
I0608 12:28:29.959712 30581 solver.cpp:259]     Train net output #0: mbox_loss = 3.57817 (* 1 = 3.57817 loss)
I0608 12:28:29.959735 30581 sgd_solver.cpp:138] Iteration 470, lr = 0.0005
I0608 12:28:40.100600 30581 solver.cpp:243] Iteration 480, loss = 3.65221
I0608 12:28:40.100628 30581 solver.cpp:259]     Train net output #0: mbox_loss = 3.46481 (* 1 = 3.46481 loss)
I0608 12:28:40.100633 30581 sgd_solver.cpp:138] Iteration 480, lr = 0.0005
I0608 12:28:51.201547 30581 solver.cpp:243] Iteration 490, loss = 3.57214
I0608 12:28:51.201576 30581 solver.cpp:259]     Train net output #0: mbox_loss = 3.29341 (* 1 = 3.29341 loss)
I0608 12:28:51.201582 30581 sgd_solver.cpp:138] Iteration 490, lr = 0.0005
I0608 12:29:02.429167 30581 solver.cpp:243] Iteration 500, loss = 3.77611
I0608 12:29:02.429348 30581 solver.cpp:259]     Train net output #0: mbox_loss = 3.80686 (* 1 = 3.80686 loss)
I0608 12:29:02.429370 30581 sgd_solver.cpp:138] Iteration 500, lr = 0.0005
I0608 12:29:12.394335 30581 solver.cpp:243] Iteration 510, loss = 3.44247
I0608 12:29:12.394362 30581 solver.cpp:259]     Train net output #0: mbox_loss = 3.31825 (* 1 = 3.31825 loss)
I0608 12:29:12.394368 30581 sgd_solver.cpp:138] Iteration 510, lr = 0.0005
I0608 12:29:22.377789 30581 solver.cpp:243] Iteration 520, loss = 3.54195
I0608 12:29:22.377817 30581 solver.cpp:259]     Train net output #0: mbox_loss = 3.38135 (* 1 = 3.38135 loss)
I0608 12:29:22.377823 30581 sgd_solver.cpp:138] Iteration 520, lr = 0.0005
I0608 12:29:31.876760 30581 solver.cpp:243] Iteration 530, loss = 3.42749
I0608 12:29:31.876782 30581 solver.cpp:259]     Train net output #0: mbox_loss = 3.60067 (* 1 = 3.60067 loss)
I0608 12:29:31.876788 30581 sgd_solver.cpp:138] Iteration 530, lr = 0.0005
I0608 12:29:42.818202 30581 solver.cpp:243] Iteration 540, loss = 3.5629
I0608 12:29:42.818359 30581 solver.cpp:259]     Train net output #0: mbox_loss = 3.68318 (* 1 = 3.68318 loss)
I0608 12:29:42.818368 30581 sgd_solver.cpp:138] Iteration 540, lr = 0.0005
I0608 12:29:53.609874 30581 solver.cpp:243] Iteration 550, loss = 3.5128
I0608 12:29:53.609904 30581 solver.cpp:259]     Train net output #0: mbox_loss = 3.51107 (* 1 = 3.51107 loss)
I0608 12:29:53.609910 30581 sgd_solver.cpp:138] Iteration 550, lr = 0.0005
I0608 12:30:03.643481 30581 solver.cpp:243] Iteration 560, loss = 3.5005
I0608 12:30:03.643510 30581 solver.cpp:259]     Train net output #0: mbox_loss = 3.52383 (* 1 = 3.52383 loss)
I0608 12:30:03.643532 30581 sgd_solver.cpp:138] Iteration 560, lr = 0.0005
I0608 12:30:14.447270 30581 solver.cpp:243] Iteration 570, loss = 3.41259
I0608 12:30:14.447422 30581 solver.cpp:259]     Train net output #0: mbox_loss = 3.16274 (* 1 = 3.16274 loss)
I0608 12:30:14.447445 30581 sgd_solver.cpp:138] Iteration 570, lr = 0.0005
I0608 12:30:25.151798 30581 solver.cpp:243] Iteration 580, loss = 3.58983
I0608 12:30:25.151828 30581 solver.cpp:259]     Train net output #0: mbox_loss = 3.59822 (* 1 = 3.59822 loss)
I0608 12:30:25.151834 30581 sgd_solver.cpp:138] Iteration 580, lr = 0.0005
I0608 12:30:35.882632 30581 solver.cpp:243] Iteration 590, loss = 3.38299
I0608 12:30:35.882660 30581 solver.cpp:259]     Train net output #0: mbox_loss = 3.4042 (* 1 = 3.4042 loss)
I0608 12:30:35.882666 30581 sgd_solver.cpp:138] Iteration 590, lr = 0.0005
I0608 12:30:44.744380 30581 solver.cpp:433] Iteration 600, Testing net (#0)
I0608 12:30:44.744560 30581 net.cpp:693] Ignoring source layer mbox_loss
I0608 12:30:46.526126 30581 solver.cpp:546]     Test net output #0: detection_eval = 0.669598
I0608 12:30:46.830374 30581 solver.cpp:243] Iteration 600, loss = 3.45417
I0608 12:30:46.830405 30581 solver.cpp:259]     Train net output #0: mbox_loss = 3.42505 (* 1 = 3.42505 loss)
I0608 12:30:46.830411 30581 sgd_solver.cpp:138] Iteration 600, lr = 0.0005
I0608 12:30:56.160262 30581 solver.cpp:243] Iteration 610, loss = 3.3701
I0608 12:30:56.160290 30581 solver.cpp:259]     Train net output #0: mbox_loss = 3.30499 (* 1 = 3.30499 loss)
I0608 12:30:56.160296 30581 sgd_solver.cpp:138] Iteration 610, lr = 0.0005
I0608 12:31:07.623265 30581 solver.cpp:243] Iteration 620, loss = 3.53692
I0608 12:31:07.623292 30581 solver.cpp:259]     Train net output #0: mbox_loss = 3.66459 (* 1 = 3.66459 loss)
I0608 12:31:07.623313 30581 sgd_solver.cpp:138] Iteration 620, lr = 0.0005
I0608 12:31:17.795958 30581 solver.cpp:243] Iteration 630, loss = 3.34117
I0608 12:31:17.796125 30581 solver.cpp:259]     Train net output #0: mbox_loss = 3.25741 (* 1 = 3.25741 loss)
I0608 12:31:17.796149 30581 sgd_solver.cpp:138] Iteration 630, lr = 0.0005
I0608 12:31:28.101065 30581 solver.cpp:243] Iteration 640, loss = 3.21348
I0608 12:31:28.101096 30581 solver.cpp:259]     Train net output #0: mbox_loss = 3.19024 (* 1 = 3.19024 loss)
I0608 12:31:28.101102 30581 sgd_solver.cpp:138] Iteration 640, lr = 0.0005
I0608 12:31:38.766547 30581 solver.cpp:243] Iteration 650, loss = 3.37433
I0608 12:31:38.766577 30581 solver.cpp:259]     Train net output #0: mbox_loss = 3.2515 (* 1 = 3.2515 loss)
I0608 12:31:38.766583 30581 sgd_solver.cpp:138] Iteration 650, lr = 0.0005
I0608 12:31:48.224864 30581 solver.cpp:243] Iteration 660, loss = 3.48672
I0608 12:31:48.225018 30581 solver.cpp:259]     Train net output #0: mbox_loss = 3.41703 (* 1 = 3.41703 loss)
I0608 12:31:48.225041 30581 sgd_solver.cpp:138] Iteration 660, lr = 0.0005
I0608 12:31:58.584509 30581 solver.cpp:243] Iteration 670, loss = 3.39314
I0608 12:31:58.584538 30581 solver.cpp:259]     Train net output #0: mbox_loss = 3.33851 (* 1 = 3.33851 loss)
I0608 12:31:58.584560 30581 sgd_solver.cpp:138] Iteration 670, lr = 0.0005
I0608 12:32:08.856463 30581 solver.cpp:243] Iteration 680, loss = 3.4439
I0608 12:32:08.856489 30581 solver.cpp:259]     Train net output #0: mbox_loss = 3.77168 (* 1 = 3.77168 loss)
I0608 12:32:08.856495 30581 sgd_solver.cpp:138] Iteration 680, lr = 0.0005
I0608 12:32:18.711827 30581 solver.cpp:243] Iteration 690, loss = 3.35242
I0608 12:32:18.711969 30581 solver.cpp:259]     Train net output #0: mbox_loss = 3.51941 (* 1 = 3.51941 loss)
I0608 12:32:18.711993 30581 sgd_solver.cpp:138] Iteration 690, lr = 0.0005
I0608 12:32:28.390437 30581 solver.cpp:243] Iteration 700, loss = 3.17655
I0608 12:32:28.390466 30581 solver.cpp:259]     Train net output #0: mbox_loss = 3.16442 (* 1 = 3.16442 loss)
I0608 12:32:28.390472 30581 sgd_solver.cpp:138] Iteration 700, lr = 0.0005
I0608 12:32:38.575109 30581 solver.cpp:243] Iteration 710, loss = 3.12887
I0608 12:32:38.575139 30581 solver.cpp:259]     Train net output #0: mbox_loss = 3.18669 (* 1 = 3.18669 loss)
I0608 12:32:38.575143 30581 sgd_solver.cpp:138] Iteration 710, lr = 0.0005
I0608 12:32:49.160424 30581 solver.cpp:243] Iteration 720, loss = 3.21174
I0608 12:32:49.160552 30581 solver.cpp:259]     Train net output #0: mbox_loss = 3.2124 (* 1 = 3.2124 loss)
I0608 12:32:49.160575 30581 sgd_solver.cpp:138] Iteration 720, lr = 0.0005
I0608 12:32:59.143200 30581 solver.cpp:243] Iteration 730, loss = 3.32185
I0608 12:32:59.143227 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.93096 (* 1 = 2.93096 loss)
I0608 12:32:59.143232 30581 sgd_solver.cpp:138] Iteration 730, lr = 0.0005
I0608 12:33:08.956655 30581 solver.cpp:243] Iteration 740, loss = 3.09075
I0608 12:33:08.956681 30581 solver.cpp:259]     Train net output #0: mbox_loss = 3.11383 (* 1 = 3.11383 loss)
I0608 12:33:08.956687 30581 sgd_solver.cpp:138] Iteration 740, lr = 0.0005
I0608 12:33:19.490789 30581 solver.cpp:243] Iteration 750, loss = 3.13832
I0608 12:33:19.490928 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.93463 (* 1 = 2.93463 loss)
I0608 12:33:19.490952 30581 sgd_solver.cpp:138] Iteration 750, lr = 0.0005
I0608 12:33:29.673655 30581 solver.cpp:243] Iteration 760, loss = 3.15101
I0608 12:33:29.673681 30581 solver.cpp:259]     Train net output #0: mbox_loss = 3.00259 (* 1 = 3.00259 loss)
I0608 12:33:29.673686 30581 sgd_solver.cpp:138] Iteration 760, lr = 0.0005
I0608 12:33:40.002981 30581 solver.cpp:243] Iteration 770, loss = 3.23555
I0608 12:33:40.003006 30581 solver.cpp:259]     Train net output #0: mbox_loss = 3.21025 (* 1 = 3.21025 loss)
I0608 12:33:40.003012 30581 sgd_solver.cpp:138] Iteration 770, lr = 0.0005
I0608 12:33:50.506245 30581 solver.cpp:243] Iteration 780, loss = 3.14905
I0608 12:33:50.506419 30581 solver.cpp:259]     Train net output #0: mbox_loss = 3.47133 (* 1 = 3.47133 loss)
I0608 12:33:50.506443 30581 sgd_solver.cpp:138] Iteration 780, lr = 0.0005
I0608 12:34:00.532765 30581 solver.cpp:243] Iteration 790, loss = 3.10769
I0608 12:34:00.532791 30581 solver.cpp:259]     Train net output #0: mbox_loss = 3.26429 (* 1 = 3.26429 loss)
I0608 12:34:00.532812 30581 sgd_solver.cpp:138] Iteration 790, lr = 0.0005
I0608 12:34:10.249955 30581 solver.cpp:433] Iteration 800, Testing net (#0)
I0608 12:34:10.250020 30581 net.cpp:693] Ignoring source layer mbox_loss
I0608 12:34:11.972820 30581 solver.cpp:546]     Test net output #0: detection_eval = 0.738998
I0608 12:34:12.267868 30581 solver.cpp:243] Iteration 800, loss = 3.16918
I0608 12:34:12.267896 30581 solver.cpp:259]     Train net output #0: mbox_loss = 3.52688 (* 1 = 3.52688 loss)
I0608 12:34:12.267902 30581 sgd_solver.cpp:138] Iteration 800, lr = 0.0005
I0608 12:34:21.973574 30581 solver.cpp:243] Iteration 810, loss = 3.12492
I0608 12:34:21.973726 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.8288 (* 1 = 2.8288 loss)
I0608 12:34:21.973734 30581 sgd_solver.cpp:138] Iteration 810, lr = 0.0005
I0608 12:34:32.049574 30581 solver.cpp:243] Iteration 820, loss = 3.12589
I0608 12:34:32.049603 30581 solver.cpp:259]     Train net output #0: mbox_loss = 3.23618 (* 1 = 3.23618 loss)
I0608 12:34:32.049609 30581 sgd_solver.cpp:138] Iteration 820, lr = 0.0005
I0608 12:34:42.966431 30581 solver.cpp:243] Iteration 830, loss = 3.12701
I0608 12:34:42.966460 30581 solver.cpp:259]     Train net output #0: mbox_loss = 3.08318 (* 1 = 3.08318 loss)
I0608 12:34:42.966482 30581 sgd_solver.cpp:138] Iteration 830, lr = 0.0005
I0608 12:34:52.782729 30581 solver.cpp:243] Iteration 840, loss = 3.01887
I0608 12:34:52.782821 30581 solver.cpp:259]     Train net output #0: mbox_loss = 3.15863 (* 1 = 3.15863 loss)
I0608 12:34:52.782829 30581 sgd_solver.cpp:138] Iteration 840, lr = 0.0005
I0608 12:35:02.781054 30581 solver.cpp:243] Iteration 850, loss = 3.10328
I0608 12:35:02.781080 30581 solver.cpp:259]     Train net output #0: mbox_loss = 3.30077 (* 1 = 3.30077 loss)
I0608 12:35:02.781086 30581 sgd_solver.cpp:138] Iteration 850, lr = 0.0005
I0608 12:35:12.759871 30581 solver.cpp:243] Iteration 860, loss = 2.99502
I0608 12:35:12.759898 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.90277 (* 1 = 2.90277 loss)
I0608 12:35:12.759904 30581 sgd_solver.cpp:138] Iteration 860, lr = 0.0005
I0608 12:35:23.695302 30581 solver.cpp:243] Iteration 870, loss = 2.98268
I0608 12:35:23.695443 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.82178 (* 1 = 2.82178 loss)
I0608 12:35:23.695467 30581 sgd_solver.cpp:138] Iteration 870, lr = 0.0005
I0608 12:35:34.296258 30581 solver.cpp:243] Iteration 880, loss = 3.05814
I0608 12:35:34.296289 30581 solver.cpp:259]     Train net output #0: mbox_loss = 3.08247 (* 1 = 3.08247 loss)
I0608 12:35:34.296298 30581 sgd_solver.cpp:138] Iteration 880, lr = 0.0005
I0608 12:35:44.368728 30581 solver.cpp:243] Iteration 890, loss = 2.97431
I0608 12:35:44.368763 30581 solver.cpp:259]     Train net output #0: mbox_loss = 3.01719 (* 1 = 3.01719 loss)
I0608 12:35:44.368772 30581 sgd_solver.cpp:138] Iteration 890, lr = 0.0005
I0608 12:35:55.242805 30581 solver.cpp:243] Iteration 900, loss = 2.95673
I0608 12:35:55.242947 30581 solver.cpp:259]     Train net output #0: mbox_loss = 3.21406 (* 1 = 3.21406 loss)
I0608 12:35:55.242969 30581 sgd_solver.cpp:138] Iteration 900, lr = 0.0005
I0608 12:36:05.271631 30581 solver.cpp:243] Iteration 910, loss = 2.98489
I0608 12:36:05.271661 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.46726 (* 1 = 2.46726 loss)
I0608 12:36:05.271667 30581 sgd_solver.cpp:138] Iteration 910, lr = 0.0005
I0608 12:36:16.947998 30581 solver.cpp:243] Iteration 920, loss = 3.05314
I0608 12:36:16.948027 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.90446 (* 1 = 2.90446 loss)
I0608 12:36:16.948034 30581 sgd_solver.cpp:138] Iteration 920, lr = 0.0005
I0608 12:36:27.804978 30581 solver.cpp:243] Iteration 930, loss = 2.98767
I0608 12:36:27.805153 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.82635 (* 1 = 2.82635 loss)
I0608 12:36:27.805177 30581 sgd_solver.cpp:138] Iteration 930, lr = 0.0005
I0608 12:36:38.462833 30581 solver.cpp:243] Iteration 940, loss = 2.97878
I0608 12:36:38.462860 30581 solver.cpp:259]     Train net output #0: mbox_loss = 3.17874 (* 1 = 3.17874 loss)
I0608 12:36:38.462867 30581 sgd_solver.cpp:138] Iteration 940, lr = 0.0005
I0608 12:36:49.668189 30581 solver.cpp:243] Iteration 950, loss = 2.91752
I0608 12:36:49.668218 30581 solver.cpp:259]     Train net output #0: mbox_loss = 3.12193 (* 1 = 3.12193 loss)
I0608 12:36:49.668226 30581 sgd_solver.cpp:138] Iteration 950, lr = 0.0005
I0608 12:37:00.163331 30581 solver.cpp:243] Iteration 960, loss = 2.81632
I0608 12:37:00.163476 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.82195 (* 1 = 2.82195 loss)
I0608 12:37:00.163499 30581 sgd_solver.cpp:138] Iteration 960, lr = 0.0005
I0608 12:37:10.186204 30581 solver.cpp:243] Iteration 970, loss = 2.89366
I0608 12:37:10.186233 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.75131 (* 1 = 2.75131 loss)
I0608 12:37:10.186240 30581 sgd_solver.cpp:138] Iteration 970, lr = 0.0005
I0608 12:37:20.179592 30581 solver.cpp:243] Iteration 980, loss = 2.95459
I0608 12:37:20.179625 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.82818 (* 1 = 2.82818 loss)
I0608 12:37:20.179631 30581 sgd_solver.cpp:138] Iteration 980, lr = 0.0005
I0608 12:37:30.501582 30581 solver.cpp:243] Iteration 990, loss = 3.01878
I0608 12:37:30.501725 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.97234 (* 1 = 2.97234 loss)
I0608 12:37:30.501734 30581 sgd_solver.cpp:138] Iteration 990, lr = 0.0005
I0608 12:37:39.252287 30581 solver.cpp:433] Iteration 1000, Testing net (#0)
I0608 12:37:39.252394 30581 net.cpp:693] Ignoring source layer mbox_loss
I0608 12:37:40.927726 30581 solver.cpp:546]     Test net output #0: detection_eval = 0.769288
I0608 12:37:41.221328 30581 solver.cpp:243] Iteration 1000, loss = 2.79205
I0608 12:37:41.221359 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.65224 (* 1 = 2.65224 loss)
I0608 12:37:41.221365 30581 sgd_solver.cpp:138] Iteration 1000, lr = 0.0005
I0608 12:37:50.110009 30581 solver.cpp:243] Iteration 1010, loss = 2.94069
I0608 12:37:50.110038 30581 solver.cpp:259]     Train net output #0: mbox_loss = 3.34005 (* 1 = 3.34005 loss)
I0608 12:37:50.110044 30581 sgd_solver.cpp:138] Iteration 1010, lr = 0.0005
I0608 12:37:51.182834 30581 blocking_queue.cpp:50] Data layer prefetch queue empty
I0608 12:38:00.271415 30581 solver.cpp:243] Iteration 1020, loss = 2.80219
I0608 12:38:00.271442 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.92101 (* 1 = 2.92101 loss)
I0608 12:38:00.271447 30581 sgd_solver.cpp:138] Iteration 1020, lr = 0.0005
I0608 12:38:09.944339 30581 solver.cpp:243] Iteration 1030, loss = 2.76439
I0608 12:38:09.944489 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.98828 (* 1 = 2.98828 loss)
I0608 12:38:09.944511 30581 sgd_solver.cpp:138] Iteration 1030, lr = 0.0005
I0608 12:38:19.777387 30581 solver.cpp:243] Iteration 1040, loss = 2.77191
I0608 12:38:19.777420 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.67148 (* 1 = 2.67148 loss)
I0608 12:38:19.777442 30581 sgd_solver.cpp:138] Iteration 1040, lr = 0.0005
I0608 12:38:29.828016 30581 solver.cpp:243] Iteration 1050, loss = 2.88336
I0608 12:38:29.828042 30581 solver.cpp:259]     Train net output #0: mbox_loss = 3.44517 (* 1 = 3.44517 loss)
I0608 12:38:29.828048 30581 sgd_solver.cpp:138] Iteration 1050, lr = 0.0005
I0608 12:38:40.479684 30581 solver.cpp:243] Iteration 1060, loss = 2.80216
I0608 12:38:40.479862 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.8468 (* 1 = 2.8468 loss)
I0608 12:38:40.479885 30581 sgd_solver.cpp:138] Iteration 1060, lr = 0.0005
I0608 12:38:50.299926 30581 solver.cpp:243] Iteration 1070, loss = 2.98238
I0608 12:38:50.299957 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.80567 (* 1 = 2.80567 loss)
I0608 12:38:50.299978 30581 sgd_solver.cpp:138] Iteration 1070, lr = 0.0005
I0608 12:39:00.480726 30581 solver.cpp:243] Iteration 1080, loss = 2.86911
I0608 12:39:00.480753 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.779 (* 1 = 2.779 loss)
I0608 12:39:00.480759 30581 sgd_solver.cpp:138] Iteration 1080, lr = 0.0005
I0608 12:39:10.571651 30581 solver.cpp:243] Iteration 1090, loss = 2.73106
I0608 12:39:10.571802 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.74689 (* 1 = 2.74689 loss)
I0608 12:39:10.571825 30581 sgd_solver.cpp:138] Iteration 1090, lr = 0.0005
I0608 12:39:21.173163 30581 solver.cpp:243] Iteration 1100, loss = 2.72871
I0608 12:39:21.173187 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.82926 (* 1 = 2.82926 loss)
I0608 12:39:21.173192 30581 sgd_solver.cpp:138] Iteration 1100, lr = 0.0005
I0608 12:39:32.166834 30581 solver.cpp:243] Iteration 1110, loss = 2.69415
I0608 12:39:32.166865 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.74576 (* 1 = 2.74576 loss)
I0608 12:39:32.166872 30581 sgd_solver.cpp:138] Iteration 1110, lr = 0.0005
I0608 12:39:42.399927 30581 solver.cpp:243] Iteration 1120, loss = 2.64283
I0608 12:39:42.400091 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.46102 (* 1 = 2.46102 loss)
I0608 12:39:42.400113 30581 sgd_solver.cpp:138] Iteration 1120, lr = 0.0005
I0608 12:39:52.622685 30581 solver.cpp:243] Iteration 1130, loss = 2.88671
I0608 12:39:52.622712 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.68508 (* 1 = 2.68508 loss)
I0608 12:39:52.622717 30581 sgd_solver.cpp:138] Iteration 1130, lr = 0.0005
I0608 12:40:02.995070 30581 solver.cpp:243] Iteration 1140, loss = 2.7241
I0608 12:40:02.995100 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.50088 (* 1 = 2.50088 loss)
I0608 12:40:02.995123 30581 sgd_solver.cpp:138] Iteration 1140, lr = 0.0005
I0608 12:40:13.625406 30581 solver.cpp:243] Iteration 1150, loss = 2.61458
I0608 12:40:13.625550 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.84463 (* 1 = 2.84463 loss)
I0608 12:40:13.625572 30581 sgd_solver.cpp:138] Iteration 1150, lr = 0.0005
I0608 12:40:23.325717 30581 solver.cpp:243] Iteration 1160, loss = 2.71267
I0608 12:40:23.325745 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.55971 (* 1 = 2.55971 loss)
I0608 12:40:23.325752 30581 sgd_solver.cpp:138] Iteration 1160, lr = 0.0005
I0608 12:40:33.538053 30581 solver.cpp:243] Iteration 1170, loss = 2.73081
I0608 12:40:33.538081 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.62366 (* 1 = 2.62366 loss)
I0608 12:40:33.538087 30581 sgd_solver.cpp:138] Iteration 1170, lr = 0.0005
I0608 12:40:43.942975 30581 solver.cpp:243] Iteration 1180, loss = 2.72181
I0608 12:40:43.943130 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.67113 (* 1 = 2.67113 loss)
I0608 12:40:43.943153 30581 sgd_solver.cpp:138] Iteration 1180, lr = 0.0005
I0608 12:40:54.515192 30581 solver.cpp:243] Iteration 1190, loss = 2.50895
I0608 12:40:54.515218 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.54722 (* 1 = 2.54722 loss)
I0608 12:40:54.515223 30581 sgd_solver.cpp:138] Iteration 1190, lr = 0.0005
I0608 12:41:03.842290 30581 solver.cpp:433] Iteration 1200, Testing net (#0)
I0608 12:41:03.842355 30581 net.cpp:693] Ignoring source layer mbox_loss
I0608 12:41:05.499516 30581 solver.cpp:546]     Test net output #0: detection_eval = 0.817438
I0608 12:41:05.793329 30581 solver.cpp:243] Iteration 1200, loss = 2.57895
I0608 12:41:05.793359 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.26203 (* 1 = 2.26203 loss)
I0608 12:41:05.793365 30581 sgd_solver.cpp:138] Iteration 1200, lr = 0.0005
I0608 12:41:15.548847 30581 solver.cpp:243] Iteration 1210, loss = 2.59071
I0608 12:41:15.549003 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.57607 (* 1 = 2.57607 loss)
I0608 12:41:15.549031 30581 sgd_solver.cpp:138] Iteration 1210, lr = 0.0005
I0608 12:41:26.266568 30581 solver.cpp:243] Iteration 1220, loss = 2.74343
I0608 12:41:26.266607 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.42336 (* 1 = 2.42336 loss)
I0608 12:41:26.266628 30581 sgd_solver.cpp:138] Iteration 1220, lr = 0.0005
I0608 12:41:36.846518 30581 solver.cpp:243] Iteration 1230, loss = 2.60728
I0608 12:41:36.846549 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.44728 (* 1 = 2.44728 loss)
I0608 12:41:36.846554 30581 sgd_solver.cpp:138] Iteration 1230, lr = 0.0005
I0608 12:41:46.945545 30581 solver.cpp:243] Iteration 1240, loss = 2.66808
I0608 12:41:46.945685 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.72721 (* 1 = 2.72721 loss)
I0608 12:41:46.945694 30581 sgd_solver.cpp:138] Iteration 1240, lr = 0.0005
I0608 12:41:57.109670 30581 solver.cpp:243] Iteration 1250, loss = 2.66318
I0608 12:41:57.109699 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.76241 (* 1 = 2.76241 loss)
I0608 12:41:57.109706 30581 sgd_solver.cpp:138] Iteration 1250, lr = 0.0005
I0608 12:42:07.734344 30581 solver.cpp:243] Iteration 1260, loss = 2.61476
I0608 12:42:07.734370 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.52256 (* 1 = 2.52256 loss)
I0608 12:42:07.734376 30581 sgd_solver.cpp:138] Iteration 1260, lr = 0.0005
I0608 12:42:17.832876 30581 solver.cpp:243] Iteration 1270, loss = 2.62395
I0608 12:42:17.833032 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.7504 (* 1 = 2.7504 loss)
I0608 12:42:17.833041 30581 sgd_solver.cpp:138] Iteration 1270, lr = 0.0005
I0608 12:42:27.844998 30581 solver.cpp:243] Iteration 1280, loss = 2.63438
I0608 12:42:27.845031 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.42162 (* 1 = 2.42162 loss)
I0608 12:42:27.845052 30581 sgd_solver.cpp:138] Iteration 1280, lr = 0.0005
I0608 12:42:38.470096 30581 solver.cpp:243] Iteration 1290, loss = 2.63417
I0608 12:42:38.470125 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.45616 (* 1 = 2.45616 loss)
I0608 12:42:38.470131 30581 sgd_solver.cpp:138] Iteration 1290, lr = 0.0005
I0608 12:42:49.269762 30581 solver.cpp:243] Iteration 1300, loss = 2.68024
I0608 12:42:49.269918 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.70794 (* 1 = 2.70794 loss)
I0608 12:42:49.269942 30581 sgd_solver.cpp:138] Iteration 1300, lr = 0.0005
I0608 12:43:00.107318 30581 solver.cpp:243] Iteration 1310, loss = 2.58738
I0608 12:43:00.107345 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.62369 (* 1 = 2.62369 loss)
I0608 12:43:00.107352 30581 sgd_solver.cpp:138] Iteration 1310, lr = 0.0005
I0608 12:43:10.371767 30581 solver.cpp:243] Iteration 1320, loss = 2.70156
I0608 12:43:10.371791 30581 solver.cpp:259]     Train net output #0: mbox_loss = 3.01723 (* 1 = 3.01723 loss)
I0608 12:43:10.371798 30581 sgd_solver.cpp:138] Iteration 1320, lr = 0.0005
I0608 12:43:21.170796 30581 solver.cpp:243] Iteration 1330, loss = 2.63491
I0608 12:43:21.170934 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.84403 (* 1 = 2.84403 loss)
I0608 12:43:21.170956 30581 sgd_solver.cpp:138] Iteration 1330, lr = 0.0005
I0608 12:43:32.536970 30581 solver.cpp:243] Iteration 1340, loss = 2.49271
I0608 12:43:32.536998 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.60693 (* 1 = 2.60693 loss)
I0608 12:43:32.537003 30581 sgd_solver.cpp:138] Iteration 1340, lr = 0.0005
I0608 12:43:42.479189 30581 solver.cpp:243] Iteration 1350, loss = 2.48662
I0608 12:43:42.479219 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.3048 (* 1 = 2.3048 loss)
I0608 12:43:42.479226 30581 sgd_solver.cpp:138] Iteration 1350, lr = 0.0005
I0608 12:43:53.475903 30581 solver.cpp:243] Iteration 1360, loss = 2.42705
I0608 12:43:53.476071 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.29476 (* 1 = 2.29476 loss)
I0608 12:43:53.476094 30581 sgd_solver.cpp:138] Iteration 1360, lr = 0.0005
I0608 12:44:04.549037 30581 solver.cpp:243] Iteration 1370, loss = 2.57477
I0608 12:44:04.549063 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.66447 (* 1 = 2.66447 loss)
I0608 12:44:04.549084 30581 sgd_solver.cpp:138] Iteration 1370, lr = 0.0005
I0608 12:44:15.850392 30581 solver.cpp:243] Iteration 1380, loss = 2.55721
I0608 12:44:15.850421 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.40704 (* 1 = 2.40704 loss)
I0608 12:44:15.850427 30581 sgd_solver.cpp:138] Iteration 1380, lr = 0.0005
I0608 12:44:25.852011 30581 solver.cpp:243] Iteration 1390, loss = 2.51718
I0608 12:44:25.853040 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.70976 (* 1 = 2.70976 loss)
I0608 12:44:25.853049 30581 sgd_solver.cpp:138] Iteration 1390, lr = 0.0005
I0608 12:44:35.265939 30581 solver.cpp:433] Iteration 1400, Testing net (#0)
I0608 12:44:35.266008 30581 net.cpp:693] Ignoring source layer mbox_loss
I0608 12:44:36.955713 30581 solver.cpp:546]     Test net output #0: detection_eval = 0.764579
I0608 12:44:37.236788 30581 solver.cpp:243] Iteration 1400, loss = 2.49055
I0608 12:44:37.236816 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.55211 (* 1 = 2.55211 loss)
I0608 12:44:37.236822 30581 sgd_solver.cpp:138] Iteration 1400, lr = 0.0005
I0608 12:44:46.327978 30581 solver.cpp:243] Iteration 1410, loss = 2.53357
I0608 12:44:46.328006 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.23808 (* 1 = 2.23808 loss)
I0608 12:44:46.328027 30581 sgd_solver.cpp:138] Iteration 1410, lr = 0.0005
I0608 12:44:57.791326 30581 solver.cpp:243] Iteration 1420, loss = 2.52423
I0608 12:44:57.791476 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.58974 (* 1 = 2.58974 loss)
I0608 12:44:57.791499 30581 sgd_solver.cpp:138] Iteration 1420, lr = 0.0005
I0608 12:45:08.106426 30581 solver.cpp:243] Iteration 1430, loss = 2.51394
I0608 12:45:08.106453 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.19917 (* 1 = 2.19917 loss)
I0608 12:45:08.106458 30581 sgd_solver.cpp:138] Iteration 1430, lr = 0.0005
I0608 12:45:19.183921 30581 solver.cpp:243] Iteration 1440, loss = 2.43764
I0608 12:45:19.183954 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.21025 (* 1 = 2.21025 loss)
I0608 12:45:19.183976 30581 sgd_solver.cpp:138] Iteration 1440, lr = 0.0005
I0608 12:45:30.174720 30581 solver.cpp:243] Iteration 1450, loss = 2.52059
I0608 12:45:30.174779 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.66095 (* 1 = 2.66095 loss)
I0608 12:45:30.174801 30581 sgd_solver.cpp:138] Iteration 1450, lr = 0.0005
I0608 12:45:40.292284 30581 solver.cpp:243] Iteration 1460, loss = 2.51261
I0608 12:45:40.292315 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.60704 (* 1 = 2.60704 loss)
I0608 12:45:40.292321 30581 sgd_solver.cpp:138] Iteration 1460, lr = 0.0005
I0608 12:45:50.311537 30581 solver.cpp:243] Iteration 1470, loss = 2.45981
I0608 12:45:50.311565 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.75492 (* 1 = 2.75492 loss)
I0608 12:45:50.311571 30581 sgd_solver.cpp:138] Iteration 1470, lr = 0.0005
I0608 12:46:01.037801 30581 solver.cpp:243] Iteration 1480, loss = 2.53834
I0608 12:46:01.037942 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.189 (* 1 = 2.189 loss)
I0608 12:46:01.037964 30581 sgd_solver.cpp:138] Iteration 1480, lr = 0.0005
I0608 12:46:10.891110 30581 solver.cpp:243] Iteration 1490, loss = 2.34115
I0608 12:46:10.891141 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.50546 (* 1 = 2.50546 loss)
I0608 12:46:10.891147 30581 sgd_solver.cpp:138] Iteration 1490, lr = 0.0005
I0608 12:46:21.698806 30581 solver.cpp:243] Iteration 1500, loss = 2.61067
I0608 12:46:21.698834 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.74856 (* 1 = 2.74856 loss)
I0608 12:46:21.698856 30581 sgd_solver.cpp:138] Iteration 1500, lr = 0.0005
I0608 12:46:32.033329 30581 solver.cpp:243] Iteration 1510, loss = 2.46785
I0608 12:46:32.033501 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.22957 (* 1 = 2.22957 loss)
I0608 12:46:32.033524 30581 sgd_solver.cpp:138] Iteration 1510, lr = 0.0005
I0608 12:46:42.003355 30581 solver.cpp:243] Iteration 1520, loss = 2.46455
I0608 12:46:42.003386 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.59179 (* 1 = 2.59179 loss)
I0608 12:46:42.003392 30581 sgd_solver.cpp:138] Iteration 1520, lr = 0.0005
I0608 12:46:51.187880 30581 solver.cpp:243] Iteration 1530, loss = 2.41591
I0608 12:46:51.187911 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.23789 (* 1 = 2.23789 loss)
I0608 12:46:51.187932 30581 sgd_solver.cpp:138] Iteration 1530, lr = 0.0005
I0608 12:47:01.052220 30581 solver.cpp:243] Iteration 1540, loss = 2.41267
I0608 12:47:01.052251 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.08043 (* 1 = 2.08043 loss)
I0608 12:47:01.052258 30581 sgd_solver.cpp:138] Iteration 1540, lr = 0.0005
I0608 12:47:11.800343 30581 solver.cpp:243] Iteration 1550, loss = 2.40206
I0608 12:47:11.800485 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.29389 (* 1 = 2.29389 loss)
I0608 12:47:11.800508 30581 sgd_solver.cpp:138] Iteration 1550, lr = 0.0005
I0608 12:47:22.528671 30581 solver.cpp:243] Iteration 1560, loss = 2.52679
I0608 12:47:22.528714 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.53578 (* 1 = 2.53578 loss)
I0608 12:47:22.528719 30581 sgd_solver.cpp:138] Iteration 1560, lr = 0.0005
I0608 12:47:32.791373 30581 solver.cpp:243] Iteration 1570, loss = 2.51226
I0608 12:47:32.791401 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.74349 (* 1 = 2.74349 loss)
I0608 12:47:32.791407 30581 sgd_solver.cpp:138] Iteration 1570, lr = 0.0005
I0608 12:47:43.335767 30581 solver.cpp:243] Iteration 1580, loss = 2.41732
I0608 12:47:43.335927 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.07867 (* 1 = 2.07867 loss)
I0608 12:47:43.335950 30581 sgd_solver.cpp:138] Iteration 1580, lr = 0.0005
I0608 12:47:53.302711 30581 solver.cpp:243] Iteration 1590, loss = 2.34091
I0608 12:47:53.302742 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.6184 (* 1 = 2.6184 loss)
I0608 12:47:53.302762 30581 sgd_solver.cpp:138] Iteration 1590, lr = 0.0005
I0608 12:48:02.671741 30581 solver.cpp:433] Iteration 1600, Testing net (#0)
I0608 12:48:02.671802 30581 net.cpp:693] Ignoring source layer mbox_loss
I0608 12:48:04.344693 30581 solver.cpp:546]     Test net output #0: detection_eval = 0.785249
I0608 12:48:04.639066 30581 solver.cpp:243] Iteration 1600, loss = 2.41281
I0608 12:48:04.639096 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.65442 (* 1 = 2.65442 loss)
I0608 12:48:04.639101 30581 sgd_solver.cpp:138] Iteration 1600, lr = 0.0005
I0608 12:48:14.667028 30581 solver.cpp:243] Iteration 1610, loss = 2.2731
I0608 12:48:14.667776 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.10852 (* 1 = 2.10852 loss)
I0608 12:48:14.667800 30581 sgd_solver.cpp:138] Iteration 1610, lr = 0.0005
I0608 12:48:24.467114 30581 solver.cpp:243] Iteration 1620, loss = 2.33895
I0608 12:48:24.467147 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.08765 (* 1 = 2.08765 loss)
I0608 12:48:24.467167 30581 sgd_solver.cpp:138] Iteration 1620, lr = 0.0005
I0608 12:48:35.293002 30581 solver.cpp:243] Iteration 1630, loss = 2.2803
I0608 12:48:35.293033 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.8053 (* 1 = 2.8053 loss)
I0608 12:48:35.293054 30581 sgd_solver.cpp:138] Iteration 1630, lr = 0.0005
I0608 12:48:45.925029 30581 solver.cpp:243] Iteration 1640, loss = 2.35199
I0608 12:48:45.925165 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.38789 (* 1 = 2.38789 loss)
I0608 12:48:45.925187 30581 sgd_solver.cpp:138] Iteration 1640, lr = 0.0005
I0608 12:48:55.314257 30581 solver.cpp:243] Iteration 1650, loss = 2.21374
I0608 12:48:55.314285 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.34146 (* 1 = 2.34146 loss)
I0608 12:48:55.314292 30581 sgd_solver.cpp:138] Iteration 1650, lr = 0.0005
I0608 12:49:05.657954 30581 solver.cpp:243] Iteration 1660, loss = 2.21078
I0608 12:49:05.657982 30581 solver.cpp:259]     Train net output #0: mbox_loss = 1.90273 (* 1 = 1.90273 loss)
I0608 12:49:05.657987 30581 sgd_solver.cpp:138] Iteration 1660, lr = 0.0005
I0608 12:49:15.645349 30581 solver.cpp:243] Iteration 1670, loss = 2.30997
I0608 12:49:15.645373 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.13033 (* 1 = 2.13033 loss)
I0608 12:49:15.645380 30581 sgd_solver.cpp:138] Iteration 1670, lr = 0.0005
I0608 12:49:25.704874 30581 solver.cpp:243] Iteration 1680, loss = 2.43343
I0608 12:49:25.705065 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.20807 (* 1 = 2.20807 loss)
I0608 12:49:25.705090 30581 sgd_solver.cpp:138] Iteration 1680, lr = 0.0005
I0608 12:49:36.289350 30581 solver.cpp:243] Iteration 1690, loss = 2.29298
I0608 12:49:36.289379 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.57771 (* 1 = 2.57771 loss)
I0608 12:49:36.289386 30581 sgd_solver.cpp:138] Iteration 1690, lr = 0.0005
I0608 12:49:46.951031 30581 solver.cpp:243] Iteration 1700, loss = 2.37568
I0608 12:49:46.951061 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.61935 (* 1 = 2.61935 loss)
I0608 12:49:46.951066 30581 sgd_solver.cpp:138] Iteration 1700, lr = 0.0005
I0608 12:49:57.239738 30581 solver.cpp:243] Iteration 1710, loss = 2.21859
I0608 12:49:57.239890 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.07969 (* 1 = 2.07969 loss)
I0608 12:49:57.239913 30581 sgd_solver.cpp:138] Iteration 1710, lr = 0.0005
I0608 12:50:08.173230 30581 solver.cpp:243] Iteration 1720, loss = 2.26154
I0608 12:50:08.173257 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.54654 (* 1 = 2.54654 loss)
I0608 12:50:08.173264 30581 sgd_solver.cpp:138] Iteration 1720, lr = 0.0005
I0608 12:50:18.401628 30581 solver.cpp:243] Iteration 1730, loss = 2.22772
I0608 12:50:18.401659 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.37591 (* 1 = 2.37591 loss)
I0608 12:50:18.401665 30581 sgd_solver.cpp:138] Iteration 1730, lr = 0.0005
I0608 12:50:28.454736 30581 solver.cpp:243] Iteration 1740, loss = 2.24883
I0608 12:50:28.454891 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.63213 (* 1 = 2.63213 loss)
I0608 12:50:28.454915 30581 sgd_solver.cpp:138] Iteration 1740, lr = 0.0005
I0608 12:50:38.565281 30581 solver.cpp:243] Iteration 1750, loss = 2.38498
I0608 12:50:38.565313 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.56894 (* 1 = 2.56894 loss)
I0608 12:50:38.565335 30581 sgd_solver.cpp:138] Iteration 1750, lr = 0.0005
I0608 12:50:48.931790 30581 solver.cpp:243] Iteration 1760, loss = 2.27889
I0608 12:50:48.931821 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.23822 (* 1 = 2.23822 loss)
I0608 12:50:48.931843 30581 sgd_solver.cpp:138] Iteration 1760, lr = 0.0005
I0608 12:50:59.763283 30581 solver.cpp:243] Iteration 1770, loss = 2.35216
I0608 12:50:59.763443 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.4109 (* 1 = 2.4109 loss)
I0608 12:50:59.763453 30581 sgd_solver.cpp:138] Iteration 1770, lr = 0.0005
I0608 12:51:09.603587 30581 solver.cpp:243] Iteration 1780, loss = 2.30859
I0608 12:51:09.603617 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.2353 (* 1 = 2.2353 loss)
I0608 12:51:09.603637 30581 sgd_solver.cpp:138] Iteration 1780, lr = 0.0005
I0608 12:51:20.024154 30581 solver.cpp:243] Iteration 1790, loss = 2.17076
I0608 12:51:20.024185 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.06884 (* 1 = 2.06884 loss)
I0608 12:51:20.024191 30581 sgd_solver.cpp:138] Iteration 1790, lr = 0.0005
I0608 12:51:28.570003 30581 solver.cpp:433] Iteration 1800, Testing net (#0)
I0608 12:51:28.570068 30581 net.cpp:693] Ignoring source layer mbox_loss
I0608 12:51:30.218420 30581 solver.cpp:546]     Test net output #0: detection_eval = 0.770506
I0608 12:51:30.515296 30581 solver.cpp:243] Iteration 1800, loss = 2.32186
I0608 12:51:30.515324 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.45043 (* 1 = 2.45043 loss)
I0608 12:51:30.515346 30581 sgd_solver.cpp:138] Iteration 1800, lr = 0.0005
I0608 12:51:40.277251 30581 solver.cpp:243] Iteration 1810, loss = 2.30874
I0608 12:51:40.277281 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.15751 (* 1 = 2.15751 loss)
I0608 12:51:40.277305 30581 sgd_solver.cpp:138] Iteration 1810, lr = 0.0005
I0608 12:51:51.203485 30581 solver.cpp:243] Iteration 1820, loss = 2.22363
I0608 12:51:51.203514 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.02002 (* 1 = 2.02002 loss)
I0608 12:51:51.203521 30581 sgd_solver.cpp:138] Iteration 1820, lr = 0.0005
I0608 12:52:01.777787 30581 solver.cpp:243] Iteration 1830, loss = 2.2353
I0608 12:52:01.777950 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.15363 (* 1 = 2.15363 loss)
I0608 12:52:01.777971 30581 sgd_solver.cpp:138] Iteration 1830, lr = 0.0005
I0608 12:52:11.708150 30581 solver.cpp:243] Iteration 1840, loss = 2.18413
I0608 12:52:11.708175 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.37593 (* 1 = 2.37593 loss)
I0608 12:52:11.708181 30581 sgd_solver.cpp:138] Iteration 1840, lr = 0.0005
I0608 12:52:21.846262 30581 solver.cpp:243] Iteration 1850, loss = 2.16448
I0608 12:52:21.846292 30581 solver.cpp:259]     Train net output #0: mbox_loss = 1.89406 (* 1 = 1.89406 loss)
I0608 12:52:21.846297 30581 sgd_solver.cpp:138] Iteration 1850, lr = 0.0005
I0608 12:52:32.053310 30581 solver.cpp:243] Iteration 1860, loss = 2.13995
I0608 12:52:32.053483 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.00696 (* 1 = 2.00696 loss)
I0608 12:52:32.053505 30581 sgd_solver.cpp:138] Iteration 1860, lr = 0.0005
I0608 12:52:42.764152 30581 solver.cpp:243] Iteration 1870, loss = 2.21151
I0608 12:52:42.764180 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.21526 (* 1 = 2.21526 loss)
I0608 12:52:42.764202 30581 sgd_solver.cpp:138] Iteration 1870, lr = 0.0005
I0608 12:52:53.490694 30581 solver.cpp:243] Iteration 1880, loss = 2.20767
I0608 12:52:53.490722 30581 solver.cpp:259]     Train net output #0: mbox_loss = 1.88008 (* 1 = 1.88008 loss)
I0608 12:52:53.490730 30581 sgd_solver.cpp:138] Iteration 1880, lr = 0.0005
I0608 12:53:03.551074 30581 solver.cpp:243] Iteration 1890, loss = 2.07094
I0608 12:53:03.551220 30581 solver.cpp:259]     Train net output #0: mbox_loss = 1.91085 (* 1 = 1.91085 loss)
I0608 12:53:03.551244 30581 sgd_solver.cpp:138] Iteration 1890, lr = 0.0005
I0608 12:53:14.216159 30581 solver.cpp:243] Iteration 1900, loss = 2.13717
I0608 12:53:14.216186 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.42759 (* 1 = 2.42759 loss)
I0608 12:53:14.216192 30581 sgd_solver.cpp:138] Iteration 1900, lr = 0.0005
I0608 12:53:23.997898 30581 solver.cpp:243] Iteration 1910, loss = 2.14314
I0608 12:53:23.997926 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.06827 (* 1 = 2.06827 loss)
I0608 12:53:23.997932 30581 sgd_solver.cpp:138] Iteration 1910, lr = 0.0005
I0608 12:53:34.073104 30581 solver.cpp:243] Iteration 1920, loss = 2.18544
I0608 12:53:34.073253 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.42988 (* 1 = 2.42988 loss)
I0608 12:53:34.073276 30581 sgd_solver.cpp:138] Iteration 1920, lr = 0.0005
I0608 12:53:44.036803 30581 solver.cpp:243] Iteration 1930, loss = 2.16527
I0608 12:53:44.036830 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.14944 (* 1 = 2.14944 loss)
I0608 12:53:44.036836 30581 sgd_solver.cpp:138] Iteration 1930, lr = 0.0005
I0608 12:53:54.481951 30581 solver.cpp:243] Iteration 1940, loss = 2.18376
I0608 12:53:54.481979 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.44556 (* 1 = 2.44556 loss)
I0608 12:53:54.481999 30581 sgd_solver.cpp:138] Iteration 1940, lr = 0.0005
I0608 12:54:04.810444 30581 solver.cpp:243] Iteration 1950, loss = 2.23375
I0608 12:54:04.810593 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.37257 (* 1 = 2.37257 loss)
I0608 12:54:04.810616 30581 sgd_solver.cpp:138] Iteration 1950, lr = 0.0005
I0608 12:54:15.482430 30581 solver.cpp:243] Iteration 1960, loss = 2.15023
I0608 12:54:15.482458 30581 solver.cpp:259]     Train net output #0: mbox_loss = 1.87933 (* 1 = 1.87933 loss)
I0608 12:54:15.482480 30581 sgd_solver.cpp:138] Iteration 1960, lr = 0.0005
I0608 12:54:25.676024 30581 solver.cpp:243] Iteration 1970, loss = 2.18063
I0608 12:54:25.676055 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.1628 (* 1 = 2.1628 loss)
I0608 12:54:25.676061 30581 sgd_solver.cpp:138] Iteration 1970, lr = 0.0005
I0608 12:54:36.493533 30581 solver.cpp:243] Iteration 1980, loss = 2.02661
I0608 12:54:36.493708 30581 solver.cpp:259]     Train net output #0: mbox_loss = 1.8871 (* 1 = 1.8871 loss)
I0608 12:54:36.493731 30581 sgd_solver.cpp:138] Iteration 1980, lr = 0.0005
I0608 12:54:47.694779 30581 solver.cpp:243] Iteration 1990, loss = 2.19801
I0608 12:54:47.694809 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.20617 (* 1 = 2.20617 loss)
I0608 12:54:47.694814 30581 sgd_solver.cpp:138] Iteration 1990, lr = 0.0005
I0608 12:54:56.561105 30581 solver.cpp:596] Snapshotting to binary proto file models/VGGNet/sharpen_tbs_v2.0/SSD_300x300/VGG_sharpen_tbs_v2.0_SSD_300x300_iter_2000.caffemodel
I0608 12:54:57.396024 30581 sgd_solver.cpp:307] Snapshotting solver state to binary proto file models/VGGNet/sharpen_tbs_v2.0/SSD_300x300/VGG_sharpen_tbs_v2.0_SSD_300x300_iter_2000.solverstate
I0608 12:54:57.496546 30581 solver.cpp:433] Iteration 2000, Testing net (#0)
I0608 12:54:57.496626 30581 net.cpp:693] Ignoring source layer mbox_loss
I0608 12:54:58.633801 30581 solver.cpp:546]     Test net output #0: detection_eval = 0.840459
I0608 12:54:58.934816 30581 solver.cpp:243] Iteration 2000, loss = 2.04972
I0608 12:54:58.934847 30581 solver.cpp:259]     Train net output #0: mbox_loss = 1.96543 (* 1 = 1.96543 loss)
I0608 12:54:58.934854 30581 sgd_solver.cpp:138] Iteration 2000, lr = 0.0005
I0608 12:55:08.579993 30581 solver.cpp:243] Iteration 2010, loss = 2.15122
I0608 12:55:08.580145 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.18391 (* 1 = 2.18391 loss)
I0608 12:55:08.580168 30581 sgd_solver.cpp:138] Iteration 2010, lr = 0.0005
I0608 12:55:18.582212 30581 solver.cpp:243] Iteration 2020, loss = 2.10663
I0608 12:55:18.582238 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.11112 (* 1 = 2.11112 loss)
I0608 12:55:18.582259 30581 sgd_solver.cpp:138] Iteration 2020, lr = 0.0005
I0608 12:55:23.054680 30581 blocking_queue.cpp:50] Data layer prefetch queue empty
I0608 12:55:28.077885 30581 solver.cpp:243] Iteration 2030, loss = 2.05306
I0608 12:55:28.077914 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.11481 (* 1 = 2.11481 loss)
I0608 12:55:28.077920 30581 sgd_solver.cpp:138] Iteration 2030, lr = 0.0005
I0608 12:55:37.956933 30581 solver.cpp:243] Iteration 2040, loss = 1.97871
I0608 12:55:37.956964 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.14345 (* 1 = 2.14345 loss)
I0608 12:55:37.956969 30581 sgd_solver.cpp:138] Iteration 2040, lr = 0.0005
I0608 12:55:48.962393 30581 solver.cpp:243] Iteration 2050, loss = 2.07622
I0608 12:55:48.962555 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.36719 (* 1 = 2.36719 loss)
I0608 12:55:48.962579 30581 sgd_solver.cpp:138] Iteration 2050, lr = 0.0005
I0608 12:56:00.119012 30581 solver.cpp:243] Iteration 2060, loss = 2.06802
I0608 12:56:00.119040 30581 solver.cpp:259]     Train net output #0: mbox_loss = 1.87657 (* 1 = 1.87657 loss)
I0608 12:56:00.119045 30581 sgd_solver.cpp:138] Iteration 2060, lr = 0.0005
I0608 12:56:10.207846 30581 solver.cpp:243] Iteration 2070, loss = 2.05956
I0608 12:56:10.207875 30581 solver.cpp:259]     Train net output #0: mbox_loss = 1.91362 (* 1 = 1.91362 loss)
I0608 12:56:10.207896 30581 sgd_solver.cpp:138] Iteration 2070, lr = 0.0005
I0608 12:56:20.738451 30581 solver.cpp:243] Iteration 2080, loss = 2.002
I0608 12:56:20.738602 30581 solver.cpp:259]     Train net output #0: mbox_loss = 1.91249 (* 1 = 1.91249 loss)
I0608 12:56:20.738626 30581 sgd_solver.cpp:138] Iteration 2080, lr = 0.0005
I0608 12:56:30.950480 30581 solver.cpp:243] Iteration 2090, loss = 1.94905
I0608 12:56:30.950510 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.47552 (* 1 = 2.47552 loss)
I0608 12:56:30.950515 30581 sgd_solver.cpp:138] Iteration 2090, lr = 0.0005
I0608 12:56:41.659778 30581 solver.cpp:243] Iteration 2100, loss = 2.08012
I0608 12:56:41.659803 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.04062 (* 1 = 2.04062 loss)
I0608 12:56:41.659811 30581 sgd_solver.cpp:138] Iteration 2100, lr = 0.0005
I0608 12:56:52.913271 30581 solver.cpp:243] Iteration 2110, loss = 2.08657
I0608 12:56:52.913482 30581 solver.cpp:259]     Train net output #0: mbox_loss = 1.90151 (* 1 = 1.90151 loss)
I0608 12:56:52.913506 30581 sgd_solver.cpp:138] Iteration 2110, lr = 0.0005
I0608 12:57:03.074249 30581 solver.cpp:243] Iteration 2120, loss = 2.09812
I0608 12:57:03.074275 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.17718 (* 1 = 2.17718 loss)
I0608 12:57:03.074280 30581 sgd_solver.cpp:138] Iteration 2120, lr = 0.0005
I0608 12:57:13.211766 30581 solver.cpp:243] Iteration 2130, loss = 2.13862
I0608 12:57:13.211794 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.22236 (* 1 = 2.22236 loss)
I0608 12:57:13.211800 30581 sgd_solver.cpp:138] Iteration 2130, lr = 0.0005
I0608 12:57:23.061247 30581 solver.cpp:243] Iteration 2140, loss = 2.06388
I0608 12:57:23.061398 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.41172 (* 1 = 2.41172 loss)
I0608 12:57:23.061422 30581 sgd_solver.cpp:138] Iteration 2140, lr = 0.0005
I0608 12:57:32.750491 30581 solver.cpp:243] Iteration 2150, loss = 2.07828
I0608 12:57:32.750519 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.00669 (* 1 = 2.00669 loss)
I0608 12:57:32.750524 30581 sgd_solver.cpp:138] Iteration 2150, lr = 0.0005
I0608 12:57:43.954051 30581 solver.cpp:243] Iteration 2160, loss = 2.03854
I0608 12:57:43.954079 30581 solver.cpp:259]     Train net output #0: mbox_loss = 1.89081 (* 1 = 1.89081 loss)
I0608 12:57:43.954085 30581 sgd_solver.cpp:138] Iteration 2160, lr = 0.0005
I0608 12:57:54.058169 30581 solver.cpp:243] Iteration 2170, loss = 2.06457
I0608 12:57:54.058327 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.13501 (* 1 = 2.13501 loss)
I0608 12:57:54.058351 30581 sgd_solver.cpp:138] Iteration 2170, lr = 0.0005
I0608 12:58:04.582475 30581 solver.cpp:243] Iteration 2180, loss = 2.00096
I0608 12:58:04.582501 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.21132 (* 1 = 2.21132 loss)
I0608 12:58:04.582509 30581 sgd_solver.cpp:138] Iteration 2180, lr = 0.0005
I0608 12:58:14.545697 30581 solver.cpp:243] Iteration 2190, loss = 1.93406
I0608 12:58:14.545725 30581 solver.cpp:259]     Train net output #0: mbox_loss = 1.93765 (* 1 = 1.93765 loss)
I0608 12:58:14.545732 30581 sgd_solver.cpp:138] Iteration 2190, lr = 0.0005
I0608 12:58:23.609177 30581 solver.cpp:433] Iteration 2200, Testing net (#0)
I0608 12:58:23.609254 30581 net.cpp:693] Ignoring source layer mbox_loss
I0608 12:58:25.320940 30581 solver.cpp:546]     Test net output #0: detection_eval = 0.828719
I0608 12:58:25.619686 30581 solver.cpp:243] Iteration 2200, loss = 2.04814
I0608 12:58:25.619710 30581 solver.cpp:259]     Train net output #0: mbox_loss = 1.80219 (* 1 = 1.80219 loss)
I0608 12:58:25.619715 30581 sgd_solver.cpp:138] Iteration 2200, lr = 0.0005
I0608 12:58:35.108889 30581 solver.cpp:243] Iteration 2210, loss = 2.03667
I0608 12:58:35.108932 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.08072 (* 1 = 2.08072 loss)
I0608 12:58:35.108953 30581 sgd_solver.cpp:138] Iteration 2210, lr = 0.0005
I0608 12:58:45.931042 30581 solver.cpp:243] Iteration 2220, loss = 1.99951
I0608 12:58:45.931072 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.02475 (* 1 = 2.02475 loss)
I0608 12:58:45.931077 30581 sgd_solver.cpp:138] Iteration 2220, lr = 0.0005
I0608 12:58:55.438565 30581 solver.cpp:243] Iteration 2230, loss = 2.07039
I0608 12:58:55.438699 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.03244 (* 1 = 2.03244 loss)
I0608 12:58:55.438722 30581 sgd_solver.cpp:138] Iteration 2230, lr = 0.0005
I0608 12:59:06.371225 30581 solver.cpp:243] Iteration 2240, loss = 2.08135
I0608 12:59:06.371255 30581 solver.cpp:259]     Train net output #0: mbox_loss = 1.88834 (* 1 = 1.88834 loss)
I0608 12:59:06.371261 30581 sgd_solver.cpp:138] Iteration 2240, lr = 0.0005
I0608 12:59:16.663045 30581 solver.cpp:243] Iteration 2250, loss = 2.04158
I0608 12:59:16.663070 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.3774 (* 1 = 2.3774 loss)
I0608 12:59:16.663091 30581 sgd_solver.cpp:138] Iteration 2250, lr = 0.0005
I0608 12:59:26.355293 30581 solver.cpp:243] Iteration 2260, loss = 2.13654
I0608 12:59:26.355460 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.19403 (* 1 = 2.19403 loss)
I0608 12:59:26.355484 30581 sgd_solver.cpp:138] Iteration 2260, lr = 0.0005
I0608 12:59:36.128516 30581 solver.cpp:243] Iteration 2270, loss = 1.88283
I0608 12:59:36.128546 30581 solver.cpp:259]     Train net output #0: mbox_loss = 1.69333 (* 1 = 1.69333 loss)
I0608 12:59:36.128552 30581 sgd_solver.cpp:138] Iteration 2270, lr = 0.0005
I0608 12:59:46.485014 30581 solver.cpp:243] Iteration 2280, loss = 2.02121
I0608 12:59:46.485060 30581 solver.cpp:259]     Train net output #0: mbox_loss = 1.97966 (* 1 = 1.97966 loss)
I0608 12:59:46.485066 30581 sgd_solver.cpp:138] Iteration 2280, lr = 0.0005
I0608 12:59:56.915352 30581 solver.cpp:243] Iteration 2290, loss = 1.99424
I0608 12:59:56.915506 30581 solver.cpp:259]     Train net output #0: mbox_loss = 1.83161 (* 1 = 1.83161 loss)
I0608 12:59:56.915530 30581 sgd_solver.cpp:138] Iteration 2290, lr = 0.0005
I0608 13:00:07.021654 30581 solver.cpp:243] Iteration 2300, loss = 1.88324
I0608 13:00:07.021682 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.07646 (* 1 = 2.07646 loss)
I0608 13:00:07.021688 30581 sgd_solver.cpp:138] Iteration 2300, lr = 0.0005
I0608 13:00:17.807426 30581 solver.cpp:243] Iteration 2310, loss = 2.0411
I0608 13:00:17.807456 30581 solver.cpp:259]     Train net output #0: mbox_loss = 1.75293 (* 1 = 1.75293 loss)
I0608 13:00:17.807477 30581 sgd_solver.cpp:138] Iteration 2310, lr = 0.0005
I0608 13:00:28.460821 30581 solver.cpp:243] Iteration 2320, loss = 2.06197
I0608 13:00:28.460870 30581 solver.cpp:259]     Train net output #0: mbox_loss = 1.86687 (* 1 = 1.86687 loss)
I0608 13:00:28.460891 30581 sgd_solver.cpp:138] Iteration 2320, lr = 0.0005
I0608 13:00:38.642170 30581 solver.cpp:243] Iteration 2330, loss = 2.03046
I0608 13:00:38.642196 30581 solver.cpp:259]     Train net output #0: mbox_loss = 1.9434 (* 1 = 1.9434 loss)
I0608 13:00:38.642202 30581 sgd_solver.cpp:138] Iteration 2330, lr = 0.0005
I0608 13:00:49.291824 30581 solver.cpp:243] Iteration 2340, loss = 2.03086
I0608 13:00:49.291851 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.13994 (* 1 = 2.13994 loss)
I0608 13:00:49.291857 30581 sgd_solver.cpp:138] Iteration 2340, lr = 0.0005
I0608 13:00:58.973397 30581 solver.cpp:243] Iteration 2350, loss = 1.84485
I0608 13:00:58.973531 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.25024 (* 1 = 2.25024 loss)
I0608 13:00:58.973554 30581 sgd_solver.cpp:138] Iteration 2350, lr = 0.0005
I0608 13:01:09.008822 30581 solver.cpp:243] Iteration 2360, loss = 1.88013
I0608 13:01:09.008852 30581 solver.cpp:259]     Train net output #0: mbox_loss = 1.75159 (* 1 = 1.75159 loss)
I0608 13:01:09.008857 30581 sgd_solver.cpp:138] Iteration 2360, lr = 0.0005
I0608 13:01:18.913455 30581 solver.cpp:243] Iteration 2370, loss = 2.0088
I0608 13:01:18.913485 30581 solver.cpp:259]     Train net output #0: mbox_loss = 1.86611 (* 1 = 1.86611 loss)
I0608 13:01:18.913491 30581 sgd_solver.cpp:138] Iteration 2370, lr = 0.0005
I0608 13:01:29.245842 30581 solver.cpp:243] Iteration 2380, loss = 1.97658
I0608 13:01:29.245998 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.0787 (* 1 = 2.0787 loss)
I0608 13:01:29.246007 30581 sgd_solver.cpp:138] Iteration 2380, lr = 0.0005
I0608 13:01:39.969854 30581 solver.cpp:243] Iteration 2390, loss = 2.00419
I0608 13:01:39.969884 30581 solver.cpp:259]     Train net output #0: mbox_loss = 1.93196 (* 1 = 1.93196 loss)
I0608 13:01:39.969890 30581 sgd_solver.cpp:138] Iteration 2390, lr = 0.0005
I0608 13:01:48.775508 30581 solver.cpp:433] Iteration 2400, Testing net (#0)
I0608 13:01:48.775573 30581 net.cpp:693] Ignoring source layer mbox_loss
I0608 13:01:50.404144 30581 solver.cpp:546]     Test net output #0: detection_eval = 0.837321
I0608 13:01:50.701337 30581 solver.cpp:243] Iteration 2400, loss = 2.01133
I0608 13:01:50.701364 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.00969 (* 1 = 2.00969 loss)
I0608 13:01:50.701370 30581 sgd_solver.cpp:138] Iteration 2400, lr = 0.0005
I0608 13:02:00.064965 30581 solver.cpp:243] Iteration 2410, loss = 1.85784
I0608 13:02:00.065129 30581 solver.cpp:259]     Train net output #0: mbox_loss = 1.7346 (* 1 = 1.7346 loss)
I0608 13:02:00.065152 30581 sgd_solver.cpp:138] Iteration 2410, lr = 0.0005
I0608 13:02:09.673363 30581 solver.cpp:243] Iteration 2420, loss = 1.8119
I0608 13:02:09.673391 30581 solver.cpp:259]     Train net output #0: mbox_loss = 1.99911 (* 1 = 1.99911 loss)
I0608 13:02:09.673398 30581 sgd_solver.cpp:138] Iteration 2420, lr = 0.0005
I0608 13:02:19.731947 30581 solver.cpp:243] Iteration 2430, loss = 1.86816
I0608 13:02:19.731974 30581 solver.cpp:259]     Train net output #0: mbox_loss = 1.65235 (* 1 = 1.65235 loss)
I0608 13:02:19.731979 30581 sgd_solver.cpp:138] Iteration 2430, lr = 0.0005
I0608 13:02:30.094266 30581 solver.cpp:243] Iteration 2440, loss = 1.82271
I0608 13:02:30.094403 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.04752 (* 1 = 2.04752 loss)
I0608 13:02:30.094426 30581 sgd_solver.cpp:138] Iteration 2440, lr = 0.0005
I0608 13:02:40.173782 30581 solver.cpp:243] Iteration 2450, loss = 1.87545
I0608 13:02:40.173811 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.19059 (* 1 = 2.19059 loss)
I0608 13:02:40.173832 30581 sgd_solver.cpp:138] Iteration 2450, lr = 0.0005
I0608 13:02:50.452461 30581 solver.cpp:243] Iteration 2460, loss = 2.11681
I0608 13:02:50.452489 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.29533 (* 1 = 2.29533 loss)
I0608 13:02:50.452494 30581 sgd_solver.cpp:138] Iteration 2460, lr = 0.0005
I0608 13:03:00.483603 30581 solver.cpp:243] Iteration 2470, loss = 1.92273
I0608 13:03:00.483757 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.1193 (* 1 = 2.1193 loss)
I0608 13:03:00.483779 30581 sgd_solver.cpp:138] Iteration 2470, lr = 0.0005
I0608 13:03:11.088330 30581 solver.cpp:243] Iteration 2480, loss = 1.83033
I0608 13:03:11.088358 30581 solver.cpp:259]     Train net output #0: mbox_loss = 1.69493 (* 1 = 1.69493 loss)
I0608 13:03:11.088382 30581 sgd_solver.cpp:138] Iteration 2480, lr = 0.0005
I0608 13:03:21.800581 30581 solver.cpp:243] Iteration 2490, loss = 1.75802
I0608 13:03:21.800611 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.02759 (* 1 = 2.02759 loss)
I0608 13:03:21.800616 30581 sgd_solver.cpp:138] Iteration 2490, lr = 0.0005
I0608 13:03:32.596007 30581 solver.cpp:243] Iteration 2500, loss = 1.87673
I0608 13:03:32.596158 30581 solver.cpp:259]     Train net output #0: mbox_loss = 1.91719 (* 1 = 1.91719 loss)
I0608 13:03:32.596180 30581 sgd_solver.cpp:138] Iteration 2500, lr = 0.0005
I0608 13:03:42.534631 30581 solver.cpp:243] Iteration 2510, loss = 2.00964
I0608 13:03:42.534657 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.04779 (* 1 = 2.04779 loss)
I0608 13:03:42.534662 30581 sgd_solver.cpp:138] Iteration 2510, lr = 0.0005
I0608 13:03:51.978703 30581 solver.cpp:243] Iteration 2520, loss = 1.8058
I0608 13:03:51.978731 30581 solver.cpp:259]     Train net output #0: mbox_loss = 1.66013 (* 1 = 1.66013 loss)
I0608 13:03:51.978752 30581 sgd_solver.cpp:138] Iteration 2520, lr = 0.0005
I0608 13:04:02.028820 30581 solver.cpp:243] Iteration 2530, loss = 1.86879
I0608 13:04:02.028851 30581 solver.cpp:259]     Train net output #0: mbox_loss = 1.83608 (* 1 = 1.83608 loss)
I0608 13:04:02.028857 30581 sgd_solver.cpp:138] Iteration 2530, lr = 0.0005
I0608 13:04:11.458369 30581 solver.cpp:243] Iteration 2540, loss = 1.89396
I0608 13:04:11.458554 30581 solver.cpp:259]     Train net output #0: mbox_loss = 1.71989 (* 1 = 1.71989 loss)
I0608 13:04:11.458576 30581 sgd_solver.cpp:138] Iteration 2540, lr = 0.0005
I0608 13:04:21.262826 30581 solver.cpp:243] Iteration 2550, loss = 1.85989
I0608 13:04:21.262854 30581 solver.cpp:259]     Train net output #0: mbox_loss = 1.74802 (* 1 = 1.74802 loss)
I0608 13:04:21.262861 30581 sgd_solver.cpp:138] Iteration 2550, lr = 0.0005
I0608 13:04:31.789654 30581 solver.cpp:243] Iteration 2560, loss = 1.92012
I0608 13:04:31.789683 30581 solver.cpp:259]     Train net output #0: mbox_loss = 1.76514 (* 1 = 1.76514 loss)
I0608 13:04:31.789688 30581 sgd_solver.cpp:138] Iteration 2560, lr = 0.0005
I0608 13:04:42.976398 30581 solver.cpp:243] Iteration 2570, loss = 1.98476
I0608 13:04:42.976541 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.30473 (* 1 = 2.30473 loss)
I0608 13:04:42.976563 30581 sgd_solver.cpp:138] Iteration 2570, lr = 0.0005
I0608 13:04:52.972853 30581 solver.cpp:243] Iteration 2580, loss = 1.89046
I0608 13:04:52.972883 30581 solver.cpp:259]     Train net output #0: mbox_loss = 1.86014 (* 1 = 1.86014 loss)
I0608 13:04:52.972889 30581 sgd_solver.cpp:138] Iteration 2580, lr = 0.0005
I0608 13:05:02.943260 30581 solver.cpp:243] Iteration 2590, loss = 1.77311
I0608 13:05:02.943290 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.30723 (* 1 = 2.30723 loss)
I0608 13:05:02.943297 30581 sgd_solver.cpp:138] Iteration 2590, lr = 0.0005
I0608 13:05:12.813347 30581 solver.cpp:433] Iteration 2600, Testing net (#0)
I0608 13:05:12.813446 30581 net.cpp:693] Ignoring source layer mbox_loss
I0608 13:05:14.427788 30581 solver.cpp:546]     Test net output #0: detection_eval = 0.820743
I0608 13:05:14.723053 30581 solver.cpp:243] Iteration 2600, loss = 1.78386
I0608 13:05:14.723076 30581 solver.cpp:259]     Train net output #0: mbox_loss = 1.84125 (* 1 = 1.84125 loss)
I0608 13:05:14.723083 30581 sgd_solver.cpp:138] Iteration 2600, lr = 0.0005
I0608 13:05:24.155143 30581 solver.cpp:243] Iteration 2610, loss = 1.86146
I0608 13:05:24.155172 30581 solver.cpp:259]     Train net output #0: mbox_loss = 1.95531 (* 1 = 1.95531 loss)
I0608 13:05:24.155179 30581 sgd_solver.cpp:138] Iteration 2610, lr = 0.0005
I0608 13:05:33.788175 30581 solver.cpp:243] Iteration 2620, loss = 1.74379
I0608 13:05:33.788198 30581 solver.cpp:259]     Train net output #0: mbox_loss = 1.67673 (* 1 = 1.67673 loss)
I0608 13:05:33.788204 30581 sgd_solver.cpp:138] Iteration 2620, lr = 0.0005
I0608 13:05:43.942945 30581 solver.cpp:243] Iteration 2630, loss = 1.80196
I0608 13:05:43.942975 30581 solver.cpp:259]     Train net output #0: mbox_loss = 1.72414 (* 1 = 1.72414 loss)
I0608 13:05:43.942996 30581 sgd_solver.cpp:138] Iteration 2630, lr = 0.0005
I0608 13:05:53.775331 30581 solver.cpp:243] Iteration 2640, loss = 1.71466
I0608 13:05:53.775496 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.00282 (* 1 = 2.00282 loss)
I0608 13:05:53.775503 30581 sgd_solver.cpp:138] Iteration 2640, lr = 0.0005
I0608 13:06:04.099263 30581 solver.cpp:243] Iteration 2650, loss = 1.70269
I0608 13:06:04.099293 30581 solver.cpp:259]     Train net output #0: mbox_loss = 1.73685 (* 1 = 1.73685 loss)
I0608 13:06:04.099299 30581 sgd_solver.cpp:138] Iteration 2650, lr = 0.0005
I0608 13:06:13.384471 30581 solver.cpp:243] Iteration 2660, loss = 1.80309
I0608 13:06:13.384501 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.17686 (* 1 = 2.17686 loss)
I0608 13:06:13.384507 30581 sgd_solver.cpp:138] Iteration 2660, lr = 0.0005
I0608 13:06:23.645165 30581 solver.cpp:243] Iteration 2670, loss = 1.75166
I0608 13:06:23.645195 30581 solver.cpp:259]     Train net output #0: mbox_loss = 1.78428 (* 1 = 1.78428 loss)
I0608 13:06:23.645200 30581 sgd_solver.cpp:138] Iteration 2670, lr = 0.0005
I0608 13:06:34.219499 30581 solver.cpp:243] Iteration 2680, loss = 1.87411
I0608 13:06:34.219653 30581 solver.cpp:259]     Train net output #0: mbox_loss = 1.90807 (* 1 = 1.90807 loss)
I0608 13:06:34.219676 30581 sgd_solver.cpp:138] Iteration 2680, lr = 0.0005
I0608 13:06:44.826555 30581 solver.cpp:243] Iteration 2690, loss = 1.76062
I0608 13:06:44.826584 30581 solver.cpp:259]     Train net output #0: mbox_loss = 1.88813 (* 1 = 1.88813 loss)
I0608 13:06:44.826591 30581 sgd_solver.cpp:138] Iteration 2690, lr = 0.0005
I0608 13:06:54.767570 30581 solver.cpp:243] Iteration 2700, loss = 1.76691
I0608 13:06:54.767603 30581 solver.cpp:259]     Train net output #0: mbox_loss = 1.76176 (* 1 = 1.76176 loss)
I0608 13:06:54.767611 30581 sgd_solver.cpp:138] Iteration 2700, lr = 0.0005
I0608 13:07:05.110345 30581 solver.cpp:243] Iteration 2710, loss = 1.85632
I0608 13:07:05.110533 30581 solver.cpp:259]     Train net output #0: mbox_loss = 1.83085 (* 1 = 1.83085 loss)
I0608 13:07:05.110541 30581 sgd_solver.cpp:138] Iteration 2710, lr = 0.0005
I0608 13:07:15.556231 30581 solver.cpp:243] Iteration 2720, loss = 1.84351
I0608 13:07:15.556257 30581 solver.cpp:259]     Train net output #0: mbox_loss = 1.94052 (* 1 = 1.94052 loss)
I0608 13:07:15.556264 30581 sgd_solver.cpp:138] Iteration 2720, lr = 0.0005
I0608 13:07:25.803167 30581 solver.cpp:243] Iteration 2730, loss = 1.9252
I0608 13:07:25.803200 30581 solver.cpp:259]     Train net output #0: mbox_loss = 1.94501 (* 1 = 1.94501 loss)
I0608 13:07:25.803205 30581 sgd_solver.cpp:138] Iteration 2730, lr = 0.0005
I0608 13:07:36.314704 30581 solver.cpp:243] Iteration 2740, loss = 1.90035
I0608 13:07:36.314863 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.8003 (* 1 = 2.8003 loss)
I0608 13:07:36.314888 30581 sgd_solver.cpp:138] Iteration 2740, lr = 0.0005
I0608 13:07:46.068379 30581 solver.cpp:243] Iteration 2750, loss = 1.99955
I0608 13:07:46.068409 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.0595 (* 1 = 2.0595 loss)
I0608 13:07:46.068415 30581 sgd_solver.cpp:138] Iteration 2750, lr = 0.0005
I0608 13:07:56.459525 30581 solver.cpp:243] Iteration 2760, loss = 1.87195
I0608 13:07:56.459555 30581 solver.cpp:259]     Train net output #0: mbox_loss = 1.73232 (* 1 = 1.73232 loss)
I0608 13:07:56.459561 30581 sgd_solver.cpp:138] Iteration 2760, lr = 0.0005
I0608 13:08:06.233721 30581 solver.cpp:243] Iteration 2770, loss = 1.79685
I0608 13:08:06.233748 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.04724 (* 1 = 2.04724 loss)
I0608 13:08:06.233754 30581 sgd_solver.cpp:138] Iteration 2770, lr = 0.0005
I0608 13:08:17.534062 30581 solver.cpp:243] Iteration 2780, loss = 1.70228
I0608 13:08:17.534131 30581 solver.cpp:259]     Train net output #0: mbox_loss = 1.6741 (* 1 = 1.6741 loss)
I0608 13:08:17.534138 30581 sgd_solver.cpp:138] Iteration 2780, lr = 0.0005
I0608 13:08:27.607201 30581 solver.cpp:243] Iteration 2790, loss = 1.78258
I0608 13:08:27.607234 30581 solver.cpp:259]     Train net output #0: mbox_loss = 1.72997 (* 1 = 1.72997 loss)
I0608 13:08:27.607239 30581 sgd_solver.cpp:138] Iteration 2790, lr = 0.0005
I0608 13:08:37.963943 30581 solver.cpp:433] Iteration 2800, Testing net (#0)
I0608 13:08:37.964042 30581 net.cpp:693] Ignoring source layer mbox_loss
I0608 13:08:39.460517 30581 solver.cpp:546]     Test net output #0: detection_eval = 0.833011
I0608 13:08:39.762251 30581 solver.cpp:243] Iteration 2800, loss = 1.77441
I0608 13:08:39.762280 30581 solver.cpp:259]     Train net output #0: mbox_loss = 1.77887 (* 1 = 1.77887 loss)
I0608 13:08:39.762285 30581 sgd_solver.cpp:138] Iteration 2800, lr = 0.0005
I0608 13:08:49.348837 30581 solver.cpp:243] Iteration 2810, loss = 1.74851
I0608 13:08:49.348942 30581 solver.cpp:259]     Train net output #0: mbox_loss = 1.62271 (* 1 = 1.62271 loss)
I0608 13:08:49.348964 30581 sgd_solver.cpp:138] Iteration 2810, lr = 0.0005
I0608 13:08:59.848387 30581 solver.cpp:243] Iteration 2820, loss = 1.74433
I0608 13:08:59.848415 30581 solver.cpp:259]     Train net output #0: mbox_loss = 1.82919 (* 1 = 1.82919 loss)
I0608 13:08:59.848422 30581 sgd_solver.cpp:138] Iteration 2820, lr = 0.0005
I0608 13:09:10.536006 30581 solver.cpp:243] Iteration 2830, loss = 1.86575
I0608 13:09:10.536031 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.25317 (* 1 = 2.25317 loss)
I0608 13:09:10.536036 30581 sgd_solver.cpp:138] Iteration 2830, lr = 0.0005
I0608 13:09:21.332844 30581 solver.cpp:243] Iteration 2840, loss = 1.76122
I0608 13:09:21.333334 30581 solver.cpp:259]     Train net output #0: mbox_loss = 1.57857 (* 1 = 1.57857 loss)
I0608 13:09:21.333345 30581 sgd_solver.cpp:138] Iteration 2840, lr = 0.0005
I0608 13:09:32.346910 30581 solver.cpp:243] Iteration 2850, loss = 1.67666
I0608 13:09:32.346937 30581 solver.cpp:259]     Train net output #0: mbox_loss = 1.64981 (* 1 = 1.64981 loss)
I0608 13:09:32.346943 30581 sgd_solver.cpp:138] Iteration 2850, lr = 0.0005
I0608 13:09:43.255004 30581 solver.cpp:243] Iteration 2860, loss = 1.68541
I0608 13:09:43.255034 30581 solver.cpp:259]     Train net output #0: mbox_loss = 1.68222 (* 1 = 1.68222 loss)
I0608 13:09:43.255043 30581 sgd_solver.cpp:138] Iteration 2860, lr = 0.0005
I0608 13:09:54.259353 30581 solver.cpp:243] Iteration 2870, loss = 1.76399
I0608 13:09:54.259507 30581 solver.cpp:259]     Train net output #0: mbox_loss = 1.37381 (* 1 = 1.37381 loss)
I0608 13:09:54.259531 30581 sgd_solver.cpp:138] Iteration 2870, lr = 0.0005
I0608 13:10:04.765775 30581 solver.cpp:243] Iteration 2880, loss = 1.78696
I0608 13:10:04.765803 30581 solver.cpp:259]     Train net output #0: mbox_loss = 1.84553 (* 1 = 1.84553 loss)
I0608 13:10:04.765810 30581 sgd_solver.cpp:138] Iteration 2880, lr = 0.0005
I0608 13:10:15.798002 30581 solver.cpp:243] Iteration 2890, loss = 1.72172
I0608 13:10:15.798028 30581 solver.cpp:259]     Train net output #0: mbox_loss = 1.51574 (* 1 = 1.51574 loss)
I0608 13:10:15.798034 30581 sgd_solver.cpp:138] Iteration 2890, lr = 0.0005
I0608 13:10:26.637058 30581 solver.cpp:243] Iteration 2900, loss = 1.68976
I0608 13:10:26.637194 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.14595 (* 1 = 2.14595 loss)
I0608 13:10:26.637217 30581 sgd_solver.cpp:138] Iteration 2900, lr = 0.0005
I0608 13:10:37.651391 30581 solver.cpp:243] Iteration 2910, loss = 1.77628
I0608 13:10:37.651418 30581 solver.cpp:259]     Train net output #0: mbox_loss = 1.52341 (* 1 = 1.52341 loss)
I0608 13:10:37.651423 30581 sgd_solver.cpp:138] Iteration 2910, lr = 0.0005
I0608 13:10:47.499203 30581 solver.cpp:243] Iteration 2920, loss = 1.90156
I0608 13:10:47.499233 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.06525 (* 1 = 2.06525 loss)
I0608 13:10:47.499239 30581 sgd_solver.cpp:138] Iteration 2920, lr = 0.0005
I0608 13:10:59.119413 30581 solver.cpp:243] Iteration 2930, loss = 2.00748
I0608 13:10:59.119560 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.22613 (* 1 = 2.22613 loss)
I0608 13:10:59.119582 30581 sgd_solver.cpp:138] Iteration 2930, lr = 0.0005
I0608 13:11:09.578752 30581 solver.cpp:243] Iteration 2940, loss = 1.91365
I0608 13:11:09.578776 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.35726 (* 1 = 2.35726 loss)
I0608 13:11:09.578783 30581 sgd_solver.cpp:138] Iteration 2940, lr = 0.0005
I0608 13:11:19.772685 30581 solver.cpp:243] Iteration 2950, loss = 1.81999
I0608 13:11:19.772708 30581 solver.cpp:259]     Train net output #0: mbox_loss = 1.93624 (* 1 = 1.93624 loss)
I0608 13:11:19.772729 30581 sgd_solver.cpp:138] Iteration 2950, lr = 0.0005
I0608 13:11:29.535454 30581 solver.cpp:243] Iteration 2960, loss = 1.93938
I0608 13:11:29.535605 30581 solver.cpp:259]     Train net output #0: mbox_loss = 1.95259 (* 1 = 1.95259 loss)
I0608 13:11:29.535629 30581 sgd_solver.cpp:138] Iteration 2960, lr = 0.0005
I0608 13:11:39.815558 30581 solver.cpp:243] Iteration 2970, loss = 1.94826
I0608 13:11:39.815587 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.01535 (* 1 = 2.01535 loss)
I0608 13:11:39.815593 30581 sgd_solver.cpp:138] Iteration 2970, lr = 0.0005
I0608 13:11:49.987579 30581 solver.cpp:243] Iteration 2980, loss = 1.8354
I0608 13:11:49.987607 30581 solver.cpp:259]     Train net output #0: mbox_loss = 1.56763 (* 1 = 1.56763 loss)
I0608 13:11:49.987613 30581 sgd_solver.cpp:138] Iteration 2980, lr = 0.0005
I0608 13:12:00.207331 30581 solver.cpp:243] Iteration 2990, loss = 1.78806
I0608 13:12:00.207476 30581 solver.cpp:259]     Train net output #0: mbox_loss = 1.48888 (* 1 = 1.48888 loss)
I0608 13:12:00.207499 30581 sgd_solver.cpp:138] Iteration 2990, lr = 0.0005
I0608 13:12:09.661147 30581 solver.cpp:433] Iteration 3000, Testing net (#0)
I0608 13:12:09.661222 30581 net.cpp:693] Ignoring source layer mbox_loss
I0608 13:12:11.171561 30581 solver.cpp:546]     Test net output #0: detection_eval = 0.809403
I0608 13:12:11.483412 30581 solver.cpp:243] Iteration 3000, loss = 1.74864
I0608 13:12:11.483439 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.20313 (* 1 = 2.20313 loss)
I0608 13:12:11.483445 30581 sgd_solver.cpp:138] Iteration 3000, lr = 0.0005
I0608 13:12:21.620409 30581 solver.cpp:243] Iteration 3010, loss = 1.66744
I0608 13:12:21.620436 30581 solver.cpp:259]     Train net output #0: mbox_loss = 1.47373 (* 1 = 1.47373 loss)
I0608 13:12:21.620441 30581 sgd_solver.cpp:138] Iteration 3010, lr = 0.0005
I0608 13:12:32.871974 30581 solver.cpp:243] Iteration 3020, loss = 1.80622
I0608 13:12:32.872233 30581 solver.cpp:259]     Train net output #0: mbox_loss = 1.94837 (* 1 = 1.94837 loss)
I0608 13:12:32.872242 30581 sgd_solver.cpp:138] Iteration 3020, lr = 0.0005
I0608 13:12:42.574950 30581 blocking_queue.cpp:50] Data layer prefetch queue empty
I0608 13:12:43.675721 30581 solver.cpp:243] Iteration 3030, loss = 1.82871
I0608 13:12:43.675747 30581 solver.cpp:259]     Train net output #0: mbox_loss = 1.74195 (* 1 = 1.74195 loss)
I0608 13:12:43.675753 30581 sgd_solver.cpp:138] Iteration 3030, lr = 0.0005
I0608 13:12:54.220438 30581 solver.cpp:243] Iteration 3040, loss = 1.72931
I0608 13:12:54.220463 30581 solver.cpp:259]     Train net output #0: mbox_loss = 1.66878 (* 1 = 1.66878 loss)
I0608 13:12:54.220468 30581 sgd_solver.cpp:138] Iteration 3040, lr = 0.0005
I0608 13:13:05.328832 30581 solver.cpp:243] Iteration 3050, loss = 1.65863
I0608 13:13:05.328886 30581 solver.cpp:259]     Train net output #0: mbox_loss = 1.75137 (* 1 = 1.75137 loss)
I0608 13:13:05.328893 30581 sgd_solver.cpp:138] Iteration 3050, lr = 0.0005
I0608 13:13:16.356453 30581 solver.cpp:243] Iteration 3060, loss = 1.58823
I0608 13:13:16.356495 30581 solver.cpp:259]     Train net output #0: mbox_loss = 1.48265 (* 1 = 1.48265 loss)
I0608 13:13:16.356501 30581 sgd_solver.cpp:138] Iteration 3060, lr = 0.0005
I0608 13:13:27.642696 30581 solver.cpp:243] Iteration 3070, loss = 1.72074
I0608 13:13:27.642724 30581 solver.cpp:259]     Train net output #0: mbox_loss = 1.56538 (* 1 = 1.56538 loss)
I0608 13:13:27.642729 30581 sgd_solver.cpp:138] Iteration 3070, lr = 0.0005
I0608 13:13:39.124044 30581 solver.cpp:243] Iteration 3080, loss = 1.75009
I0608 13:13:39.124179 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.13797 (* 1 = 2.13797 loss)
I0608 13:13:39.124187 30581 sgd_solver.cpp:138] Iteration 3080, lr = 0.0005
I0608 13:13:49.937973 30581 solver.cpp:243] Iteration 3090, loss = 1.72995
I0608 13:13:49.938009 30581 solver.cpp:259]     Train net output #0: mbox_loss = 1.68745 (* 1 = 1.68745 loss)
I0608 13:13:49.938030 30581 sgd_solver.cpp:138] Iteration 3090, lr = 0.0005
I0608 13:14:00.658128 30581 solver.cpp:243] Iteration 3100, loss = 1.66412
I0608 13:14:00.658159 30581 solver.cpp:259]     Train net output #0: mbox_loss = 1.47906 (* 1 = 1.47906 loss)
I0608 13:14:00.658167 30581 sgd_solver.cpp:138] Iteration 3100, lr = 0.0005
I0608 13:14:11.616453 30581 solver.cpp:243] Iteration 3110, loss = 1.79713
I0608 13:14:11.616519 30581 solver.cpp:259]     Train net output #0: mbox_loss = 2.19476 (* 1 = 2.19476 loss)
I0608 13:14:11.616528 30581 sgd_solver.cpp:138] Iteration 3110, lr = 0.0005
I0608 13:14:21.685377 30581 solver.cpp:243] Iteration 3120, loss = 1.67998
I0608 13:14:21.685405 30581 solver.cpp:259]     Train net output #0: mbox_loss = 1.70684 (* 1 = 1.70684 loss)
I0608 13:14:21.685413 30581 sgd_solver.cpp:138] Iteration 3120, lr = 0.0005
I0608 13:14:32.914515 30581 solver.cpp:243] Iteration 3130, loss = 1.73171
I0608 13:14:32.914543 30581 solver.cpp:259]     Train net output #0: mbox_loss = 1.72019 (* 1 = 1.72019 loss)
I0608 13:14:32.914551 30581 sgd_solver.cpp:138] Iteration 3130, lr = 0.0005
